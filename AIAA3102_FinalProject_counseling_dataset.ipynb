{"cells":[{"cell_type":"markdown","metadata":{"id":"PawYFNTou8lw"},"source":["# Run train_base.py (LoRA / QLoRA) from Drive\n","本 Notebook 包含以下步骤：\n","1. 挂载 Google Drive（读取你已保存的 train_base.py / Configs / Data）\n","2. 安装依赖（transformers, datasets, peft, bitsandbytes, accelerate, huggingface_hub）\n","3. 设置 HF_TOKEN（从 Colab Secrets / 交互输入）\n","4. 做一个小规模 debug 子集并运行 train_base.py 进行快速 smoke-test\n","5.（可选）运行完整训练"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q-zMdRtmvJPf","outputId":"a89bc8f5-9cbd-4c91-9f0e-1598d75228d3","executionInfo":{"status":"ok","timestamp":1764056035719,"user_tz":-480,"elapsed":21887,"user":{"displayName":"Andy","userId":"06581432161554596484"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","BASE_DIR = /content/drive/MyDrive/AIAA3102/Final_Project\n","total 419\n","-rw------- 1 root root  67456 Nov 12 06:36 AIAA3102-FinalProject_Awareness_Ignorance.ipynb\n","-rw------- 1 root root 101562 Nov 25 07:31 AIAA3102_FinalProject_counseling_dataset.ipynb\n","-rw------- 1 root root 112736 Nov 14 16:38 AIAA3102_FinalProject_wyy_01.ipynb\n","-rw------- 1 root root  65025 Nov 24 04:17 AIAA3102_FinalProject_wyy_02.ipynb\n","drwx------ 2 root root   4096 Nov  9 10:48 Configs\n","drwx------ 2 root root   4096 Nov  9 10:48 Data\n","drwx------ 2 root root   4096 Nov  9 10:50 Deliverables\n","-rw------- 1 root root  51393 Nov 24 04:36 File_creator.ipynb\n","drwx------ 2 root root   4096 Nov  9 11:19 .ipynb_checkpoints\n","drwx------ 2 root root   4096 Nov  9 11:29 Models\n","drwx------ 2 root root   4096 Nov  9 10:48 Results\n","drwx------ 2 root root   4096 Nov  9 11:19 Scripts\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# 修改为你自己的项目根目录（与 train_base.py 写入位置一致）\n","BASE_DIR = \"/content/drive/MyDrive/AIAA3102/Final_Project\"   # <- 如果各位的路径不同，请修改\n","SCRIPTS_DIR = f\"{BASE_DIR}/Scripts\"\n","CONFIGS_DIR = f\"{BASE_DIR}/Configs\"\n","DATA_DIR = f\"{BASE_DIR}/Data\"\n","MODELS_DIR = f\"{BASE_DIR}/Models\"\n","RESULTS_DIR = f\"{BASE_DIR}/Results\"\n","\n","print(\"BASE_DIR =\", BASE_DIR)\n","!ls -la \"{BASE_DIR}\"\n"]},{"cell_type":"markdown","metadata":{"id":"ss8UocMimzA5"},"source":["# Install dependencies and import libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"rqURByA6msI4","outputId":"a5107814-fa7e-4b2a-a63c-d504994664c5","executionInfo":{"status":"ok","timestamp":1764047129154,"user_tz":-480,"elapsed":8854,"user":{"displayName":"Andy","userId":"06581432161554596484"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n","Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.0)\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.9.0+cu126)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n","Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.48.2\n"]}],"source":["!pip install transformers datasets peft bitsandbytes accelerate huggingface_hub\n","# 需要一乃乃时间"]},{"cell_type":"markdown","metadata":{"id":"rHnE5d2fvX2T"},"source":["# Check Cuda"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7PutlfsRnEHM","outputId":"6e3ed9c8-d241-463b-f6d8-05e080a812e3","executionInfo":{"status":"ok","timestamp":1764047182359,"user_tz":-480,"elapsed":50398,"user":{"displayName":"Andy","userId":"06581432161554596484"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n","from peft import LoraConfig, get_peft_model\n","import bitsandbytes as bnb\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n"]},{"cell_type":"markdown","metadata":{"id":"xZ9W8JJpnIB6"},"source":["# Ensure the configs/script/py files"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"a-L2JXlAnUW0","outputId":"314bc146-9410-44ee-9a0b-456d9bdfb415","executionInfo":{"status":"ok","timestamp":1764047190205,"user_tz":-480,"elapsed":1920,"user":{"displayName":"Andy","userId":"06581432161554596484"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["script exists: False /content/drive/MyDrive/AIAA3102/Final_Project/Scripts/con_train_base.py\n","configs exists: True /content/drive/MyDrive/AIAA3102/Final_Project/Configs\n","train exists: True /content/drive/MyDrive/AIAA3102/Final_Project/Data/con_train.jsonl\n","valid exists: True /content/drive/MyDrive/AIAA3102/Final_Project/Data/con_valid.jsonl\n","unknown exists: True /content/drive/MyDrive/AIAA3102/Final_Project/Data/con_unknown_test.jsonl\n","\n","--- train.jsonl (first 3 lines) ---\n","{\"prompt\": \"I have suffered many things at home and school. We never went to the doctor to diagnose depression or anything like that, but I always feel like a part of my heart is missing. I try to fill it in with objects or, in this case, a woman.\", \"response\": \"There are a lot of ways to look at this. It sounds as if there is a part of you that is looking for support. I wonder what it is that you feel when you're not in a relationship?Because of the way you asked the question, I'm getting the impression that you are referring to romantic relationships. I wonder if you have close friendships that could form a network to help with this when you are not romantically involved with someone. Even when you are in a relationship with a romantic partner, having friends is still an important element.I wonder if you could also notice what changes for you inside of yourself (as far as emotions) when you move from not being in a relationship to being in one.Perhaps you could take a look at what you value about yourself.In general, it is natural for people to want to be in relationships with others (in this case, relationship has many meanings and degrees). Most of us enjoy sharing elements of our days, thoughts, feelings, etc. with someone else who we trust and care about – also hoping they care about us in return.\"}\n","{\"prompt\": \"I feel like I hate myself physically and emotionally sometimes. How can I start accepting myself and be more confident?\", \"response\": \"Self-doubt and self-hatred are such common and unpleasant experiences and really worth  understanding! Therapy with the right person can really help. When in your life do you feel the most confident? What gets in the way of you accepting and loving yourself (big question!). You can and will uncover that confident self!\"}\n","{\"prompt\": \"I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?\", \"response\": \"Feelings of worthlessness often originate  from what you learned about yourself when you were young. Improving your self esteem needs focus on that original message from parents, teachers or siblings that may be suppressed.  Most of us need help to uncover the \\\"lie\\\" because you were born valuable!\"}\n","\n","--- configs (list) ---\n","total 11\n","-rw------- 1 root root 1411 Nov  9 11:16 eval_config.yaml\n","drwx------ 2 root root 4096 Nov 17 11:33 .ipynb_checkpoints\n","-rw------- 1 root root  814 Nov  9 11:58 model_config.yaml\n","-rw------- 1 root root 1560 Nov 17 11:33 training_args0.yaml\n","-rw------- 1 root root 1580 Nov 14 16:38 training_args.yaml\n"]}],"source":["import os\n","paths = {\n","    \"script\": f\"{SCRIPTS_DIR}/con_train_base.py\",\n","    \"configs\": CONFIGS_DIR,\n","    \"train\": f\"{DATA_DIR}/con_train.jsonl\",\n","    \"valid\": f\"{DATA_DIR}/con_valid.jsonl\",\n","    \"unknown\": f\"{DATA_DIR}/con_unknown_test.jsonl\",\n","}\n","for k, p in paths.items():\n","    print(k, \"exists:\", os.path.exists(p), p)\n","\n","# 打印前几行检查\n","print(\"\\n--- train.jsonl (first 3 lines) ---\")\n","!head -n 3 \"{paths['train']}\"\n","print(\"\\n--- configs (list) ---\")\n","!ls -la \"{CONFIGS_DIR}\"\n"]},{"cell_type":"markdown","metadata":{"id":"gAcnlA-CnW7b"},"source":["# Debug Dataset Generation"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HsXvVXkHneIV","outputId":"12e696d4-cbcb-44ce-d90c-0fb914fba065","executionInfo":{"status":"ok","timestamp":1764047198047,"user_tz":-480,"elapsed":5238,"user":{"displayName":"Andy","userId":"06581432161554596484"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Debug subsets created: /content/drive/MyDrive/AIAA3102/Final_Project/Data/con_train_debug.jsonl /content/drive/MyDrive/AIAA3102/Final_Project/Data/con_valid_debug.jsonl\n","   20 /content/drive/MyDrive/AIAA3102/Final_Project/Data/con_train_debug.jsonl\n","   10 /content/drive/MyDrive/AIAA3102/Final_Project/Data/con_valid_debug.jsonl\n","   30 total\n"]}],"source":["# Create tiny debug subsets to run a quick smoke-test (avoid long runs)\n","import shutil\n","from pathlib import Path\n","p_data = Path(DATA_DIR)\n","debug_train = p_data / \"con_train_debug.jsonl\"\n","debug_valid = p_data / \"con_valid_debug.jsonl\"\n","\n","def subset(src, dst, n=20):\n","    with open(src, 'r', encoding='utf-8') as rf, open(dst, 'w', encoding='utf-8') as wf:\n","        for i, line in enumerate(rf):\n","            if i >= n:\n","                break\n","            wf.write(line)\n","\n","subset(paths[\"train\"], debug_train, n=20)\n","subset(paths[\"valid\"], debug_valid, n=10)\n","print(\"Debug subsets created:\", debug_train, debug_valid)\n","!wc -l \"{debug_train}\" \"{debug_valid}\"\n"]},{"cell_type":"markdown","metadata":{"id":"G_AzrivIu7aC"},"source":[]},{"cell_type":"markdown","metadata":{"id":"TA6O5hegn2Eh"},"source":["**Training**"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MIJUcC_0n4Ku","outputId":"a129f008-f414-4d22-86bf-8f40757bc661","executionInfo":{"status":"ok","timestamp":1764051127690,"user_tz":-480,"elapsed":2047414,"user":{"displayName":"Andy","userId":"06581432161554596484"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2025-11-25 05:06:56.448691: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1764047216.481303    2064 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1764047216.491008    2064 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1764047216.514583    2064 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1764047216.514622    2064 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1764047216.514631    2064 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1764047216.514636    2064 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","tokenizer_config.json: 100% 776/776 [00:00<00:00, 6.72MB/s]\n","tokenizer.model: 100% 500k/500k [00:01<00:00, 371kB/s]\n","tokenizer.json: 1.84MB [00:00, 135MB/s]\n","special_tokens_map.json: 100% 414/414 [00:00<00:00, 3.97MB/s]\n","config.json: 100% 560/560 [00:00<00:00, 5.45MB/s]\n","pytorch_model.bin: 100% 4.40G/4.40G [00:49<00:00, 89.0MB/s]\n","generation_config.json: 100% 129/129 [00:00<00:00, 1.18MB/s]\n","/content/drive/MyDrive/AIAA3102/Final_Project/Scripts/train_base.py:299: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n","The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n","  0% 0/1875 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n","{'loss': 2.4854, 'grad_norm': 2.6372103691101074, 'learning_rate': 4.869333333333334e-05, 'epoch': 0.13}\n","{'loss': 2.4566, 'grad_norm': 2.506474018096924, 'learning_rate': 4.736000000000001e-05, 'epoch': 0.27}\n","{'loss': 2.3815, 'grad_norm': 1.4407061338424683, 'learning_rate': 4.602666666666667e-05, 'epoch': 0.4}\n","{'loss': 2.3855, 'grad_norm': 1.3594776391983032, 'learning_rate': 4.4693333333333335e-05, 'epoch': 0.53}\n"," 11% 200/1875 [06:50<54:31,  1.95s/it]\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:03, 12.43it/s]\u001b[A\n","  8% 4/50 [00:00<00:05,  7.78it/s]\u001b[A\n"," 10% 5/50 [00:00<00:06,  6.68it/s]\u001b[A\n"," 12% 6/50 [00:00<00:06,  6.48it/s]\u001b[A\n"," 14% 7/50 [00:01<00:06,  6.33it/s]\u001b[A\n"," 16% 8/50 [00:01<00:06,  6.21it/s]\u001b[A\n"," 18% 9/50 [00:01<00:06,  6.14it/s]\u001b[A\n"," 20% 10/50 [00:01<00:06,  6.07it/s]\u001b[A\n"," 22% 11/50 [00:01<00:06,  6.02it/s]\u001b[A\n"," 24% 12/50 [00:01<00:06,  5.97it/s]\u001b[A\n"," 26% 13/50 [00:02<00:06,  5.96it/s]\u001b[A\n"," 28% 14/50 [00:02<00:06,  5.93it/s]\u001b[A\n"," 30% 15/50 [00:02<00:05,  5.90it/s]\u001b[A\n"," 32% 16/50 [00:02<00:05,  5.89it/s]\u001b[A\n"," 34% 17/50 [00:02<00:05,  5.87it/s]\u001b[A\n"," 36% 18/50 [00:02<00:05,  5.86it/s]\u001b[A\n"," 38% 19/50 [00:03<00:05,  5.82it/s]\u001b[A\n"," 40% 20/50 [00:03<00:05,  5.78it/s]\u001b[A\n"," 42% 21/50 [00:03<00:05,  5.37it/s]\u001b[A\n"," 44% 22/50 [00:03<00:05,  5.32it/s]\u001b[A\n"," 46% 23/50 [00:03<00:05,  5.32it/s]\u001b[A\n"," 48% 24/50 [00:04<00:04,  5.42it/s]\u001b[A\n"," 50% 25/50 [00:04<00:04,  5.17it/s]\u001b[A\n"," 52% 26/50 [00:04<00:04,  5.24it/s]\u001b[A\n"," 54% 27/50 [00:04<00:04,  5.03it/s]\u001b[A\n"," 56% 28/50 [00:04<00:04,  4.66it/s]\u001b[A\n"," 58% 29/50 [00:05<00:04,  4.50it/s]\u001b[A\n"," 60% 30/50 [00:05<00:04,  4.75it/s]\u001b[A\n"," 62% 31/50 [00:05<00:03,  4.93it/s]\u001b[A\n"," 64% 32/50 [00:05<00:03,  4.80it/s]\u001b[A\n"," 66% 33/50 [00:05<00:03,  4.94it/s]\u001b[A\n"," 68% 34/50 [00:06<00:03,  4.42it/s]\u001b[A\n"," 70% 35/50 [00:06<00:03,  4.31it/s]\u001b[A\n"," 72% 36/50 [00:06<00:03,  4.37it/s]\u001b[A\n"," 74% 37/50 [00:06<00:02,  4.38it/s]\u001b[A\n"," 76% 38/50 [00:07<00:02,  4.61it/s]\u001b[A\n"," 78% 39/50 [00:07<00:02,  4.10it/s]\u001b[A\n"," 80% 40/50 [00:07<00:02,  4.07it/s]\u001b[A\n"," 82% 41/50 [00:07<00:02,  4.34it/s]\u001b[A\n"," 84% 42/50 [00:08<00:01,  4.35it/s]\u001b[A\n"," 86% 43/50 [00:08<00:01,  3.89it/s]\u001b[A\n"," 88% 44/50 [00:08<00:01,  4.15it/s]\u001b[A\n"," 90% 45/50 [00:08<00:01,  4.42it/s]\u001b[A\n"," 92% 46/50 [00:09<00:01,  3.71it/s]\u001b[A\n"," 94% 47/50 [00:09<00:00,  4.01it/s]\u001b[A\n"," 96% 48/50 [00:09<00:00,  4.28it/s]\u001b[A\n"," 98% 49/50 [00:09<00:00,  3.76it/s]\u001b[A\n","                                      \n","\u001b[A{'eval_loss': 2.423112392425537, 'eval_runtime': 12.5346, 'eval_samples_per_second': 3.989, 'eval_steps_per_second': 3.989, 'epoch': 0.53}\n"," 11% 200/1875 [07:03<54:31,  1.95s/it]\n","100% 50/50 [00:12<00:00,  4.04it/s]\u001b[A\n","{'loss': 2.381, 'grad_norm': 1.40702223777771, 'learning_rate': 4.336e-05, 'epoch': 0.67}\n","{'loss': 2.3801, 'grad_norm': 2.028378963470459, 'learning_rate': 4.202666666666667e-05, 'epoch': 0.8}\n","{'loss': 2.355, 'grad_norm': 1.7850521802902222, 'learning_rate': 4.069333333333333e-05, 'epoch': 0.93}\n","{'loss': 2.3122, 'grad_norm': 1.584853172302246, 'learning_rate': 3.936e-05, 'epoch': 1.07}\n"," 21% 400/1875 [13:34<49:08,  2.00s/it]\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:03, 12.51it/s]\u001b[A\n","  8% 4/50 [00:00<00:05,  7.78it/s]\u001b[A\n"," 10% 5/50 [00:00<00:06,  6.67it/s]\u001b[A\n"," 12% 6/50 [00:00<00:06,  6.45it/s]\u001b[A\n"," 14% 7/50 [00:01<00:06,  6.32it/s]\u001b[A\n"," 16% 8/50 [00:01<00:06,  6.25it/s]\u001b[A\n"," 18% 9/50 [00:01<00:06,  6.18it/s]\u001b[A\n"," 20% 10/50 [00:01<00:06,  6.13it/s]\u001b[A\n"," 22% 11/50 [00:01<00:06,  6.08it/s]\u001b[A\n"," 24% 12/50 [00:01<00:06,  6.02it/s]\u001b[A\n"," 26% 13/50 [00:02<00:06,  5.88it/s]\u001b[A\n"," 28% 14/50 [00:02<00:06,  5.84it/s]\u001b[A\n"," 30% 15/50 [00:02<00:05,  5.84it/s]\u001b[A\n"," 32% 16/50 [00:02<00:05,  5.82it/s]\u001b[A\n"," 34% 17/50 [00:02<00:05,  5.81it/s]\u001b[A\n"," 36% 18/50 [00:02<00:05,  5.78it/s]\u001b[A\n"," 38% 19/50 [00:03<00:05,  5.74it/s]\u001b[A\n"," 40% 20/50 [00:03<00:05,  5.69it/s]\u001b[A\n"," 42% 21/50 [00:03<00:05,  5.67it/s]\u001b[A\n"," 44% 22/50 [00:03<00:04,  5.67it/s]\u001b[A\n"," 46% 23/50 [00:03<00:04,  5.65it/s]\u001b[A\n"," 48% 24/50 [00:03<00:04,  5.60it/s]\u001b[A\n"," 50% 25/50 [00:04<00:04,  5.28it/s]\u001b[A\n"," 52% 26/50 [00:04<00:04,  5.21it/s]\u001b[A\n"," 54% 27/50 [00:04<00:04,  5.02it/s]\u001b[A\n"," 56% 28/50 [00:04<00:04,  5.08it/s]\u001b[A\n"," 58% 29/50 [00:05<00:04,  4.92it/s]\u001b[A\n"," 60% 30/50 [00:05<00:03,  5.07it/s]\u001b[A\n"," 62% 31/50 [00:05<00:03,  5.20it/s]\u001b[A\n"," 64% 32/50 [00:05<00:03,  5.00it/s]\u001b[A\n"," 66% 33/50 [00:05<00:03,  5.14it/s]\u001b[A\n"," 68% 34/50 [00:05<00:03,  5.23it/s]\u001b[A\n"," 70% 35/50 [00:06<00:02,  5.01it/s]\u001b[A\n"," 72% 36/50 [00:06<00:02,  4.86it/s]\u001b[A\n"," 74% 37/50 [00:06<00:02,  4.75it/s]\u001b[A\n"," 76% 38/50 [00:06<00:02,  4.93it/s]\u001b[A\n"," 78% 39/50 [00:06<00:02,  5.07it/s]\u001b[A\n"," 80% 40/50 [00:07<00:02,  4.86it/s]\u001b[A\n"," 82% 41/50 [00:07<00:01,  4.97it/s]\u001b[A\n"," 84% 42/50 [00:07<00:01,  4.80it/s]\u001b[A\n"," 86% 43/50 [00:07<00:01,  4.93it/s]\u001b[A\n"," 88% 44/50 [00:08<00:01,  5.03it/s]\u001b[A\n"," 90% 45/50 [00:08<00:00,  5.09it/s]\u001b[A\n"," 92% 46/50 [00:08<00:00,  4.85it/s]\u001b[A\n"," 94% 47/50 [00:08<00:00,  4.95it/s]\u001b[A\n"," 96% 48/50 [00:08<00:00,  5.03it/s]\u001b[A\n"," 98% 49/50 [00:09<00:00,  5.08it/s]\u001b[A\n","                                      \n","\u001b[A{'eval_loss': 2.390200138092041, 'eval_runtime': 11.6387, 'eval_samples_per_second': 4.296, 'eval_steps_per_second': 4.296, 'epoch': 1.07}\n"," 21% 400/1875 [13:46<49:08,  2.00s/it]\n","100% 50/50 [00:11<00:00,  5.12it/s]\u001b[A\n","{'loss': 2.2979, 'grad_norm': 2.30605411529541, 'learning_rate': 3.8026666666666666e-05, 'epoch': 1.2}\n","{'loss': 2.3212, 'grad_norm': 2.306962251663208, 'learning_rate': 3.669333333333334e-05, 'epoch': 1.33}\n","{'loss': 2.3202, 'grad_norm': 2.0662615299224854, 'learning_rate': 3.536000000000001e-05, 'epoch': 1.47}\n","{'loss': 2.2943, 'grad_norm': 1.9525245428085327, 'learning_rate': 3.402666666666667e-05, 'epoch': 1.6}\n"," 32% 600/1875 [20:16<40:24,  1.90s/it]\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:03, 12.30it/s]\u001b[A\n","  8% 4/50 [00:00<00:06,  7.43it/s]\u001b[A\n"," 10% 5/50 [00:00<00:06,  6.49it/s]\u001b[A\n"," 12% 6/50 [00:00<00:06,  6.29it/s]\u001b[A\n"," 14% 7/50 [00:01<00:06,  6.17it/s]\u001b[A\n"," 16% 8/50 [00:01<00:06,  6.10it/s]\u001b[A\n"," 18% 9/50 [00:01<00:06,  5.98it/s]\u001b[A\n"," 20% 10/50 [00:01<00:06,  5.92it/s]\u001b[A\n"," 22% 11/50 [00:01<00:06,  5.90it/s]\u001b[A\n"," 24% 12/50 [00:01<00:06,  5.86it/s]\u001b[A\n"," 26% 13/50 [00:02<00:06,  5.82it/s]\u001b[A\n"," 28% 14/50 [00:02<00:06,  5.76it/s]\u001b[A\n"," 30% 15/50 [00:02<00:06,  5.76it/s]\u001b[A\n"," 32% 16/50 [00:02<00:05,  5.73it/s]\u001b[A\n"," 34% 17/50 [00:02<00:05,  5.66it/s]\u001b[A\n"," 36% 18/50 [00:02<00:05,  5.49it/s]\u001b[A\n"," 38% 19/50 [00:03<00:05,  5.46it/s]\u001b[A\n"," 40% 20/50 [00:03<00:05,  5.55it/s]\u001b[A\n"," 42% 21/50 [00:03<00:05,  5.60it/s]\u001b[A\n"," 44% 22/50 [00:03<00:04,  5.64it/s]\u001b[A\n"," 46% 23/50 [00:03<00:04,  5.65it/s]\u001b[A\n"," 48% 24/50 [00:04<00:04,  5.65it/s]\u001b[A\n"," 50% 25/50 [00:04<00:04,  5.33it/s]\u001b[A\n"," 52% 26/50 [00:04<00:04,  5.39it/s]\u001b[A\n"," 54% 27/50 [00:04<00:04,  5.14it/s]\u001b[A\n"," 56% 28/50 [00:04<00:04,  5.26it/s]\u001b[A\n"," 58% 29/50 [00:05<00:04,  5.05it/s]\u001b[A\n"," 60% 30/50 [00:05<00:03,  5.20it/s]\u001b[A\n"," 62% 31/50 [00:05<00:03,  5.28it/s]\u001b[A\n"," 64% 32/50 [00:05<00:03,  5.04it/s]\u001b[A\n"," 66% 33/50 [00:05<00:03,  5.17it/s]\u001b[A\n"," 68% 34/50 [00:05<00:03,  5.23it/s]\u001b[A\n"," 70% 35/50 [00:06<00:02,  5.00it/s]\u001b[A\n"," 72% 36/50 [00:06<00:02,  4.84it/s]\u001b[A\n"," 74% 37/50 [00:06<00:02,  4.73it/s]\u001b[A\n"," 76% 38/50 [00:06<00:02,  4.91it/s]\u001b[A\n"," 78% 39/50 [00:07<00:02,  5.05it/s]\u001b[A\n"," 80% 40/50 [00:07<00:02,  4.85it/s]\u001b[A\n"," 82% 41/50 [00:07<00:01,  4.96it/s]\u001b[A\n"," 84% 42/50 [00:07<00:01,  4.79it/s]\u001b[A\n"," 86% 43/50 [00:07<00:01,  4.91it/s]\u001b[A\n"," 88% 44/50 [00:08<00:01,  5.02it/s]\u001b[A\n"," 90% 45/50 [00:08<00:00,  5.09it/s]\u001b[A\n"," 92% 46/50 [00:08<00:00,  4.87it/s]\u001b[A\n"," 94% 47/50 [00:08<00:00,  4.96it/s]\u001b[A\n"," 96% 48/50 [00:08<00:00,  5.03it/s]\u001b[A\n"," 98% 49/50 [00:09<00:00,  5.07it/s]\u001b[A\n","                                      \n","\u001b[A{'eval_loss': 2.373713493347168, 'eval_runtime': 11.6785, 'eval_samples_per_second': 4.281, 'eval_steps_per_second': 4.281, 'epoch': 1.6}\n"," 32% 600/1875 [20:27<40:24,  1.90s/it]\n","100% 50/50 [00:11<00:00,  5.11it/s]\u001b[A\n","{'loss': 2.2732, 'grad_norm': 1.8653957843780518, 'learning_rate': 3.2693333333333334e-05, 'epoch': 1.73}\n","{'loss': 2.2873, 'grad_norm': 2.383558511734009, 'learning_rate': 3.136e-05, 'epoch': 1.87}\n","{'loss': 2.2658, 'grad_norm': 1.590349555015564, 'learning_rate': 3.0026666666666668e-05, 'epoch': 2.0}\n","{'loss': 2.2626, 'grad_norm': 2.330760955810547, 'learning_rate': 2.8693333333333332e-05, 'epoch': 2.13}\n"," 43% 800/1875 [26:58<34:37,  1.93s/it]\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:03, 12.21it/s]\u001b[A\n","  8% 4/50 [00:00<00:06,  7.34it/s]\u001b[A\n"," 10% 5/50 [00:00<00:07,  6.42it/s]\u001b[A\n"," 12% 6/50 [00:00<00:07,  6.19it/s]\u001b[A\n"," 14% 7/50 [00:01<00:07,  6.14it/s]\u001b[A\n"," 16% 8/50 [00:01<00:06,  6.11it/s]\u001b[A\n"," 18% 9/50 [00:01<00:06,  6.03it/s]\u001b[A\n"," 20% 10/50 [00:01<00:06,  6.00it/s]\u001b[A\n"," 22% 11/50 [00:01<00:06,  5.97it/s]\u001b[A\n"," 24% 12/50 [00:01<00:06,  5.96it/s]\u001b[A\n"," 26% 13/50 [00:02<00:06,  5.93it/s]\u001b[A\n"," 28% 14/50 [00:02<00:06,  5.92it/s]\u001b[A\n"," 30% 15/50 [00:02<00:05,  5.89it/s]\u001b[A\n"," 32% 16/50 [00:02<00:05,  5.87it/s]\u001b[A\n"," 34% 17/50 [00:02<00:05,  5.86it/s]\u001b[A\n"," 36% 18/50 [00:02<00:05,  5.86it/s]\u001b[A\n"," 38% 19/50 [00:03<00:05,  5.82it/s]\u001b[A\n"," 40% 20/50 [00:03<00:05,  5.78it/s]\u001b[A\n"," 42% 21/50 [00:03<00:05,  5.76it/s]\u001b[A\n"," 44% 22/50 [00:03<00:04,  5.74it/s]\u001b[A\n"," 46% 23/50 [00:03<00:04,  5.72it/s]\u001b[A\n"," 48% 24/50 [00:03<00:04,  5.70it/s]\u001b[A\n"," 50% 25/50 [00:04<00:04,  5.34it/s]\u001b[A\n"," 52% 26/50 [00:04<00:04,  5.39it/s]\u001b[A\n"," 54% 27/50 [00:04<00:04,  5.15it/s]\u001b[A\n"," 56% 28/50 [00:04<00:04,  5.25it/s]\u001b[A\n"," 58% 29/50 [00:04<00:04,  5.04it/s]\u001b[A\n"," 60% 30/50 [00:05<00:03,  5.15it/s]\u001b[A\n"," 62% 31/50 [00:05<00:03,  5.28it/s]\u001b[A\n"," 64% 32/50 [00:05<00:03,  5.05it/s]\u001b[A\n"," 66% 33/50 [00:05<00:03,  5.19it/s]\u001b[A\n"," 68% 34/50 [00:05<00:03,  5.29it/s]\u001b[A\n"," 70% 35/50 [00:06<00:02,  5.03it/s]\u001b[A\n"," 72% 36/50 [00:06<00:02,  4.87it/s]\u001b[A\n"," 74% 37/50 [00:06<00:02,  4.74it/s]\u001b[A\n"," 76% 38/50 [00:06<00:02,  4.92it/s]\u001b[A\n"," 78% 39/50 [00:06<00:02,  5.05it/s]\u001b[A\n"," 80% 40/50 [00:07<00:02,  4.85it/s]\u001b[A\n"," 82% 41/50 [00:07<00:01,  4.96it/s]\u001b[A\n"," 84% 42/50 [00:07<00:01,  4.79it/s]\u001b[A\n"," 86% 43/50 [00:07<00:01,  4.93it/s]\u001b[A\n"," 88% 44/50 [00:07<00:01,  5.00it/s]\u001b[A\n"," 90% 45/50 [00:08<00:00,  5.08it/s]\u001b[A\n"," 92% 46/50 [00:08<00:00,  4.85it/s]\u001b[A\n"," 94% 47/50 [00:08<00:00,  4.95it/s]\u001b[A\n"," 96% 48/50 [00:08<00:00,  5.01it/s]\u001b[A\n"," 98% 49/50 [00:08<00:00,  5.06it/s]\u001b[A\n","                                      \n","\u001b[A{'eval_loss': 2.3648760318756104, 'eval_runtime': 11.7379, 'eval_samples_per_second': 4.26, 'eval_steps_per_second': 4.26, 'epoch': 2.13}\n"," 43% 800/1875 [27:10<34:37,  1.93s/it]\n","100% 50/50 [00:11<00:00,  5.09it/s]\u001b[A\n","{'loss': 2.2163, 'grad_norm': 2.6606311798095703, 'learning_rate': 2.7360000000000002e-05, 'epoch': 2.27}\n","{'loss': 2.2364, 'grad_norm': 2.987384080886841, 'learning_rate': 2.6026666666666666e-05, 'epoch': 2.4}\n","{'loss': 2.2682, 'grad_norm': 2.065859317779541, 'learning_rate': 2.4693333333333336e-05, 'epoch': 2.53}\n","{'loss': 2.2134, 'grad_norm': 1.9083659648895264, 'learning_rate': 2.336e-05, 'epoch': 2.67}\n"," 53% 1000/1875 [33:40<29:52,  2.05s/it]\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:03, 12.49it/s]\u001b[A\n","  8% 4/50 [00:00<00:05,  7.68it/s]\u001b[A\n"," 10% 5/50 [00:00<00:06,  6.61it/s]\u001b[A\n"," 12% 6/50 [00:00<00:06,  6.46it/s]\u001b[A\n"," 14% 7/50 [00:01<00:06,  6.36it/s]\u001b[A\n"," 16% 8/50 [00:01<00:06,  6.27it/s]\u001b[A\n"," 18% 9/50 [00:01<00:06,  6.16it/s]\u001b[A\n"," 20% 10/50 [00:01<00:06,  6.09it/s]\u001b[A\n"," 22% 11/50 [00:01<00:06,  6.03it/s]\u001b[A\n"," 24% 12/50 [00:01<00:06,  6.00it/s]\u001b[A\n"," 26% 13/50 [00:02<00:06,  5.95it/s]\u001b[A\n"," 28% 14/50 [00:02<00:06,  5.91it/s]\u001b[A\n"," 30% 15/50 [00:02<00:05,  5.86it/s]\u001b[A\n"," 32% 16/50 [00:02<00:05,  5.86it/s]\u001b[A\n"," 34% 17/50 [00:02<00:05,  5.85it/s]\u001b[A\n"," 36% 18/50 [00:02<00:05,  5.83it/s]\u001b[A\n"," 38% 19/50 [00:03<00:05,  5.81it/s]\u001b[A\n"," 40% 20/50 [00:03<00:05,  5.78it/s]\u001b[A\n"," 42% 21/50 [00:03<00:05,  5.70it/s]\u001b[A\n"," 44% 22/50 [00:03<00:04,  5.69it/s]\u001b[A\n"," 46% 23/50 [00:03<00:04,  5.68it/s]\u001b[A\n"," 48% 24/50 [00:03<00:04,  5.68it/s]\u001b[A\n"," 50% 25/50 [00:04<00:04,  5.34it/s]\u001b[A\n"," 52% 26/50 [00:04<00:04,  5.40it/s]\u001b[A\n"," 54% 27/50 [00:04<00:04,  5.16it/s]\u001b[A\n"," 56% 28/50 [00:04<00:04,  5.28it/s]\u001b[A\n"," 58% 29/50 [00:04<00:04,  5.06it/s]\u001b[A\n"," 60% 30/50 [00:05<00:03,  5.17it/s]\u001b[A\n"," 62% 31/50 [00:05<00:03,  5.26it/s]\u001b[A\n"," 64% 32/50 [00:05<00:03,  5.03it/s]\u001b[A\n"," 66% 33/50 [00:05<00:03,  5.14it/s]\u001b[A\n"," 68% 34/50 [00:05<00:03,  5.23it/s]\u001b[A\n"," 70% 35/50 [00:06<00:02,  5.01it/s]\u001b[A\n"," 72% 36/50 [00:06<00:02,  4.85it/s]\u001b[A\n"," 74% 37/50 [00:06<00:02,  4.75it/s]\u001b[A\n"," 76% 38/50 [00:06<00:02,  4.91it/s]\u001b[A\n"," 78% 39/50 [00:06<00:02,  5.00it/s]\u001b[A\n"," 80% 40/50 [00:07<00:02,  4.83it/s]\u001b[A\n"," 82% 41/50 [00:07<00:01,  4.98it/s]\u001b[A\n"," 84% 42/50 [00:07<00:01,  4.78it/s]\u001b[A\n"," 86% 43/50 [00:07<00:01,  4.93it/s]\u001b[A\n"," 88% 44/50 [00:07<00:01,  5.04it/s]\u001b[A\n"," 90% 45/50 [00:08<00:00,  5.04it/s]\u001b[A\n"," 92% 46/50 [00:08<00:00,  4.82it/s]\u001b[A\n"," 94% 47/50 [00:08<00:00,  4.90it/s]\u001b[A\n"," 96% 48/50 [00:08<00:00,  4.96it/s]\u001b[A\n"," 98% 49/50 [00:08<00:00,  4.96it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 2.3526663780212402, 'eval_runtime': 11.8725, 'eval_samples_per_second': 4.211, 'eval_steps_per_second': 4.211, 'epoch': 2.67}\n"," 53% 1000/1875 [33:51<29:52,  2.05s/it]\n","100% 50/50 [00:11<00:00,  5.02it/s]\u001b[A\n","{'loss': 2.2499, 'grad_norm': 2.5814507007598877, 'learning_rate': 2.2026666666666667e-05, 'epoch': 2.8}\n","{'loss': 2.2519, 'grad_norm': 2.943593978881836, 'learning_rate': 2.0693333333333334e-05, 'epoch': 2.93}\n","{'loss': 2.2324, 'grad_norm': 2.616750955581665, 'learning_rate': 1.936e-05, 'epoch': 3.07}\n","{'loss': 2.1832, 'grad_norm': 3.665578842163086, 'learning_rate': 1.8026666666666668e-05, 'epoch': 3.2}\n"," 64% 1200/1875 [40:22<21:54,  1.95s/it]\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:03, 12.48it/s]\u001b[A\n","  8% 4/50 [00:00<00:05,  7.78it/s]\u001b[A\n"," 10% 5/50 [00:00<00:06,  6.68it/s]\u001b[A\n"," 12% 6/50 [00:00<00:06,  6.39it/s]\u001b[A\n"," 14% 7/50 [00:01<00:06,  6.28it/s]\u001b[A\n"," 16% 8/50 [00:01<00:06,  6.22it/s]\u001b[A\n"," 18% 9/50 [00:01<00:06,  6.15it/s]\u001b[A\n"," 20% 10/50 [00:01<00:06,  6.09it/s]\u001b[A\n"," 22% 11/50 [00:01<00:06,  6.03it/s]\u001b[A\n"," 24% 12/50 [00:01<00:06,  5.98it/s]\u001b[A\n"," 26% 13/50 [00:02<00:06,  5.91it/s]\u001b[A\n"," 28% 14/50 [00:02<00:06,  5.92it/s]\u001b[A\n"," 30% 15/50 [00:02<00:05,  5.88it/s]\u001b[A\n"," 32% 16/50 [00:02<00:05,  5.89it/s]\u001b[A\n"," 34% 17/50 [00:02<00:05,  5.86it/s]\u001b[A\n"," 36% 18/50 [00:02<00:05,  5.82it/s]\u001b[A\n"," 38% 19/50 [00:03<00:05,  5.80it/s]\u001b[A\n"," 40% 20/50 [00:03<00:05,  5.76it/s]\u001b[A\n"," 42% 21/50 [00:03<00:05,  5.74it/s]\u001b[A\n"," 44% 22/50 [00:03<00:04,  5.72it/s]\u001b[A\n"," 46% 23/50 [00:03<00:04,  5.70it/s]\u001b[A\n"," 48% 24/50 [00:03<00:04,  5.65it/s]\u001b[A\n"," 50% 25/50 [00:04<00:04,  5.31it/s]\u001b[A\n"," 52% 26/50 [00:04<00:04,  5.41it/s]\u001b[A\n"," 54% 27/50 [00:04<00:04,  5.15it/s]\u001b[A\n"," 56% 28/50 [00:04<00:04,  5.25it/s]\u001b[A\n"," 58% 29/50 [00:04<00:04,  5.03it/s]\u001b[A\n"," 60% 30/50 [00:05<00:03,  5.12it/s]\u001b[A\n"," 62% 31/50 [00:05<00:03,  5.17it/s]\u001b[A\n"," 64% 32/50 [00:05<00:03,  4.97it/s]\u001b[A\n"," 66% 33/50 [00:05<00:03,  5.08it/s]\u001b[A\n"," 68% 34/50 [00:05<00:03,  5.00it/s]\u001b[A\n"," 70% 35/50 [00:06<00:03,  4.82it/s]\u001b[A\n"," 72% 36/50 [00:06<00:02,  4.72it/s]\u001b[A\n"," 74% 37/50 [00:06<00:02,  4.65it/s]\u001b[A\n"," 76% 38/50 [00:06<00:02,  4.83it/s]\u001b[A\n"," 78% 39/50 [00:06<00:02,  4.97it/s]\u001b[A\n"," 80% 40/50 [00:07<00:02,  4.80it/s]\u001b[A\n"," 82% 41/50 [00:07<00:01,  4.85it/s]\u001b[A\n"," 84% 42/50 [00:07<00:01,  4.70it/s]\u001b[A\n"," 86% 43/50 [00:07<00:01,  4.79it/s]\u001b[A\n"," 88% 44/50 [00:08<00:01,  4.91it/s]\u001b[A\n"," 90% 45/50 [00:08<00:01,  4.99it/s]\u001b[A\n"," 92% 46/50 [00:08<00:00,  4.81it/s]\u001b[A\n"," 94% 47/50 [00:08<00:00,  4.92it/s]\u001b[A\n"," 96% 48/50 [00:08<00:00,  5.00it/s]\u001b[A\n"," 98% 49/50 [00:09<00:00,  5.04it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 2.3443055152893066, 'eval_runtime': 11.6653, 'eval_samples_per_second': 4.286, 'eval_steps_per_second': 4.286, 'epoch': 3.2}\n"," 64% 1200/1875 [40:34<21:54,  1.95s/it]\n","100% 50/50 [00:11<00:00,  5.09it/s]\u001b[A\n","{'loss': 2.2458, 'grad_norm': 2.476698875427246, 'learning_rate': 1.669333333333333e-05, 'epoch': 3.33}\n","{'loss': 2.2167, 'grad_norm': 3.2489511966705322, 'learning_rate': 1.536e-05, 'epoch': 3.47}\n","{'loss': 2.223, 'grad_norm': 2.759610176086426, 'learning_rate': 1.4026666666666669e-05, 'epoch': 3.6}\n","{'loss': 2.2076, 'grad_norm': 2.7597851753234863, 'learning_rate': 1.2693333333333334e-05, 'epoch': 3.73}\n"," 75% 1400/1875 [47:04<15:24,  1.95s/it]\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:03, 12.10it/s]\u001b[A\n","  8% 4/50 [00:00<00:05,  7.76it/s]\u001b[A\n"," 10% 5/50 [00:00<00:06,  6.68it/s]\u001b[A\n"," 12% 6/50 [00:00<00:06,  6.48it/s]\u001b[A\n"," 14% 7/50 [00:01<00:06,  6.32it/s]\u001b[A\n"," 16% 8/50 [00:01<00:06,  6.20it/s]\u001b[A\n"," 18% 9/50 [00:01<00:06,  6.11it/s]\u001b[A\n"," 20% 10/50 [00:01<00:06,  6.07it/s]\u001b[A\n"," 22% 11/50 [00:01<00:06,  6.01it/s]\u001b[A\n"," 24% 12/50 [00:01<00:06,  5.97it/s]\u001b[A\n"," 26% 13/50 [00:02<00:06,  5.96it/s]\u001b[A\n"," 28% 14/50 [00:02<00:06,  5.94it/s]\u001b[A\n"," 30% 15/50 [00:02<00:05,  5.93it/s]\u001b[A\n"," 32% 16/50 [00:02<00:05,  5.88it/s]\u001b[A\n"," 34% 17/50 [00:02<00:05,  5.86it/s]\u001b[A\n"," 36% 18/50 [00:02<00:05,  5.85it/s]\u001b[A\n"," 38% 19/50 [00:03<00:05,  5.83it/s]\u001b[A\n"," 40% 20/50 [00:03<00:05,  5.81it/s]\u001b[A\n"," 42% 21/50 [00:03<00:05,  5.77it/s]\u001b[A\n"," 44% 22/50 [00:03<00:04,  5.74it/s]\u001b[A\n"," 46% 23/50 [00:03<00:04,  5.74it/s]\u001b[A\n"," 48% 24/50 [00:03<00:04,  5.72it/s]\u001b[A\n"," 50% 25/50 [00:04<00:04,  5.36it/s]\u001b[A\n"," 52% 26/50 [00:04<00:04,  5.45it/s]\u001b[A\n"," 54% 27/50 [00:04<00:04,  5.18it/s]\u001b[A\n"," 56% 28/50 [00:04<00:04,  5.30it/s]\u001b[A\n"," 58% 29/50 [00:04<00:04,  5.08it/s]\u001b[A\n"," 60% 30/50 [00:05<00:03,  5.17it/s]\u001b[A\n"," 62% 31/50 [00:05<00:03,  5.20it/s]\u001b[A\n"," 64% 32/50 [00:05<00:03,  4.98it/s]\u001b[A\n"," 66% 33/50 [00:05<00:03,  5.11it/s]\u001b[A\n"," 68% 34/50 [00:05<00:03,  5.18it/s]\u001b[A\n"," 70% 35/50 [00:06<00:03,  4.94it/s]\u001b[A\n"," 72% 36/50 [00:06<00:02,  4.80it/s]\u001b[A\n"," 74% 37/50 [00:06<00:02,  4.70it/s]\u001b[A\n"," 76% 38/50 [00:06<00:02,  4.86it/s]\u001b[A\n"," 78% 39/50 [00:06<00:02,  4.99it/s]\u001b[A\n"," 80% 40/50 [00:07<00:02,  4.79it/s]\u001b[A\n"," 82% 41/50 [00:07<00:01,  4.88it/s]\u001b[A\n"," 84% 42/50 [00:07<00:01,  4.73it/s]\u001b[A\n"," 86% 43/50 [00:07<00:01,  4.85it/s]\u001b[A\n"," 88% 44/50 [00:07<00:01,  4.96it/s]\u001b[A\n"," 90% 45/50 [00:08<00:00,  5.05it/s]\u001b[A\n"," 92% 46/50 [00:08<00:00,  4.84it/s]\u001b[A\n"," 94% 47/50 [00:08<00:00,  4.94it/s]\u001b[A\n"," 96% 48/50 [00:08<00:00,  4.99it/s]\u001b[A\n"," 98% 49/50 [00:08<00:00,  5.05it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 2.339223623275757, 'eval_runtime': 11.5802, 'eval_samples_per_second': 4.318, 'eval_steps_per_second': 4.318, 'epoch': 3.73}\n"," 75% 1400/1875 [47:16<15:24,  1.95s/it]\n","100% 50/50 [00:11<00:00,  5.09it/s]\u001b[A\n","{'loss': 2.2079, 'grad_norm': 2.509399652481079, 'learning_rate': 1.1360000000000001e-05, 'epoch': 3.87}\n","{'loss': 2.1813, 'grad_norm': 3.557408332824707, 'learning_rate': 1.0026666666666668e-05, 'epoch': 4.0}\n","{'loss': 2.2333, 'grad_norm': 2.969754457473755, 'learning_rate': 8.693333333333334e-06, 'epoch': 4.13}\n","{'loss': 2.1305, 'grad_norm': 2.277273178100586, 'learning_rate': 7.36e-06, 'epoch': 4.27}\n"," 85% 1600/1875 [53:46<08:57,  1.96s/it]\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:03, 12.32it/s]\u001b[A\n","  8% 4/50 [00:00<00:05,  7.78it/s]\u001b[A\n"," 10% 5/50 [00:00<00:06,  6.67it/s]\u001b[A\n"," 12% 6/50 [00:00<00:06,  6.39it/s]\u001b[A\n"," 14% 7/50 [00:01<00:06,  6.28it/s]\u001b[A\n"," 16% 8/50 [00:01<00:06,  6.17it/s]\u001b[A\n"," 18% 9/50 [00:01<00:06,  6.10it/s]\u001b[A\n"," 20% 10/50 [00:01<00:06,  6.05it/s]\u001b[A\n"," 22% 11/50 [00:01<00:06,  6.00it/s]\u001b[A\n"," 24% 12/50 [00:01<00:06,  5.95it/s]\u001b[A\n"," 26% 13/50 [00:02<00:06,  5.92it/s]\u001b[A\n"," 28% 14/50 [00:02<00:06,  5.90it/s]\u001b[A\n"," 30% 15/50 [00:02<00:05,  5.90it/s]\u001b[A\n"," 32% 16/50 [00:02<00:05,  5.88it/s]\u001b[A\n"," 34% 17/50 [00:02<00:05,  5.85it/s]\u001b[A\n"," 36% 18/50 [00:02<00:05,  5.81it/s]\u001b[A\n"," 38% 19/50 [00:03<00:05,  5.80it/s]\u001b[A\n"," 40% 20/50 [00:03<00:05,  5.77it/s]\u001b[A\n"," 42% 21/50 [00:03<00:05,  5.74it/s]\u001b[A\n"," 44% 22/50 [00:03<00:04,  5.73it/s]\u001b[A\n"," 46% 23/50 [00:03<00:04,  5.71it/s]\u001b[A\n"," 48% 24/50 [00:03<00:04,  5.70it/s]\u001b[A\n"," 50% 25/50 [00:04<00:04,  5.35it/s]\u001b[A\n"," 52% 26/50 [00:04<00:04,  5.43it/s]\u001b[A\n"," 54% 27/50 [00:04<00:04,  5.17it/s]\u001b[A\n"," 56% 28/50 [00:04<00:04,  5.27it/s]\u001b[A\n"," 58% 29/50 [00:04<00:04,  5.03it/s]\u001b[A\n"," 60% 30/50 [00:05<00:03,  5.12it/s]\u001b[A\n"," 62% 31/50 [00:05<00:03,  5.21it/s]\u001b[A\n"," 64% 32/50 [00:05<00:03,  4.99it/s]\u001b[A\n"," 66% 33/50 [00:05<00:03,  5.09it/s]\u001b[A\n"," 68% 34/50 [00:05<00:03,  5.14it/s]\u001b[A\n"," 70% 35/50 [00:06<00:03,  4.94it/s]\u001b[A\n"," 72% 36/50 [00:06<00:02,  4.80it/s]\u001b[A\n"," 74% 37/50 [00:06<00:02,  4.70it/s]\u001b[A\n"," 76% 38/50 [00:06<00:02,  4.80it/s]\u001b[A\n"," 78% 39/50 [00:06<00:02,  4.91it/s]\u001b[A\n"," 80% 40/50 [00:07<00:02,  4.73it/s]\u001b[A\n"," 82% 41/50 [00:07<00:01,  4.84it/s]\u001b[A\n"," 84% 42/50 [00:07<00:01,  4.70it/s]\u001b[A\n"," 86% 43/50 [00:07<00:01,  4.85it/s]\u001b[A\n"," 88% 44/50 [00:08<00:01,  4.97it/s]\u001b[A\n"," 90% 45/50 [00:08<00:00,  5.04it/s]\u001b[A\n"," 92% 46/50 [00:08<00:00,  4.83it/s]\u001b[A\n"," 94% 47/50 [00:08<00:00,  4.93it/s]\u001b[A\n"," 96% 48/50 [00:08<00:00,  5.00it/s]\u001b[A\n"," 98% 49/50 [00:09<00:00,  5.05it/s]\u001b[A\n","                                       \n","\u001b[A{'eval_loss': 2.3342814445495605, 'eval_runtime': 11.6084, 'eval_samples_per_second': 4.307, 'eval_steps_per_second': 4.307, 'epoch': 4.27}\n"," 85% 1600/1875 [53:57<08:57,  1.96s/it]\n","100% 50/50 [00:11<00:00,  5.10it/s]\u001b[A\n","{'loss': 2.2022, 'grad_norm': 2.018361806869507, 'learning_rate': 6.026666666666667e-06, 'epoch': 4.4}\n","{'loss': 2.2151, 'grad_norm': 2.9717161655426025, 'learning_rate': 4.693333333333334e-06, 'epoch': 4.53}\n","{'loss': 2.1393, 'grad_norm': 2.718470335006714, 'learning_rate': 3.36e-06, 'epoch': 4.67}\n","{'loss': 2.1748, 'grad_norm': 2.631885528564453, 'learning_rate': 2.0266666666666666e-06, 'epoch': 4.8}\n"," 96% 1800/1875 [1:00:28<02:27,  1.96s/it]\n","  0% 0/50 [00:00<?, ?it/s]\u001b[A\n","  4% 2/50 [00:00<00:03, 12.45it/s]\u001b[A\n","  8% 4/50 [00:00<00:05,  7.75it/s]\u001b[A\n"," 10% 5/50 [00:00<00:06,  6.68it/s]\u001b[A\n"," 12% 6/50 [00:00<00:06,  6.45it/s]\u001b[A\n"," 14% 7/50 [00:01<00:06,  6.32it/s]\u001b[A\n"," 16% 8/50 [00:01<00:06,  6.22it/s]\u001b[A\n"," 18% 9/50 [00:01<00:06,  6.13it/s]\u001b[A\n"," 20% 10/50 [00:01<00:06,  6.10it/s]\u001b[A\n"," 22% 11/50 [00:01<00:06,  6.05it/s]\u001b[A\n"," 24% 12/50 [00:01<00:06,  5.97it/s]\u001b[A\n"," 26% 13/50 [00:02<00:06,  5.96it/s]\u001b[A\n"," 28% 14/50 [00:02<00:06,  5.92it/s]\u001b[A\n"," 30% 15/50 [00:02<00:05,  5.88it/s]\u001b[A\n"," 32% 16/50 [00:02<00:05,  5.84it/s]\u001b[A\n"," 34% 17/50 [00:02<00:05,  5.80it/s]\u001b[A\n"," 36% 18/50 [00:02<00:05,  5.74it/s]\u001b[A\n"," 38% 19/50 [00:03<00:05,  5.77it/s]\u001b[A\n"," 40% 20/50 [00:03<00:05,  5.78it/s]\u001b[A\n"," 42% 21/50 [00:03<00:05,  5.75it/s]\u001b[A\n"," 44% 22/50 [00:03<00:04,  5.72it/s]\u001b[A\n"," 46% 23/50 [00:03<00:04,  5.66it/s]\u001b[A\n"," 48% 24/50 [00:03<00:04,  5.62it/s]\u001b[A\n"," 50% 25/50 [00:04<00:04,  5.27it/s]\u001b[A\n"," 52% 26/50 [00:04<00:04,  5.32it/s]\u001b[A\n"," 54% 27/50 [00:04<00:04,  5.08it/s]\u001b[A\n"," 56% 28/50 [00:04<00:04,  5.20it/s]\u001b[A\n"," 58% 29/50 [00:04<00:04,  5.01it/s]\u001b[A\n"," 60% 30/50 [00:05<00:03,  5.12it/s]\u001b[A\n"," 62% 31/50 [00:05<00:03,  5.21it/s]\u001b[A\n"," 64% 32/50 [00:05<00:03,  4.96it/s]\u001b[A\n"," 66% 33/50 [00:05<00:03,  5.08it/s]\u001b[A\n"," 68% 34/50 [00:05<00:03,  5.10it/s]\u001b[A\n"," 70% 35/50 [00:06<00:03,  4.90it/s]\u001b[A\n"," 72% 36/50 [00:06<00:02,  4.78it/s]\u001b[A\n"," 74% 37/50 [00:06<00:02,  4.70it/s]\u001b[A\n"," 76% 38/50 [00:06<00:02,  4.87it/s]\u001b[A\n"," 78% 39/50 [00:06<00:02,  5.03it/s]\u001b[A\n"," 80% 40/50 [00:07<00:02,  4.84it/s]\u001b[A\n"," 82% 41/50 [00:07<00:01,  4.97it/s]\u001b[A\n"," 84% 42/50 [00:07<00:01,  4.79it/s]\u001b[A\n"," 86% 43/50 [00:07<00:01,  4.91it/s]\u001b[A\n"," 88% 44/50 [00:08<00:01,  5.03it/s]\u001b[A\n"," 90% 45/50 [00:08<00:00,  5.05it/s]\u001b[A\n"," 92% 46/50 [00:08<00:00,  4.86it/s]\u001b[A\n"," 94% 47/50 [00:08<00:00,  4.96it/s]\u001b[A\n"," 96% 48/50 [00:08<00:00,  5.03it/s]\u001b[A\n"," 98% 49/50 [00:09<00:00,  5.05it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 2.332937240600586, 'eval_runtime': 11.554, 'eval_samples_per_second': 4.328, 'eval_steps_per_second': 4.328, 'epoch': 4.8}\n"," 96% 1800/1875 [1:00:39<02:27,  1.96s/it]\n","100% 50/50 [00:11<00:00,  5.10it/s]\u001b[A\n","{'loss': 2.1571, 'grad_norm': 2.3954107761383057, 'learning_rate': 6.933333333333333e-07, 'epoch': 4.93}\n","{'train_runtime': 3786.8578, 'train_samples_per_second': 1.981, 'train_steps_per_second': 0.495, 'train_loss': 2.265031113688151, 'epoch': 5.0}\n","100% 1875/1875 [1:03:06<00:00,  2.02s/it]\n"]}],"source":["# 这个是debug的命令\n","# 注意：--config_dir 指向你 Drive 下的 Configs 文件夹\n","'''\n","!python \"{SCRIPTS_DIR}/train_base.py\" \\\n","  --config_dir \"{CONFIGS_DIR}\" \\\n","  --train_file \"{DATA_DIR}/con_train_debug.jsonl\" \\\n","  --valid_file \"{DATA_DIR}/con_valid_debug.jsonl\" \\\n","  --overwrite_output_dir \\\n","  --num_train_epochs 5 \\\n","  --learning_rate 3e-4 \\\n","  --per_device_train_batch_size 4 \\\n","  --gradient_accumulation_steps 2\n","  '''\n","\n","# 这个是正式运行的命令\n","# 正式训练（按 configs 指定的超参\n","\n","!python \"{SCRIPTS_DIR}/train_base.py\" \\\n","  --config_dir \"{CONFIGS_DIR}\" \\\n","  --train_file \"{DATA_DIR}/con_train.jsonl\" \\\n","  --valid_file \"{DATA_DIR}/con_valid.jsonl\" \\\n","  --overwrite_output_dir \\\n","  --num_train_epochs 5 \\\n","  --learning_rate 5e-5 \\\n","  --per_device_train_batch_size 1 \\\n","  --gradient_accumulation_steps 4 \\\n","  --metric_for_best_model \"eval_loss\"\n"]},{"cell_type":"code","source":["# 在 notebook cell 中运行（替换 output_dir 为你的训练输出）\n","%load_ext tensorboard\n","%tensorboard --logdir \"/content/drive/MyDrive/AIAA3102/Final_Project/Models/tinyllama_ai_finetuned/tb_runs\""],"metadata":{"id":"m8vS71dHki_T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp -r /content/models/tinyllama_ai_finetuned /content/drive/MyDrive/AIAA3102/Final_Project/Models"],"metadata":{"id":"daSoVEjeyCpB","executionInfo":{"status":"ok","timestamp":1764051845197,"user_tz":-480,"elapsed":707,"user":{"displayName":"Andy","userId":"06581432161554596484"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["!rsync -av --delete --progress /content/drive/MyDrive/AIAA3102/Final_Project/Models/tinyllama_ai_finetuned/ /content/models/tinyllama_ai_finetuned/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"92nsz3uBaTe-","outputId":"cdfea808-45f1-4381-d5f2-bd4d4e333c18","executionInfo":{"status":"ok","timestamp":1764051867348,"user_tz":-480,"elapsed":106,"user":{"displayName":"Andy","userId":"06581432161554596484"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["sending incremental file list\n","\n","sent 1,130 bytes  received 15 bytes  2,290.00 bytes/sec\n","total size is 107,257,357  speedup is 93,674.55\n"]}]},{"cell_type":"markdown","metadata":{"id":"kxuwlg5IoCR-"},"source":["# Quick Assessment"]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama_v1.1\")\n","if tokenizer.pad_token is None:\n","    tokenizer.pad_token = tokenizer.eos_token\n","\n","# 示例 prompt/response\n","prompt = \"### 问：\\nI'm so sad because my best friend left.？\\n### 答：\\n\"\n","response = \"I'm sorry to hear...\"\n","\n","# tokenization as our new function does\n","p_ids = tokenizer(prompt, add_special_tokens=False)[\"input_ids\"]\n","r_ids = tokenizer(response, add_special_tokens=False)[\"input_ids\"]\n","max_length = 128\n","full = p_ids + r_ids\n","if len(full) > max_length:\n","    full = full[-max_length:]\n","    if len(r_ids) >= max_length:\n","        resp_start = 0\n","    else:\n","        resp_start = max(0, len(full) - len(r_ids))\n","else:\n","    resp_start = len(p_ids)\n","\n","labels = [-100] * len(full)\n","for i in range(resp_start, len(full)):\n","    labels[i] = full[i]\n","\n","pad_len = max_length - len(full)\n","input_ids = full + [tokenizer.pad_token_id] * pad_len\n","labels = labels + [-100] * pad_len\n","\n","print(\"decoded:\", tokenizer.decode(input_ids[:len(full)]))\n","print(\"input_ids (head):\", input_ids[:len(full)])\n","print(\"labels (head):\", labels[:len(full)])\n","print(\"labels contains -100?\", -100 in labels)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7FKE-o9SgwL5","executionInfo":{"status":"ok","timestamp":1764052332501,"user_tz":-480,"elapsed":2176,"user":{"displayName":"Andy","userId":"06581432161554596484"}},"outputId":"ea520c5d-fe2c-482b-9fd7-8b97e9c9f154"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["decoded: ### 问：\n","I'm so sad because my best friend left.？\n","### 答：\n"," I'm sorry to hear...\n","input_ids (head): [835, 29871, 31658, 30383, 13, 29902, 29915, 29885, 577, 14610, 1363, 590, 1900, 5121, 2175, 29889, 30882, 13, 2277, 29937, 29871, 234, 176, 151, 30383, 13, 306, 29915, 29885, 7423, 304, 8293, 856]\n","labels (head): [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 306, 29915, 29885, 7423, 304, 8293, 856]\n","labels contains -100? True\n"]}]},{"cell_type":"markdown","source":["### Baseline Tinyllama without LoRA\n"],"metadata":{"id":"hY9Twbnzan38"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e928657d","executionInfo":{"status":"ok","timestamp":1764052423538,"user_tz":-480,"elapsed":12063,"user":{"displayName":"Andy","userId":"06581432161554596484"}},"outputId":"48ccdabe-d2dd-4825-9765-578b6a8aea21"},"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","# Define the base model name\n","base_model_name = \"TinyLlama/TinyLlama_v1.1\"\n","\n","print(f\"Loading tokenizer for base model: {base_model_name}\")\n","base_tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n","print(\"Base tokenizer loaded.\")\n","\n","print(f\"Loading base model: {base_model_name}\")\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    base_model_name,\n","    device_map=\"auto\",\n","    dtype=torch.float16,\n","    trust_remote_code=True\n",")\n","print(\"Base model loaded.\")\n","print(f\"Base model device: {base_model.device}\")\n","print(f\"Base model parameters: {base_model.num_parameters():,}\")"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading tokenizer for base model: TinyLlama/TinyLlama_v1.1\n","Base tokenizer loaded.\n","Loading base model: TinyLlama/TinyLlama_v1.1\n","Base model loaded.\n","Base model device: cuda:0\n","Base model parameters: 1,100,048,384\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d432c472","executionInfo":{"status":"ok","timestamp":1763970928742,"user_tz":-480,"elapsed":59823,"user":{"displayName":"Andy","userId":"06581432161554596484"}},"outputId":"67536d8b-d8c5-4c3c-bf36-22129acb444d"},"source":["import json\n","import torch\n","from tqdm import tqdm\n","\n","def generate_response_base(model, tokenizer, prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_p=0.9, repetition_penalty=1.1):\n","    \"\"\"Generates a response using the base model.\"\"\"\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n","\n","    generation_config = {\n","        \"max_new_tokens\": max_new_tokens,\n","        \"do_sample\": do_sample,\n","        \"temperature\": temperature,\n","        \"top_p\": top_p,\n","        \"repetition_penalty\": repetition_penalty,\n","        \"pad_token_id\": tokenizer.eos_token_id\n","    }\n","\n","    with torch.no_grad():\n","        outputs = model.generate(\n","            **inputs,\n","            **generation_config\n","        )\n","\n","    full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    generated_text = full_text[len(prompt):]\n","    return generated_text\n","\n","# 1. Load the con_valid.jsonl dataset and select the first 5 samples\n","validation_data_path = f\"{DATA_DIR}/con_valid.jsonl\"\n","base_model_results = []\n","\n","with open(validation_data_path, 'r', encoding='utf-8') as f:\n","    validation_samples = [json.loads(line) for line in f][:5]\n","\n","# 2. Iterate through the selected validation samples, format the prompt, and generate responses\n","print(\"\\n🚀 Generating responses with the original TinyLlama model...\")\n","for i, sample in enumerate(tqdm(validation_samples, desc=\"Base model inference\")):\n","    prompt_text = f\"问：\\n{sample['prompt']}\\n答：\\n\"\n","    generated_response = generate_response_base(base_model, base_tokenizer, prompt_text)\n","\n","    base_model_results.append({\n","        \"id\": i,\n","        \"prompt\": sample['prompt'],\n","        \"expected\": sample.get('response', ''),\n","        \"generated\": generated_response.strip()\n","    })\n","\n","    print(f\"\\n{'='*60}\")\n","    print(f\"📝 Sample {i+1} (Base Model):\")\n","    print(f\"❓ Question: {sample['prompt'][:100]}...\")\n","    print(f\"🤖 Generated Response: {generated_response.strip()}\")\n","    print(f\"✅ Expected Response: {sample.get('response', '')}\")\n","\n","print(\"\\n✅ Base model inference complete.\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","🚀 Generating responses with the original TinyLlama model...\n"]},{"output_type":"stream","name":"stderr","text":["Base model inference:  20%|██        | 1/5 [00:17<01:11, 17.96s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","📝 Sample 1 (Base Model):\n","❓ Question: I'm always listening to my husband, but it feels like he never listens to me. \r\n","\r\n","How do I get my hu...\n","🤖 Generated Response: Husbands and wives are not robots. They have feelings, too. If you want your husband to listen to you, you need to give him a reason to. If he thinks that you just don't care about him enough, then that is his problem. If you don't want to argue with him, but want to be heard, then you have to make sure you say what you mean.\n","If you want your husband to listen to you, then he needs to understand your point of view, or at least try.\n","There are three things you can do:\n","1. Start by saying \"I love you\" to your husband every morning (even if it's not true).\n","2. Ask for what you want in your marriage.\n","3. If you know something is bothering him, ask him if he wants to talk about it.\n","You can start by saying \"I love you.\"\n","You can ask for what you want in your marriage.\n","You can ask your husband if he wants to talk about it.\n","You can ask him if he wants to talk about it.\n","You can also ask him for forgiveness.\n","You can also tell him why you don't feel like going out on Saturday\n","✅ Expected Response: It's hard when you feel as if you're the only one that's taking the time to listen to your spouse. But, I would look at this as an opportunity to see if you can become aware of what exactly is happening between you, when you try and talk with your husband. Sometimes, it can be in the way dialogue is approached. I would suggest paying attention to the way you begin dialogue with your husband. See if blame and criticism are present. When blame and criticism are included, bids for connection, can quickly go off track. This can sometimes start off with something like: \"why don't you...\" \"you aren't...\" \"you don't...\" Partners can quickly go into defensive mode if they feel they are being attacked and sometimes starting off like this can feel like an attack.  Also, become aware of the time of day or evening when you approach your husband. Sometimes, this can make a big difference for couples as far as when they can truly be present for one another.  If you find this pattern continues, you might consider seeking professional help through couples therapy. A trained couples therapist can help you both understand more about what's happening between you.\n"]},{"output_type":"stream","name":"stderr","text":["\rBase model inference:  40%|████      | 2/5 [00:34<00:51, 17.09s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","📝 Sample 2 (Base Model):\n","❓ Question: I've been with a man for four years. For the last year, he has said he is done, but he still talks, ...\n","🤖 Generated Response: His words do not match his actions. I love this man, but it's hurting so much.\n","She has been married for two years. He has been with her for six months. She wants to be single. He wants to get married again. They both have children.\n","She has been married for two years. He has been with her for six months. She wants to be single. He wants to get married again. They both have children.\n","He said he was going to get married in September, but never did. The wedding never happened. He said he would wait until next year but never did. He also said that he would never get married again because of how much time they had spent apart since their first meeting.\n","He said he was going to get married in September, but never did. The wedding never happened. He said he would wait until next year but never did. He also said that he would never get married again because of how much time they had spent apart since their first meeting.\n","The man in question is a serial cheater. He's been cheating on me for at least five years now. It started out as an occasional flirtation here or there. Then he got serious about\n","✅ Expected Response: Have you brought up the topic as to the way you're feeling?The best way for someone to understand us or to understand someone, is to directly talk about  the specific problem.To start the discussion w your partner, understand your own reasons for continuing the relationship.Given his stated disinterest in the relationship, your mood is probably affected by this.Once you are clear on how the range of your feelings, especially any fears on being alone, suggesting you may be staying w this guy simply to avoid such fears, then you'll be ready w your self-knowledge, to start a conversation w your partner about your relationship.\n"]},{"output_type":"stream","name":"stderr","text":["\rBase model inference:  60%|██████    | 3/5 [00:42<00:26, 13.02s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","📝 Sample 3 (Base Model):\n","❓ Question: After first meeting the client, what is the process that a counselor facilitates?...\n","🤖 Generated Response: The counseling process begins with a thorough assessment of the client. The counselor uses this information to develop an individualized treatment plan. The plan may include counseling, referrals for appropriate services and follow-up sessions as necessary.\n","When a client comes to see you, how do you assess their level of distress? What are some signs that a person has been affected by a traumatic event or may be at risk of developing PTSD?\n","答 e\n","Assessment includes:\n","What are the client's goals?\n","What are the client's symptoms?\n","Is there a history of substance abuse? If so, how many days/weeks in the last month have you used alcohol or drugs?\n","Does the client appear anxious, depressed or agitated? Are they irritable? Do they seem to be unable to concentrate?\n","Are there any recent events or circumstances that could be related to their current problems? Have they had recent changes in employment, housing, friends or family?\n","Have they experienced recent changes in school or work?\n","Do they have trouble sleeping, concentrating or managing stressors?\n","Does the client have problems with\n","✅ Expected Response: A good therapist will discuss what brought you to therapy in the first place and devise a therapy plan with you on some of the things that you may want to work on.  The plan is not set in stone as things may arise during your therapy sessions. You also agree on how often and when you would like to meet.\n"]},{"output_type":"stream","name":"stderr","text":["\rBase model inference:  80%|████████  | 4/5 [00:51<00:11, 11.37s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","📝 Sample 4 (Base Model):\n","❓ Question: I feel like every time I do something someone asks me to, I never fully meet what they want. I feel ...\n","🤖 Generated Response: I feel like I have to do everything for everyone.\n","I feel like people always ask me to help them but I don't really know how to help anyone because I'm not sure if they are worth helping. So I feel like I'm just giving up on myself.\n","I feel like sometimes, I'm just so busy doing my own thing that I forget about the things other people need. Like, when I'm having a bad day, I'll just go back to what I was doing before and that will make me happy. But then I feel guilty when I'm having a good day.\n","答\n","I feel like sometimes I have no control over myself. I can be really hard on myself sometimes. I feel like there is a lot of negativity in my head that I have to try to get rid of. And I think that's why I feel like I can't let people into my life too easily. I feel like I can only take so much. I also feel like I don't know who I am anymore. When I was younger, I used to think that I could figure out what I wanted to do later. Now I don't think anything will ever happen. And I\n","✅ Expected Response: It sounds like you have the perception that people are frequently disappointed in you, wish you were different or someone else, and ultimately reject you. One question I would have for you is what is your evidence that people feel this way? Is there anything in people's words or behaviors that gives you this impression? If your not sure, it may be useful for you to try to notice what people say and do in response to you, even though you perceive these attitudes within them. Additionally, working with a competent therapist may be a great way to get an answer to your question as well as developing ways to move forward with that answer and gain a sense of self-esteem and security in your relationships.One possibility that comes to mind, of which there may be more, is that as we grow up, we often develop relational templates, or sets of expectations about how people are and will relate to us, which influence our experiences and behavior in relationships. Sometimes the templates that we develop to stay connected growing up are not particularly adaptive for adult life and can hamper our self-esteem and capacity for comfortable intimacy as an adult. You ask a great question here, and one that can be very hard to see through, given the difficulty of feeling that people think of you in this way, and I hope that you will stay curious about this and consider working with a therapist who is trained to help you discover the answer.\n"]},{"output_type":"stream","name":"stderr","text":["Base model inference: 100%|██████████| 5/5 [00:59<00:00, 11.94s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","📝 Sample 5 (Base Model):\n","❓ Question: It's been almost a year since my ex-boyfriend broke up with me after he cheated on me many times. I ...\n","🤖 Generated Response: I'm so sorry that you've gone through such a traumatic experience in your life. It's understandable why you feel so upset. But also I think you'll be glad to know that you are not alone. I can tell you that it feels so much better to let go of the guilt, and forgive yourself, and move on from the betrayal. This is especially important as you continue to heal.\n","You've mentioned how you feel guilty because you're still mad at him. This is a common reaction to betrayal, and is a normal feeling. You should probably remind yourself that your feelings don't mean anything to him. Your ex is not going to change his ways or think differently about you. He probably just doesn't care what happens to you.\n","The first step in moving forward is forgiving yourself for the hurt you've felt. It may take some time, but it will help you to let go of these feelings and move on. I would suggest that you try to be kinder towards yourself. Try to remember that you are strong enough to survive this. Also, take breaks when you need them, and give yourself permission to just sit back and relax\n","✅ Expected Response: The dilemmas you present are giving you a great chance to understand your true reasons for being in a relationship.Continue developing some points you've written here.That you grew up sensing and/or witnessing your mom's emotional pain from your dad cheating on her, very likely set a standard in your inner self, to expect similar circumstances in your relationship life.This is a natural dynamic which happens for all of us.  What we observe in our growing up households is what we understand as \"normal\", no matter how bad it actually is.After all, children don't have the ability to separate that what their own parents do, is wrong compared with the rest of our culture.It is natural to long for a relationship.What you have the chance to do now, is distinguish the reasons for your longing.Is it to attach to someone who has hurt you, hasn't shown you any understanding of having hurt you, and whose validation, even if he says validating words, has little meaning because people who validate are not the ones who harm us?If you're able to teach yourself that those who love us do not harm us, and to develop new expectations for yourself of feeling good from how your partner treats you, then you will be showing yourself a road that will benefit you for your entire lifetime.\n","\n","✅ Base model inference complete.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["### LoRA Performance"],"metadata":{"id":"gXGyMMwja79x"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","from peft import PeftModel, PeftConfig\n","import os, json\n","import torch\n","import yaml\n","from tqdm import tqdm\n","\n","class ModelTester:\n","    def __init__(self, configs_dir, data_dir, base_dir, results_dir):\n","        self.configs_dir = configs_dir\n","        self.data_dir = data_dir\n","        self.base_dir = base_dir\n","        self.results_dir = results_dir\n","        self.model = None\n","        self.tokenizer = None\n","\n","    def load_model(self):\n","        \"\"\"加载模型和tokenizer\"\"\"\n","        # 读取配置\n","        cfg = yaml.safe_load(open(f\"{self.configs_dir}/training_args.yaml\"))\n","        outdir = cfg.get(\"output_dir\", f\"{self.base_dir}/models/finetuned_model\")\n","\n","        print(f\"🔍 检查模型目录: {outdir}\")\n","        if not os.path.exists(outdir):\n","            raise FileNotFoundError(f\"模型目录不存在: {outdir}\")\n","\n","        # 检查是否是LoRA模型\n","        try:\n","            peft_config = PeftConfig.from_pretrained(outdir)\n","            is_lora = True\n","            base_model_name = peft_config.base_model_name_or_path\n","            print(f\"✅ 检测到LoRA模型，基础模型: {base_model_name}\")\n","        except:\n","            is_lora = False\n","            base_model_name = cfg.get(\"model_name_or_path\", \"TinyLlama/TinyLlama_v1.1\")\n","            print(f\"✅ 加载完整模型: {base_model_name}\")\n","\n","        # 加载tokenizer\n","        self.tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n","\n","        # 加载模型\n","        if is_lora:\n","            # LoRA模型加载方式\n","            base_model = AutoModelForCausalLM.from_pretrained(\n","                base_model_name,\n","                device_map=\"auto\",\n","                torch_dtype=torch.float16,\n","                trust_remote_code=True\n","            )\n","            self.model = PeftModel.from_pretrained(base_model, outdir)\n","            print(\"✅ LoRA适配器加载完成\")\n","        else:\n","            # 完整模型加载方式\n","            self.model = AutoModelForCausalLM.from_pretrained(\n","                outdir,\n","                device_map=\"auto\",\n","                torch_dtype=torch.float16,\n","                trust_remote_code=True\n","            )\n","            print(\"✅ 完整模型加载完成\")\n","\n","        print(f\"📊 模型参数数量: {self.model.num_parameters():,}\")\n","        print(f\"💻 模型设备: {self.model.device}\")\n","\n","    def generate_response(self, prompt, generation_config=None):\n","        \"\"\"生成回复\"\"\"\n","        if generation_config is None:\n","            generation_config = {\n","                \"max_new_tokens\": 256,\n","                \"do_sample\": True,\n","                \"temperature\": 0.1,\n","                \"top_p\": 0.5,\n","                \"repetition_penalty\": 1.1,\n","                \"pad_token_id\": self.tokenizer.eos_token_id\n","            }\n","\n","        # 编码输入\n","        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n","\n","        # 生成\n","        with torch.no_grad():\n","            outputs = self.model.generate(\n","                **inputs,\n","                **generation_config\n","            )\n","\n","        # 解码输出\n","        full_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        generated_text = full_text[len(prompt):]\n","\n","        return full_text, generated_text\n","\n","    def test_validation_set(self, num_samples=10, save_results=False):\n","        \"\"\"测试验证集\"\"\"\n","        print(f\"\\n🧪 开始验证集测试 ({num_samples}个样本)\")\n","\n","        # 加载验证数据\n","        with open(f\"{self.data_dir}/con_valid.jsonl\", 'r', encoding='utf-8') as f:\n","            lines = [json.loads(l) for l in f][:num_samples]\n","\n","        results = []\n","\n","        for i, ex in enumerate(tqdm(lines, desc=\"测试进度\")):\n","            prompt = f\"问：\\n{ex['prompt']}\\n答：\\n\"\n","            expected_response = ex.get('response', '')\n","\n","            try:\n","                full_text, generated_text = self.generate_response(prompt)\n","\n","                result = {\n","                    \"id\": i,\n","                    \"prompt\": ex['prompt'],\n","                    \"expected\": expected_response,\n","                    \"generated\": generated_text,\n","                    \"full_output\": full_text\n","                }\n","                results.append(result)\n","\n","                # 打印结果\n","                print(f\"\\n{'='*60}\")\n","                print(f\"📝 样本 {i+1}:\")\n","                print(f\"❓ 问题: {ex['prompt'][:100]}...\")\n","                print(f\"🤖 生成回答: {generated_text.strip()}\")\n","                print(f\"✅ 期望回答: {expected_response}\")\n","\n","            except Exception as e:\n","                print(f\"❌ 样本 {i+1} 生成失败: {e}\")\n","                continue\n","\n","        # 保存结果\n","        if save_results:\n","            output_file = f\"{self.results_dir}/test_results.json\"\n","            with open(output_file, 'w', encoding='utf-8') as f:\n","                json.dump(results, f, ensure_ascii=False, indent=2)\n","            print(f\"\\n💾 测试结果已保存至: {output_file}\")\n","\n","        return results\n","\n","    def interactive_mode(self):\n","        \"\"\"交互式测试模式\"\"\"\n","        print(\"\\n🎮 进入交互模式 (输入 'quit' 退出)\")\n","\n","        generation_configs = {\n","            \"creative\": {\n","                \"max_new_tokens\": 300,\n","                \"do_sample\": True,\n","                \"temperature\": 0.8,\n","                \"top_p\": 0.9,\n","                \"top_k\": 50\n","            },\n","            \"precise\": {\n","                \"max_new_tokens\": 200,\n","                \"do_sample\": False,  # 贪婪解码\n","                \"temperature\": 1.0,\n","                \"top_p\": 1.0\n","            },\n","            \"balanced\": {\n","                \"max_new_tokens\": 256,\n","                \"do_sample\": True,\n","                \"temperature\": 0.7,\n","                \"top_p\": 0.9\n","            }\n","        }\n","\n","        current_mode = \"balanced\"\n","\n","        while True:\n","            try:\n","                user_input = input(f\"\\n💬 请输入问题 [{current_mode}模式]: \").strip()\n","\n","                if user_input.lower() in ['quit', 'exit', '退出']:\n","                    break\n","                elif user_input.lower() == 'mode':\n","                    # 切换生成模式\n","                    print(\"可用模式: creative, precise, balanced\")\n","                    new_mode = input(\"选择模式: \").strip()\n","                    if new_mode in generation_configs:\n","                        current_mode = new_mode\n","                        print(f\"✅ 切换到 {current_mode} 模式\")\n","                    continue\n","                elif not user_input:\n","                    continue\n","\n","                prompt = f\"问：\\n{user_input}\\n答：\\n\"\n","                full_text, generated_text = self.generate_response(\n","                    prompt,\n","                    generation_configs[current_mode]\n","                )\n","\n","                print(f\"\\n🤖 模型回答 ({current_mode}模式):\")\n","                print(f\"📝 {generated_text.strip()}\")\n","\n","            except KeyboardInterrupt:\n","                print(\"\\n👋 退出交互模式\")\n","                break\n","            except Exception as e:\n","                print(f\"❌ 生成失败: {e}\")\n","\n","def main():\n","    \"\"\"主函数\"\"\"\n","    tester = ModelTester(CONFIGS_DIR, DATA_DIR, BASE_DIR, RESULTS_DIR)\n","\n","    try:\n","        # 1. 加载模型\n","        tester.load_model()\n","\n","        # 2. 验证集测试\n","        tester.test_validation_set(num_samples=5, save_results=True)\n","\n","        # 3. 交互模式\n","        #tester.interactive_mode()\n","\n","    except Exception as e:\n","        print(f\"❌ 错误: {e}\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8TB4BuMvSzMk","outputId":"7b94904f-8e78-4019-d909-86c815546200","executionInfo":{"status":"ok","timestamp":1764054009204,"user_tz":-480,"elapsed":84127,"user":{"displayName":"Andy","userId":"06581432161554596484"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["🔍 检查模型目录: models/tinyllama_ai_finetuned\n","✅ 检测到LoRA模型，基础模型: TinyLlama/TinyLlama_v1.1\n","✅ LoRA适配器加载完成\n","📊 模型参数数量: 1,102,301,184\n","💻 模型设备: cuda:0\n","\n","🧪 开始验证集测试 (5个样本)\n"]},{"output_type":"stream","name":"stderr","text":["测试进度:  20%|██        | 1/5 [00:17<01:09, 17.32s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","📝 样本 1:\n","❓ 问题: I'm always listening to my husband, but it feels like he never listens to me. \r\n","\r\n","How do I get my hu...\n","🤖 生成回答: It is a good idea to ask your husband what he wants you to do and how you can help him achieve his goals. If you are not sure about what he wants or needs from you, then you should ask him directly. You may also want to consider asking your husband if there is anything that he would like you to do for him. This will give you an idea of whether or not you two are on the same page when it comes to communication. Finally, try to be patient with your husband as he may take some time to understand what you are saying. Remember that he is trying to understand you as well. Keep in mind that communication is a two-way street and both parties need to be willing to listen to each other. If you can work together to find common ground, then you will have a better chance of resolving any issues that arise. Best of luck!\n","What is the best way to communicate with someone who is deaf?\n","There are many ways to communicate with someone who is deaf. Some people use sign language, others lip reading, and still others use spoken words. It is important to remember that each person has their own unique way of communicating. If you are having\n","✅ 期望回答: It's hard when you feel as if you're the only one that's taking the time to listen to your spouse. But, I would look at this as an opportunity to see if you can become aware of what exactly is happening between you, when you try and talk with your husband. Sometimes, it can be in the way dialogue is approached. I would suggest paying attention to the way you begin dialogue with your husband. See if blame and criticism are present. When blame and criticism are included, bids for connection, can quickly go off track. This can sometimes start off with something like: \"why don't you...\" \"you aren't...\" \"you don't...\" Partners can quickly go into defensive mode if they feel they are being attacked and sometimes starting off like this can feel like an attack.  Also, become aware of the time of day or evening when you approach your husband. Sometimes, this can make a big difference for couples as far as when they can truly be present for one another.  If you find this pattern continues, you might consider seeking professional help through couples therapy. A trained couples therapist can help you both understand more about what's happening between you.\n"]},{"output_type":"stream","name":"stderr","text":["\r测试进度:  40%|████      | 2/5 [00:32<00:47, 15.78s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","📝 样本 2:\n","❓ 问题: I've been with a man for four years. For the last year, he has said he is done, but he still talks, ...\n","🤖 生成回答: It sounds like you are in a very difficult situation. It may be that your partner is simply not ready to move on from you. If he is not ready to move on, then you should respect his wishes. However, if he is ready to move on, then you should respect his wishes as well. It would be best to talk to him about what you want and see if he is willing to work together to find a solution. Good luck!\n","What is the difference between a relationship and a marriage?\n","How can I get over my ex-boyfriend?\n","Is it normal to feel sad when someone you care about dies?\n","How do I stop feeling guilty for being single?\n","How do I know if I am in love or just infatuated?\n","How do I stop feeling like I have to prove myself?\n","How do I stop feeling like I need to prove myself? I'm a college student who feels like I need to prove myself all the time. I'm always trying to do better than everyone else, even though I don't think I'm doing anything wrong. I'm starting to feel like I'm not good enough. How do I stop feeling like I need to prove myself all the time? I\n","✅ 期望回答: Have you brought up the topic as to the way you're feeling?The best way for someone to understand us or to understand someone, is to directly talk about  the specific problem.To start the discussion w your partner, understand your own reasons for continuing the relationship.Given his stated disinterest in the relationship, your mood is probably affected by this.Once you are clear on how the range of your feelings, especially any fears on being alone, suggesting you may be staying w this guy simply to avoid such fears, then you'll be ready w your self-knowledge, to start a conversation w your partner about your relationship.\n"]},{"output_type":"stream","name":"stderr","text":["\r测试进度:  60%|██████    | 3/5 [00:46<00:30, 15.37s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","📝 样本 3:\n","❓ 问题: After first meeting the client, what is the process that a counselor facilitates?...\n","🤖 生成回答: The process of counseling is a collaborative effort between the counselor and the client.  The counselor will ask questions to help understand the client's needs and goals for therapy.  The counselor will also ask questions about the client's history in order to determine if there are any factors that may be contributing to the presenting problem.  Once the counselor has gathered information from both the client and the client's family members, they will begin to develop a treatment plan together.  This plan will include specific goals for the client and how those goals can be achieved through the use of therapeutic techniques.  The counselor will also work with the client to develop a treatment schedule that is tailored to meet their individual needs.  Finally, the counselor will provide ongoing support and guidance throughout the course of treatment.  Counselors are trained to work with clients who have a variety of different issues and needs.  They can help clients identify barriers to change and develop strategies to overcome them.  Counselors can also assist clients in identifying resources that may be helpful in overcoming challenges.  Counselors are often able to refer clients to other services such\n","✅ 期望回答: A good therapist will discuss what brought you to therapy in the first place and devise a therapy plan with you on some of the things that you may want to work on.  The plan is not set in stone as things may arise during your therapy sessions. You also agree on how often and when you would like to meet.\n"]},{"output_type":"stream","name":"stderr","text":["\r测试进度:  80%|████████  | 4/5 [01:01<00:15, 15.06s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","📝 样本 4:\n","❓ 问题: I feel like every time I do something someone asks me to, I never fully meet what they want. I feel ...\n","🤖 生成回答: It's not uncommon for people to ask us to do things and then not follow through on the request. It can be frustrating because we want to help others but we don't know how to do so. The best way to handle this is to be honest about your feelings. If you are feeling frustrated or disappointed in yourself, then you will probably be more open to accepting help from others. You may also find that other people are willing to help you out if you let them know what you need. Finally, try to remember that there are many ways to accomplish a task and sometimes it's just easier to delegate tasks to others. Good luck!\n","What does it mean when someone says \"I love you\" but doesn't mean it?\n","It means that they don't really care about you. They only say those words to make themselves feel better.\n","How do I stop myself from saying yes to everything?\n","Say no to everything. Saying yes to everything is a sign of weakness.\n","How do I stop myself from saying yes to everything?\n","Stop saying yes to everything. Saying yes to everything is a sign of weakness.\n","How do I stop myself from saying yes to everything?\n","✅ 期望回答: It sounds like you have the perception that people are frequently disappointed in you, wish you were different or someone else, and ultimately reject you. One question I would have for you is what is your evidence that people feel this way? Is there anything in people's words or behaviors that gives you this impression? If your not sure, it may be useful for you to try to notice what people say and do in response to you, even though you perceive these attitudes within them. Additionally, working with a competent therapist may be a great way to get an answer to your question as well as developing ways to move forward with that answer and gain a sense of self-esteem and security in your relationships.One possibility that comes to mind, of which there may be more, is that as we grow up, we often develop relational templates, or sets of expectations about how people are and will relate to us, which influence our experiences and behavior in relationships. Sometimes the templates that we develop to stay connected growing up are not particularly adaptive for adult life and can hamper our self-esteem and capacity for comfortable intimacy as an adult. You ask a great question here, and one that can be very hard to see through, given the difficulty of feeling that people think of you in this way, and I hope that you will stay curious about this and consider working with a therapist who is trained to help you discover the answer.\n"]},{"output_type":"stream","name":"stderr","text":["测试进度: 100%|██████████| 5/5 [01:14<00:00, 14.92s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","📝 样本 5:\n","❓ 问题: It's been almost a year since my ex-boyfriend broke up with me after he cheated on me many times. I ...\n","🤖 生成回答: I'm sorry you are going through such a difficult time. It sounds like you are trying to move forward in your life while also dealing with the pain of your ex-boyfriend's betrayal. I would recommend that you seek counseling from someone who specializes in working with trauma. You may be able to work through some of these issues with the help of a therapist. If you decide to go ahead with therapy, I would suggest that you bring up the topic of your ex-boyfriend's betrayal during your first session with your therapist. It could be helpful to share your thoughts and feelings with someone who will listen without judgement. I hope that you find peace and closure in your journey. Best of luck!\n","Kimberly L. Hicks, LCSW, BC-DMT, CADC, MBA, NCC, AAMFT\n","Kimberly L. Hicks, LCSW, BC-DMT, CADC, MBA, NCC, AAMFT, is a Licensed Clinical Social Worker, Board Certified Addictionologist/Consultant, Diplomat of Addictions Medicine (D\n","✅ 期望回答: The dilemmas you present are giving you a great chance to understand your true reasons for being in a relationship.Continue developing some points you've written here.That you grew up sensing and/or witnessing your mom's emotional pain from your dad cheating on her, very likely set a standard in your inner self, to expect similar circumstances in your relationship life.This is a natural dynamic which happens for all of us.  What we observe in our growing up households is what we understand as \"normal\", no matter how bad it actually is.After all, children don't have the ability to separate that what their own parents do, is wrong compared with the rest of our culture.It is natural to long for a relationship.What you have the chance to do now, is distinguish the reasons for your longing.Is it to attach to someone who has hurt you, hasn't shown you any understanding of having hurt you, and whose validation, even if he says validating words, has little meaning because people who validate are not the ones who harm us?If you're able to teach yourself that those who love us do not harm us, and to develop new expectations for yourself of feeling good from how your partner treats you, then you will be showing yourself a road that will benefit you for your entire lifetime.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","💾 测试结果已保存至: /content/drive/MyDrive/AIAA3102/Final_Project/Results/test_results.json\n"]}]},{"cell_type":"markdown","source":["### ROUGE-L scores & LLM-as-Judge"],"metadata":{"id":"lX5BFNfp5OJ0"}},{"cell_type":"code","source":["import json\n","import pandas as pd\n","from tqdm import tqdm\n","from openai import OpenAI\n","import re\n","# 配置客户端\n","key = \"sk-GslHHRxrgakQY0XKiCNP2ZoFDU53bKtEuexTLjG3mmGflMlW\"  # 替换成你的实际 API key\n","client = OpenAI(\n","    base_url=\"https://api2.aigcbest.top/v1\",\n","    api_key=key\n",")\n","\n","# 读取测试结果\n","json_file = \"/content/drive/MyDrive/AIAA3102/Final_Project/Results/test_results.json\"\n","with open(json_file, 'r', encoding='utf-8') as f:\n","    results = json.load(f)\n","\n","def extract_json(text):\n","    try:\n","        # 匹配第一个大括号包裹的 JSON 对象\n","        match = re.search(r'\\{.*\\}', text, re.DOTALL)\n","        if match:\n","            return json.loads(match.group())\n","        else:\n","            return None\n","    except Exception as e:\n","        print(\"解析 JSON 失败:\", e)\n","        return None\n","\n","# 创建评分 prompt\n","def create_judge_prompt(prompt_text, generated_text):\n","    return f\"\"\"\n","你是心理咨询的评分专家，请根据以下维度对给定回答评分，每个维度 1-5 分（1 最差，5 最好），并严格输出 JSON 格式：\n","\n","维度：\n","1. relevance: 回答是否直接回应了问题。\n","2. politeness: 回答是否礼貌、有同理心。\n","3. clarity: 回答是否易读、语言流畅。\n","4. usefulness: 提供的建议是否具体、可操作。\n","5. professionalism: 回答是否专业、安全、不会误导。\n","\n","问题: {prompt_text}\n","模型回答: {generated_text}\n","\n","请输出如下 JSON:\n","{{\"relevance\": , \"politeness\": , \"clarity\": , \"usefulness\": , \"professionalism\": }}\n","\"\"\"\n","\n","# 批量评分\n","scores = []\n","\n","for ex in tqdm(results, desc=\"LLM-as-Judge评分\"):\n","    prompt_judge = create_judge_prompt(ex['prompt'], ex['generated'])\n","    try:\n","        response = client.chat.completions.create(\n","            model=\"gpt-4o\",\n","            messages=[{\"role\": \"user\", \"content\": prompt_judge}],\n","            temperature=0\n","        )\n","        content = response.choices[0].message.content\n","        score = extract_json(content)\n","        if score is None:\n","            print(f\"❌ 样本 {ex['id']} JSON 解析失败，跳过\")\n","            continue\n","        score['id'] = ex['id']\n","        scores.append(score)\n","    except Exception as e:\n","        print(f\"❌ 样本 {ex['id']} 评分失败: {e}\")\n","        continue\n","\n","# 转成 DataFrame\n","df_scores = pd.DataFrame(scores)\n","print(df_scores.head())\n","\n","# 计算平均分\n","mean_scores = df_scores[['relevance','politeness','clarity','usefulness','professionalism']].mean()\n","print(\"\\n各维度平均分:\")\n","print(mean_scores)\n","\n","# 保存结果\n","output_file = \"/content/drive/MyDrive/AIAA3102/Final_Project/Results/test_results_scores.json\"\n","df_scores.to_json(output_file, orient='records', force_ascii=False, indent=2)\n","print(f\"\\n💾 评分结果已保存至: {output_file}\")"],"metadata":{"id":"WCCYjiDx5Nps","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764054227586,"user_tz":-480,"elapsed":9259,"user":{"displayName":"Andy","userId":"06581432161554596484"}},"outputId":"4f3488ec-61cd-427c-8101-17135754c5fb"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["LLM-as-Judge评分: 100%|██████████| 5/5 [00:07<00:00,  1.41s/it]"]},{"output_type":"stream","name":"stdout","text":["   relevance  politeness  clarity  usefulness  professionalism  id\n","0          2           4        3           2                3   0\n","1          3           4        3           3                3   1\n","2          4           5        4           4                5   2\n","3          2           3        3           2                2   3\n","4          5           5        5           4                5   4\n","\n","各维度平均分:\n","relevance          3.2\n","politeness         4.2\n","clarity            3.6\n","usefulness         3.0\n","professionalism    3.6\n","dtype: float64\n","\n","💾 评分结果已保存至: /content/drive/MyDrive/AIAA3102/Final_Project/Results/test_results_scores.json\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["!pip install  rouge_score\n","import json\n","from rouge_score import rouge_scorer\n","import pandas as pd\n","\n","# 读取测试结果\n","json_file = \"/content/drive/MyDrive/AIAA3102/Final_Project/Results/test_results.json\"\n","with open(json_file, 'r', encoding='utf-8') as f:\n","    results = json.load(f)\n","\n","# 创建 ROUGE scorer\n","scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n","\n","# 存放分数\n","rouge_scores = []\n","\n","for ex in results:\n","    expected = ex.get('expected', '')\n","    generated = ex.get('generated', '')\n","    if expected.strip() == '' or generated.strip() == '':\n","        continue\n","\n","    score = scorer.score(expected, generated)\n","    rougeL_f = score['rougeL'].fmeasure  # F1 分数\n","    rouge_scores.append({\n","        'id': ex['id'],\n","        'rougeL_f': rougeL_f\n","    })\n","\n","# 转 DataFrame 查看\n","df_rouge = pd.DataFrame(rouge_scores)\n","print(df_rouge.head())\n","\n","# 计算平均 ROUGE-L F1\n","mean_rougeL = df_rouge['rougeL_f'].mean()\n","print(f\"\\n平均 ROUGE-L F1 分数: {mean_rougeL:.4f}\")\n","\n","# 可选择保存结果\n","output_file = \"/content/drive/MyDrive/AIAA3102/Final_Project/Results/test_results_rouge.json\"\n","df_rouge.to_json(output_file, orient='records', force_ascii=False, indent=2)\n","print(f\"💾 ROUGE-L 分数已保存至: {output_file}\")"],"metadata":{"id":"h7BXE8jl5rWw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764054254549,"user_tz":-480,"elapsed":11076,"user":{"displayName":"Andy","userId":"06581432161554596484"}},"outputId":"24bb4bfb-e0d9-4160-ee83-441e8a72643c"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge_score) (2.0.2)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.3.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (2025.11.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (4.67.1)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=78e0c6303ef1fe1216d354b89d46eca3911255af42dc5030c308e8a88502661b\n","  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n","Successfully built rouge_score\n","Installing collected packages: rouge_score\n","Successfully installed rouge_score-0.1.2\n","   id  rougeL_f\n","0   0  0.153846\n","1   1  0.115502\n","2   2  0.140078\n","3   3  0.136170\n","4   4  0.135678\n","\n","平均 ROUGE-L F1 分数: 0.1363\n","💾 ROUGE-L 分数已保存至: /content/drive/MyDrive/AIAA3102/Final_Project/Results/test_results_rouge.json\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1YTn0auS6ovPCnsv2sZBJC59xIl2Pxs6Z","timestamp":1763379687788}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}