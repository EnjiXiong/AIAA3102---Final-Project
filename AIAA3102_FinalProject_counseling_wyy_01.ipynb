{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PawYFNTou8lw"
      },
      "source": [
        "# Run train_base.py (LoRA / QLoRA) from Drive\n",
        "本 Notebook 包含以下步骤：\n",
        "1. 挂载 Google Drive（读取你已保存的 train_base.py / Configs / Data）\n",
        "2. 安装依赖（transformers, datasets, peft, bitsandbytes, accelerate, huggingface_hub）\n",
        "3. 设置 HF_TOKEN（从 Colab Secrets / 交互输入）\n",
        "4. 做一个小规模 debug 子集并运行 train_base.py 进行快速 smoke-test\n",
        "5.（可选）运行完整训练"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-zMdRtmvJPf",
        "outputId": "d6f41dd3-869b-4d2f-90fd-2dbb5732344b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "BASE_DIR = /content/drive/MyDrive/AIAA3102/Final_Project\n",
            "total 118\n",
            "-rw------- 1 root root 75085 Nov  9 11:45 AIAA3102-FinalProject_Awareness_Ignorance.ipynb\n",
            "drwx------ 2 root root  4096 Nov 13 10:19 Configs\n",
            "drwx------ 2 root root  4096 Nov 13 10:19 Data\n",
            "-rw------- 1 root root  8196 Nov 13 08:01 .DS_Store\n",
            "drwx------ 2 root root  4096 Nov 14 09:53 Models\n",
            "drwx------ 2 root root  4096 Nov 13 10:19 Scripts\n",
            "-rw------- 1 root root 20387 Nov 24 09:06 test_results.json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# 修改为你自己的项目根目录（与 train_base.py 写入位置一致）\n",
        "BASE_DIR = \"/content/drive/MyDrive/AIAA3102/Final_Project\"   # <- 如果各位的路径不同，请修改\n",
        "SCRIPTS_DIR = f\"{BASE_DIR}/Scripts\"\n",
        "CONFIGS_DIR = f\"{BASE_DIR}/Configs\"\n",
        "DATA_DIR = f\"{BASE_DIR}/Data\"\n",
        "MODELS_DIR = f\"{BASE_DIR}/Models\"\n",
        "RESULTS_DIR = f\"{BASE_DIR}/Results\"\n",
        "\n",
        "print(\"BASE_DIR =\", BASE_DIR)\n",
        "!ls -la \"{BASE_DIR}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss8UocMimzA5"
      },
      "source": [
        "# Install dependencies and import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rqURByA6msI4",
        "outputId": "8c1e461c-78fa-48cb-d73b-9af1c0ac2d4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.9.0+cu126)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
            "Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.48.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets peft bitsandbytes accelerate huggingface_hub\n",
        "# 需要一乃乃时间"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHnE5d2fvX2T"
      },
      "source": [
        "# Check Cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PutlfsRnEHM",
        "outputId": "38ae7225-a0c7-44c0-9757-9c48584aae71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import bitsandbytes as bnb\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ9W8JJpnIB6"
      },
      "source": [
        "# Ensure the configs/script/py files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "a-L2JXlAnUW0",
        "outputId": "98ab7109-06d7-4695-8c35-2732bdc9b912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "script exists: True /content/drive/MyDrive/AIAA3102/Final_Project/Scripts/train_base.py\n",
            "configs exists: True /content/drive/MyDrive/AIAA3102/Final_Project/Configs\n",
            "train exists: True /content/drive/MyDrive/AIAA3102/Final_Project/Data/con_train.jsonl\n",
            "valid exists: True /content/drive/MyDrive/AIAA3102/Final_Project/Data/con_valid.jsonl\n",
            "unknown exists: True /content/drive/MyDrive/AIAA3102/Final_Project/Data/con_unknown_test.jsonl\n",
            "\n",
            "--- train.jsonl (first 3 lines) ---\n",
            "{\"prompt\": \"I have suffered many things at home and school. We never went to the doctor to diagnose depression or anything like that, but I always feel like a part of my heart is missing. I try to fill it in with objects or, in this case, a woman.\", \"response\": \"There are a lot of ways to look at this. It sounds as if there is a part of you that is looking for support. I wonder what it is that you feel when you're not in a relationship?Because of the way you asked the question, I'm getting the impression that you are referring to romantic relationships. I wonder if you have close friendships that could form a network to help with this when you are not romantically involved with someone. Even when you are in a relationship with a romantic partner, having friends is still an important element.I wonder if you could also notice what changes for you inside of yourself (as far as emotions) when you move from not being in a relationship to being in one.Perhaps you could take a look at what you value about yourself.In general, it is natural for people to want to be in relationships with others (in this case, relationship has many meanings and degrees). Most of us enjoy sharing elements of our days, thoughts, feelings, etc. with someone else who we trust and care about – also hoping they care about us in return.\"}\n",
            "{\"prompt\": \"I feel like I hate myself physically and emotionally sometimes. How can I start accepting myself and be more confident?\", \"response\": \"Self-doubt and self-hatred are such common and unpleasant experiences and really worth  understanding! Therapy with the right person can really help. When in your life do you feel the most confident? What gets in the way of you accepting and loving yourself (big question!). You can and will uncover that confident self!\"}\n",
            "{\"prompt\": \"I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?\", \"response\": \"Feelings of worthlessness often originate  from what you learned about yourself when you were young. Improving your self esteem needs focus on that original message from parents, teachers or siblings that may be suppressed.  Most of us need help to uncover the \\\"lie\\\" because you were born valuable!\"}\n",
            "\n",
            "--- configs (list) ---\n",
            "total 7\n",
            "-rw------- 1 root root 3932 Nov 26 13:41 eval_config.yaml\n",
            "-rw------- 1 root root  814 Nov  9 11:58 model_config.yaml\n",
            "-rw------- 1 root root 1704 Nov 26 15:11 training_args.yaml\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "paths = {\n",
        "    \"script\": f\"{SCRIPTS_DIR}/train_base.py\",\n",
        "    \"configs\": CONFIGS_DIR,\n",
        "    \"train\": f\"{DATA_DIR}/con_train.jsonl\",\n",
        "    \"valid\": f\"{DATA_DIR}/con_valid.jsonl\",\n",
        "    \"unknown\": f\"{DATA_DIR}/con_unknown_test.jsonl\",\n",
        "}\n",
        "for k, p in paths.items():\n",
        "    print(k, \"exists:\", os.path.exists(p), p)\n",
        "\n",
        "# 打印前几行检查\n",
        "print(\"\\n--- train.jsonl (first 3 lines) ---\")\n",
        "!head -n 3 \"{paths['train']}\"\n",
        "print(\"\\n--- configs (list) ---\")\n",
        "!ls -la \"{CONFIGS_DIR}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAcnlA-CnW7b"
      },
      "source": [
        "# Debug Dataset Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsXvVXkHneIV",
        "outputId": "16648eaf-fb5c-4199-9a5d-a6d9f775b681"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Debug subsets created: /content/drive/MyDrive/AIAA3102/Final_Project/Data/con_train_debug.jsonl /content/drive/MyDrive/AIAA3102/Final_Project/Data/con_valid_debug.jsonl\n",
            "   20 /content/drive/MyDrive/AIAA3102/Final_Project/Data/con_train_debug.jsonl\n",
            "   10 /content/drive/MyDrive/AIAA3102/Final_Project/Data/con_valid_debug.jsonl\n",
            "   30 total\n"
          ]
        }
      ],
      "source": [
        "# Create tiny debug subsets to run a quick smoke-test (avoid long runs)\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "p_data = Path(DATA_DIR)\n",
        "debug_train = p_data / \"con_train_debug.jsonl\"\n",
        "debug_valid = p_data / \"con_valid_debug.jsonl\"\n",
        "\n",
        "def subset(src, dst, n=20):\n",
        "    with open(src, 'r', encoding='utf-8') as rf, open(dst, 'w', encoding='utf-8') as wf:\n",
        "        for i, line in enumerate(rf):\n",
        "            if i >= n:\n",
        "                break\n",
        "            wf.write(line)\n",
        "\n",
        "subset(paths[\"train\"], debug_train, n=20)\n",
        "subset(paths[\"valid\"], debug_valid, n=10)\n",
        "print(\"Debug subsets created:\", debug_train, debug_valid)\n",
        "!wc -l \"{debug_train}\" \"{debug_valid}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_AzrivIu7aC"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA6O5hegn2Eh"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dSOKLOBvaZX_",
        "outputId": "29334551-0ef1-4b17-961b-37d868e15291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (7.7.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (3.0.16)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.5.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.9.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.23.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.14)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.5.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.3)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.25.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.29.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.12/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.14.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.23)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.11.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.0.3)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.1)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.10.0)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.12/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2025.2)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi\n",
            "Successfully installed jedi-0.19.2\n"
          ]
        }
      ],
      "source": [
        "# 安装额外依赖\n",
        "!pip install ipywidgets matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "038d4ef87fa74c53b9416ed79dd0c4ab",
            "2350a57bb4514b9b9d5e0f7899c275ff",
            "ee5a096e552d417286b6c8a1f1fe7556",
            "a6a6a8e9f59e4578977ca441a621106e",
            "70dba67ec3224f8fb8b839914d716d47",
            "e915826245a243609d91de4dfecc4d39",
            "ec60bfb2332a494bae0b4fd1d9fcf170",
            "d0528b1f7b3b46c6909b1d0047f88bfe",
            "73d449953c45453aa100920eac9b5469",
            "49bfb3bb49454f499ae9492247e7a0c0",
            "0b2df86222f2418c8fa24c809588e078",
            "41bb550430984750a3714be37bea1fa6",
            "f3a3777eab014b6a8388d4a2addfbad5",
            "bca27627895c4eefbfc0e42f673ed1f8",
            "02bda5ae65ff49eca7ca9d85dc9f9fde",
            "d3c9668541634b68a038513ab04552bd",
            "b07218a34540494aa195ebfd5b117bba",
            "df2d7d6a1709475bb016d350f0dfb9cd",
            "f7cc58c0e36240498cc59f30f3613235",
            "d8f95ea53f43460386e534c7a7e388d2",
            "e1f2226b7c234302b49f703b7166ba24",
            "4ac69b286b71499e84ba2c9bf53842dc",
            "ba22222804bf439da3da75e78db8f348",
            "ee9f854d85b4403e814345e8d74140ce",
            "74a1353dea3141289ecd823b3671dcf4",
            "d44339678a37423791602eb36c905b56",
            "29b9be4a3a1e42d2ab6eeb2bd5e0a6b1",
            "0a9704453b534214b7a07e289d61df91",
            "f5b2ce7a3f1344478c7352e1f1503da1",
            "572bf87b5da742eba8952e23ef05032a",
            "17a4f2b608ce467f8ad739ac1d59de7f",
            "87be1bb561b24cb9a061057fdae60943",
            "72e983d4a9474273b88638913e061559",
            "23c37f2b497041d8a0471787969287f0",
            "5b0ccc7ee64f4e8d84a6c6768c2b3d3b",
            "f0d9ff174aec4f708024cfe21b8cd2cd",
            "3e42affd65cc4861a79e56fefe7b174d",
            "88bece3f7fcb4ca7b24d5a5a871bab94",
            "7a64d68638a74f35bb8897de18fbb620",
            "8bd0aaf4a7c142d2aa49c35b2ef3e91c",
            "ee43947fabab441a9fab251869d6e850",
            "d8c25d93cc89478b9688b2f6d68b2f39",
            "af98cedb370540b890087f101039e06d",
            "bb97041f5ae34eaa8a90c9d1f2ad97a0",
            "b59cbf828c114d7bb8ba29d8a8c7cf7b",
            "94e1f99aa8a443ca9e2036d2f3ec9d1f",
            "f7e46686608e4a4abb84952aadf42fc3",
            "c21200208c1147f1b3e555aa562278c3",
            "d6e9cb3ff487403586f30a9c329e478a",
            "240c090bdf8048369f792170d6d7e41d",
            "63c426670e094dcbbb1e0653596addb4",
            "251197c8bf6d475d8eb824198507000c",
            "f05146921d504673b745e9a0a619613e"
          ]
        },
        "id": "-3b9H-o-aZX_",
        "outputId": "73d5e85d-49aa-4ac6-8988-9e6ae9d47310"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Tab(children=(VBox(children=(IntSlider(value=5, description='epoch:', max=20, min=1, style=Slid…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "038d4ef87fa74c53b9416ed79dd0c4ab"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import yaml\n",
        "import json\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "import traceback\n",
        "import signal\n",
        "import os\n",
        "import re\n",
        "\n",
        "class TrainingConfigGUI:\n",
        "    def __init__(self, configs_dir):\n",
        "        self.configs_dir = Path(configs_dir)\n",
        "        self.widgets = {}\n",
        "        self.output = widgets.Output()\n",
        "\n",
        "    def load_configs(self):\n",
        "        \"\"\"加载现有配置\"\"\"\n",
        "        training_cfg = yaml.safe_load(open(self.configs_dir / \"training_args.yaml\"))\n",
        "        model_cfg = yaml.safe_load(open(self.configs_dir / \"model_config.yaml\"))\n",
        "        return training_cfg, model_cfg\n",
        "\n",
        "    def create_widgets(self):\n",
        "        \"\"\"创建交互式控件\"\"\"\n",
        "        training_cfg, model_cfg = self.load_configs()\n",
        "\n",
        "        # 基础训练参数\n",
        "        self.widgets['num_train_epochs'] = widgets.IntSlider(\n",
        "            value=training_cfg.get('num_train_epochs', 3),\n",
        "            min=1, max=20, step=1,\n",
        "            description='epoch:',\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "\n",
        "        self.widgets['learning_rate'] = widgets.FloatLogSlider(\n",
        "            value=training_cfg.get('learning_rate', 5e-5),\n",
        "            base=10, min=-6, max=-3,\n",
        "            description='learning rate:',\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "\n",
        "        self.widgets['per_device_train_batch_size'] = widgets.IntSlider(\n",
        "            value=training_cfg.get('per_device_train_batch_size', 2),\n",
        "            min=1, max=16, step=1,\n",
        "            description='batch size:',\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "\n",
        "        self.widgets['gradient_accumulation_steps'] = widgets.IntSlider(\n",
        "            value=training_cfg.get('gradient_accumulation_steps', 1),\n",
        "            min=1, max=16, step=1,\n",
        "            description='gradient accumulation steps:',\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "\n",
        "        # LoRA参数\n",
        "        lora_cfg = training_cfg.get('lora', {})\n",
        "        self.widgets['use_lora'] = widgets.Checkbox(\n",
        "            value=lora_cfg.get('use_lora', True),\n",
        "            description='Use LoRA',\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "\n",
        "        self.widgets['lora_rank'] = widgets.IntSlider(\n",
        "            value=lora_cfg.get('r', 8),\n",
        "            min=4, max=64, step=4,\n",
        "            description='LoRA rank:',\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "\n",
        "        self.widgets['lora_alpha'] = widgets.IntSlider(\n",
        "            value=lora_cfg.get('lora_alpha', 32),\n",
        "            min=8, max=128, step=8,\n",
        "            description='LoRA Alpha:',\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "\n",
        "        # QLoRA参数\n",
        "        qlora_cfg = training_cfg.get('qlora', {})\n",
        "        self.widgets['use_qlora'] = widgets.Checkbox(\n",
        "            value=qlora_cfg.get('use_qlora', False),\n",
        "            description='Use QLoRA (4-bit)',\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "\n",
        "        # 数据参数\n",
        "        self.widgets['max_train_samples'] = widgets.IntText(\n",
        "            value=1000,\n",
        "            description='Max Train Samples:',\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "\n",
        "        self.widgets['max_eval_samples'] = widgets.IntText(\n",
        "            value=100,\n",
        "            description='Max Eval Samples:',\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "\n",
        "        # 执行按钮\n",
        "        self.widgets['run_button'] = widgets.Button(\n",
        "            description='Start Training',\n",
        "            button_style='success',\n",
        "            icon='rocket'\n",
        "        )\n",
        "        self.widgets['run_button'].on_click(self.run_training)\n",
        "\n",
        "        # 保存配置按钮\n",
        "        self.widgets['save_button'] = widgets.Button(\n",
        "            description='Save Settings',\n",
        "            button_style='info',\n",
        "            icon='save'\n",
        "        )\n",
        "        self.widgets['save_button'].on_click(self.save_configs)\n",
        "\n",
        "        self.widgets['stop_button'] = widgets.Button(\n",
        "            description='Stop Training',\n",
        "            button_style='danger',\n",
        "            icon='stop',\n",
        "            disabled=True  # 初始时禁用\n",
        "        )\n",
        "        self.widgets['stop_button'].on_click(self.stop_training)\n",
        "\n",
        "        self.training_process = None\n",
        "        self.is_training = False\n",
        "\n",
        "    def display_gui(self):\n",
        "        \"\"\"显示GUI界面\"\"\"\n",
        "        self.create_widgets()\n",
        "\n",
        "        # 组织布局\n",
        "        training_params = widgets.VBox([\n",
        "            self.widgets['num_train_epochs'],\n",
        "            self.widgets['learning_rate'],\n",
        "            self.widgets['per_device_train_batch_size'],\n",
        "            self.widgets['gradient_accumulation_steps'],\n",
        "        ])\n",
        "\n",
        "        lora_params = widgets.VBox([\n",
        "            self.widgets['use_lora'],\n",
        "            self.widgets['lora_rank'],\n",
        "            self.widgets['lora_alpha'],\n",
        "            self.widgets['use_qlora'],\n",
        "        ])\n",
        "\n",
        "        data_params = widgets.VBox([\n",
        "            self.widgets['max_train_samples'],\n",
        "            self.widgets['max_eval_samples'],\n",
        "        ])\n",
        "\n",
        "        buttons = widgets.HBox([\n",
        "            self.widgets['run_button'],\n",
        "            self.widgets['stop_button'],\n",
        "            self.widgets['save_button']\n",
        "        ])\n",
        "\n",
        "        # 使用选项卡组织界面\n",
        "        tab = widgets.Tab()\n",
        "        tab.children = [training_params, lora_params, data_params]\n",
        "        tab.set_title(0, 'Training Parameters')\n",
        "        tab.set_title(1, 'LoRA Parameters')\n",
        "        tab.set_title(2, 'Data Parameters')\n",
        "\n",
        "        # 显示界面\n",
        "        display(widgets.VBox([tab, buttons, self.output]))\n",
        "\n",
        "    def save_configs(self, button):\n",
        "        \"\"\"保存配置到文件\"\"\"\n",
        "        with self.output:\n",
        "            clear_output()\n",
        "\n",
        "            # 更新配置\n",
        "            training_cfg, model_cfg = self.load_configs()\n",
        "\n",
        "            # 更新训练参数\n",
        "            training_cfg['num_train_epochs'] = self.widgets['num_train_epochs'].value\n",
        "            training_cfg['learning_rate'] = self.widgets['learning_rate'].value\n",
        "            training_cfg['per_device_train_batch_size'] = self.widgets['per_device_train_batch_size'].value\n",
        "            training_cfg['gradient_accumulation_steps'] = self.widgets['gradient_accumulation_steps'].value\n",
        "\n",
        "            # 更新LoRA参数\n",
        "            training_cfg['lora']['use_lora'] = self.widgets['use_lora'].value\n",
        "            training_cfg['lora']['r'] = self.widgets['lora_rank'].value\n",
        "            training_cfg['lora']['lora_alpha'] = self.widgets['lora_alpha'].value\n",
        "            training_cfg['qlora']['use_qlora'] = self.widgets['use_qlora'].value\n",
        "\n",
        "            # 保存文件\n",
        "            with open(self.configs_dir / \"training_args.yaml\", 'w') as f:\n",
        "                yaml.dump(training_cfg, f, default_flow_style=False)\n",
        "\n",
        "            print(\"✅ Settings Saved!\")\n",
        "    def format_training_line(self, line, current_epoch):\n",
        "      \"\"\"格式化训练输出，移除重复信息\"\"\"\n",
        "      line = line.strip()\n",
        "\n",
        "      # 过滤掉不必要的信息\n",
        "      if not line:\n",
        "          return None\n",
        "\n",
        "      # 过滤掉缓存警告（只显示一次）\n",
        "      if 'use_cache=True' in line and 'incompatible' in line:\n",
        "          if not hasattr(self, 'cache_warning_shown'):\n",
        "              self.cache_warning_shown = True\n",
        "              return \"⚠️ \" + line + \"\\n\"\n",
        "          return None\n",
        "\n",
        "      # 进度百分比跟踪\n",
        "      if '%|' in line:\n",
        "          percent_match = re.search(r'(\\d+)%\\|', line)\n",
        "          if percent_match:\n",
        "              current_percent = int(percent_match.group(1))\n",
        "\n",
        "              # 初始化\n",
        "              if not hasattr(self, 'last_percent'):\n",
        "                  self.last_percent = -1\n",
        "\n",
        "              # 过滤重复百分比\n",
        "              if current_percent == self.last_percent:\n",
        "                  return None\n",
        "\n",
        "              # 更新并显示\n",
        "              self.last_percent = current_percent\n",
        "              return line + \"\\n\"\n",
        "\n",
        "\n",
        "      # 默认返回原始行\n",
        "      return line + \"\\n\"\n",
        "\n",
        "    def stop_training(self, button):\n",
        "        \"\"\"停止训练\"\"\"\n",
        "        if self.training_process and self.is_training:\n",
        "            try:\n",
        "                # 发送终止信号\n",
        "                self.training_process.terminate()\n",
        "\n",
        "                # 等待进程结束（最多5秒）\n",
        "                try:\n",
        "                    self.training_process.wait(timeout=5)\n",
        "                except subprocess.TimeoutExpired:\n",
        "                    # 如果进程不响应，强制终止\n",
        "                    self.training_process.kill()\n",
        "                    self.training_process.wait()\n",
        "\n",
        "                self.is_training = False\n",
        "                self.widgets['stop_button'].disabled = True\n",
        "                self.widgets['run_button'].disabled = False\n",
        "                print(\"🛑 Training stopped by user\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error stopping training: {e}\")\n",
        "                # 强制恢复按钮状态\n",
        "                self.is_training = False\n",
        "                self.widgets['stop_button'].disabled = True\n",
        "                self.widgets['run_button'].disabled = False\n",
        "    def run_training(self, button):\n",
        "        \"\"\"运行训练\"\"\"\n",
        "        with self.output:\n",
        "            clear_output()\n",
        "            print(\"🚀 Start Training...\")\n",
        "            print(\"Press 'Stop Training' to interrupt\\n\")\n",
        "            # 更新按钮状态\n",
        "            self.widgets['run_button'].disabled = True\n",
        "            self.widgets['stop_button'].disabled = False\n",
        "            self.is_training = True\n",
        "\n",
        "            # 构建参数列表\n",
        "            args = [\n",
        "                \"python\", \"-u\", f\"{SCRIPTS_DIR}/train_base.py\",\n",
        "                \"--config_dir\", f\"{CONFIGS_DIR}\",\n",
        "                \"--train_file\", f\"{DATA_DIR}/con_train.jsonl\",\n",
        "                \"--valid_file\", f\"{DATA_DIR}/con_valid.jsonl\",\n",
        "                \"--overwrite_output_dir\",\n",
        "                \"--num_train_epochs\", str(self.widgets['num_train_epochs'].value),\n",
        "                \"--learning_rate\", str(self.widgets['learning_rate'].value),\n",
        "                \"--per_device_train_batch_size\", str(self.widgets['per_device_train_batch_size'].value),\n",
        "                \"--gradient_accumulation_steps\", str(self.widgets['gradient_accumulation_steps'].value),\n",
        "                \"--max_train_samples\", str(self.widgets['max_train_samples'].value),\n",
        "                \"--max_eval_samples\", str(self.widgets['max_eval_samples'].value),\n",
        "                \"--use_lora\", str(self.widgets['use_lora'].value),\n",
        "                \"--use_qlora\", str(self.widgets['use_qlora'].value),\n",
        "                \"--lora_rank\", str(self.widgets['lora_rank'].value),\n",
        "                \"--lora_alpha\", str(self.widgets['lora_alpha'].value)\n",
        "            ]\n",
        "\n",
        "            print(\"Command:\", \" \".join(args))\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            try:\n",
        "                # 使用 preexec_fn 确保子进程在单独的进程组中\n",
        "                def preexec_function():\n",
        "                    # 创建新的进程组\n",
        "                    os.setpgrp()\n",
        "\n",
        "                self.training_process = subprocess.Popen(\n",
        "                    args,\n",
        "                    stdout=subprocess.PIPE,\n",
        "                    stderr=subprocess.STDOUT,\n",
        "                    text=True,\n",
        "                    bufsize=1,\n",
        "                    universal_newlines=True,\n",
        "                    preexec_fn=preexec_function  # 确保子进程在独立进程组\n",
        "                )\n",
        "\n",
        "                # 实时处理输出\n",
        "                current_epoch = 0\n",
        "                for line in self.training_process.stdout:\n",
        "                    if not self.is_training:\n",
        "                        # 用户请求停止，立即终止进程\n",
        "                        print(\"\\n🛑 Stopping training process...\")\n",
        "                        try:\n",
        "                            # 终止整个进程组\n",
        "                            os.killpg(os.getpgid(self.training_process.pid), signal.SIGTERM)\n",
        "                            self.training_process.wait(timeout=5)\n",
        "                        except:\n",
        "                            try:\n",
        "                                self.training_process.kill()\n",
        "                                self.training_process.wait()\n",
        "                            except:\n",
        "                                pass\n",
        "                        break\n",
        "\n",
        "                    line = line.strip()\n",
        "                    if not line:\n",
        "                        continue\n",
        "\n",
        "                    # 动态更新显示\n",
        "                    formatted = self.format_training_line(line, current_epoch)\n",
        "                    if formatted:\n",
        "                        print(formatted, end='', flush=True)\n",
        "\n",
        "                        # 更新epoch信息\n",
        "                        if 'Epoch' in line and '/' in line:\n",
        "                            try:\n",
        "                                current_epoch = int(line.split('Epoch')[-1].split('/')[0].strip())\n",
        "                            except:\n",
        "                                pass\n",
        "\n",
        "                # 检查进程是否还在运行\n",
        "                if self.training_process.poll() is None:\n",
        "                    # 进程仍在运行，强制终止\n",
        "                    try:\n",
        "                        os.killpg(os.getpgid(self.training_process.pid), signal.SIGKILL)\n",
        "                        self.training_process.wait()\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                # 获取返回码\n",
        "                returncode = self.training_process.poll()\n",
        "\n",
        "                # 恢复按钮状态\n",
        "                self.widgets['run_button'].disabled = False\n",
        "                self.widgets['stop_button'].disabled = True\n",
        "                self.is_training = False\n",
        "\n",
        "                if returncode == 0:\n",
        "                    print(\"=\"*60)\n",
        "                    print(\"✅ Training completed successfully!\")\n",
        "                elif returncode == -15 or returncode == 15:  # 被终止\n",
        "                    print(\"=\"*60)\n",
        "                    print(\"🛑 Training stopped by user\")\n",
        "                else:\n",
        "                    print(\"=\"*60)\n",
        "                    print(f\"❌ Training failed (code: {returncode})\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                # 恢复按钮状态\n",
        "                self.widgets['run_button'].disabled = False\n",
        "                self.widgets['stop_button'].disabled = True\n",
        "                self.is_training = False\n",
        "\n",
        "# 使用GUI\n",
        "gui = TrainingConfigGUI(CONFIGS_DIR)\n",
        "gui.display_gui()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8vS71dHki_T"
      },
      "outputs": [],
      "source": [
        "# 在 notebook cell 中运行（替换 output_dir 为你的训练输出）\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"/content/drive/MyDrive/AIAA3102/Final_Project/Models/tinyllama_ai_finetuned/tb_runs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daSoVEjeyCpB"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/models/tinyllama_ai_finetuned /content/drive/MyDrive/AIAA3102/Final_Project/Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "92nsz3uBaTe-",
        "outputId": "cdfea808-45f1-4381-d5f2-bd4d4e333c18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sending incremental file list\n",
            "\n",
            "sent 1,130 bytes  received 15 bytes  2,290.00 bytes/sec\n",
            "total size is 107,257,357  speedup is 93,674.55\n"
          ]
        }
      ],
      "source": [
        "!rsync -av --delete --progress /content/drive/MyDrive/AIAA3102/Final_Project/Models/tinyllama_ai_finetuned/ /content/models/tinyllama_ai_finetuned/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assessment with Safety and Domain Check"
      ],
      "metadata": {
        "id": "zgJ0aS_k0WlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel, PeftConfig\n",
        "import os, json\n",
        "import torch\n",
        "import yaml\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class ModelTester:\n",
        "    def __init__(self, configs_dir, data_dir, base_dir, results_dir):\n",
        "        self.configs_dir = configs_dir\n",
        "        self.data_dir = data_dir\n",
        "        self.base_dir = base_dir\n",
        "        self.results_dir = results_dir\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "\n",
        "    def _safety_and_domain_check(self, user_input: str):\n",
        "        \"\"\"\n",
        "        Check if input contains dangerous content or is out-of-domain.\n",
        "        Returns (should_block: bool, response_message: str)\n",
        "        All messages are in English.\n",
        "        \"\"\"\n",
        "        user_input_lower = user_input.lower().strip()\n",
        "\n",
        "        # Dangerous keywords (English only, for your use case)\n",
        "        DANGEROUS_KEYWORDS = {\n",
        "            'suicide', 'kill myself', 'end my life', 'want to die', 'die alone',\n",
        "            'murder', 'homicide', 'self harm', 'cut myself', 'overdose',\n",
        "            'no reason to live', 'hurt myself', 'suicidal thoughts',\n",
        "            'can\\'t go on', 'better off dead'\n",
        "        }\n",
        "\n",
        "        # Out-of-domain keywords (clear non-counseling topics)\n",
        "        OUT_OF_DOMAIN_KEYWORDS = {\n",
        "            'code', 'python', 'java', 'javascript', 'c++', 'html', 'css', 'sql',\n",
        "            'math', 'calculate', 'solve', 'equation', 'derivative', 'integral', 'algebra',\n",
        "            'weather', 'forecast', 'stock', 'price', 'bitcoin', 'crypto',\n",
        "            'translate', 'summarize', 'write a poem', 'build a website',\n",
        "            'how to install', 'debug', 'error message', 'algorithm'\n",
        "        }\n",
        "\n",
        "        # Check dangerous content first (higher priority)\n",
        "        for phrase in DANGEROUS_KEYWORDS:\n",
        "            if phrase in user_input_lower:\n",
        "                return True, (\n",
        "                    \"I'm really concerned about what you're going through. \"\n",
        "                    \"Please reach out to a mental health professional or contact a crisis hotline immediately. \"\n",
        "                    \"In China, you can call or text 119. \"\n",
        "                    \"Your life matters, and help is available.\"\n",
        "                )\n",
        "\n",
        "        # Check out-of-domain content\n",
        "        for phrase in OUT_OF_DOMAIN_KEYWORDS:\n",
        "            if phrase in user_input_lower:\n",
        "                return True, (\n",
        "                    \"I'm designed to provide emotional support and counseling-related guidance only. \"\n",
        "                    \"This question is outside my area of expertise.\"\n",
        "                )\n",
        "\n",
        "        return False, \"\"\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Load model and tokenizer\"\"\"\n",
        "        cfg = yaml.safe_load(open(f\"{self.configs_dir}/training_args.yaml\"))\n",
        "        outdir = cfg.get(\"output_dir\", f\"{self.base_dir}/models/finetuned_model\")\n",
        "\n",
        "        print(f\"🔍 Checking model directory: {outdir}\")\n",
        "        if not os.path.exists(outdir):\n",
        "            raise FileNotFoundError(f\"Model directory not found: {outdir}\")\n",
        "\n",
        "        try:\n",
        "            peft_config = PeftConfig.from_pretrained(outdir)\n",
        "            is_lora = True\n",
        "            base_model_name = peft_config.base_model_name_or_path\n",
        "            print(f\"✅ Detected LoRA model, base model: {base_model_name}\")\n",
        "        except:\n",
        "            is_lora = False\n",
        "            base_model_name = cfg.get(\"model_name_or_path\", \"TinyLlama/TinyLlama_v1.1\")\n",
        "            print(f\"✅ Loading full model: {base_model_name}\")\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        if is_lora:\n",
        "            base_model = AutoModelForCausalLM.from_pretrained(\n",
        "                base_model_name,\n",
        "                device_map=\"auto\",\n",
        "                torch_dtype=torch.float16,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "            self.model = PeftModel.from_pretrained(base_model, outdir)\n",
        "            print(\"✅ LoRA adapter loaded successfully\")\n",
        "        else:\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                outdir,\n",
        "                device_map=\"auto\",\n",
        "                torch_dtype=torch.float16,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "            print(\"✅ Full model loaded successfully\")\n",
        "\n",
        "        print(f\"📊 Model parameters: {self.model.num_parameters():,}\")\n",
        "        print(f\"💻 Model device: {self.model.device}\")\n",
        "\n",
        "    def generate_response(self, prompt, generation_config=None):\n",
        "        \"\"\"Generate model response\"\"\"\n",
        "        if generation_config is None:\n",
        "            generation_config = {\n",
        "                \"max_new_tokens\": 256,\n",
        "                \"do_sample\": True,\n",
        "                \"temperature\": 1.0,\n",
        "                \"top_p\": 1.0,\n",
        "                \"repetition_penalty\": 1.1,\n",
        "                \"pad_token_id\": self.tokenizer.eos_token_id\n",
        "            }\n",
        "\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(self.model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                **generation_config\n",
        "            )\n",
        "\n",
        "        full_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        generated_text = full_text[len(prompt):].strip()\n",
        "        return full_text, generated_text\n",
        "\n",
        "    def test_validation_set(self, num_samples=10, save_results=False):\n",
        "        \"\"\"Test on validation set\"\"\"\n",
        "        print(f\"\\n🧪 Starting validation test ({num_samples} samples)\")\n",
        "\n",
        "        with open(f\"{self.data_dir}/con_valid.jsonl\", 'r', encoding='utf-8') as f:\n",
        "            lines = [json.loads(l) for l in f][:num_samples]\n",
        "\n",
        "        results = []\n",
        "\n",
        "        for i, ex in enumerate(tqdm(lines, desc=\"Testing\")):\n",
        "            prompt_text = ex['prompt']\n",
        "            expected_response = ex.get('response', '')\n",
        "\n",
        "            # Safety/domain check\n",
        "            blocked, safety_msg = self._safety_and_domain_check(prompt_text)\n",
        "            if blocked:\n",
        "                full_text = f\"Question:\\n{prompt_text}\\nAnswer:\\n{safety_msg}\"\n",
        "                generated_text = safety_msg\n",
        "            else:\n",
        "                prompt = f\"Question:\\n{prompt_text}\\nAnswer:\\n\"\n",
        "                try:\n",
        "                    full_text, generated_text = self.generate_response(prompt)\n",
        "                except Exception as e:\n",
        "                    generated_text = f\"[Generation failed: {str(e)}]\"\n",
        "                    full_text = prompt + generated_text\n",
        "\n",
        "            result = {\n",
        "                \"id\": i,\n",
        "                \"prompt\": prompt_text,\n",
        "                \"expected\": expected_response,\n",
        "                \"generated\": generated_text,\n",
        "                \"full_output\": full_text\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"📝 Sample {i+1}:\")\n",
        "            print(f\"❓ Question: {prompt_text[:100]}...\")\n",
        "            print(f\"🤖 Generated: {generated_text}\")\n",
        "            print(f\"✅ Expected: {expected_response}\")\n",
        "\n",
        "        if save_results:\n",
        "            output_file = f\"{self.results_dir}/test_results.json\"\n",
        "            os.makedirs(self.results_dir, exist_ok=True)\n",
        "            with open(output_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"\\n💾 Results saved to: {output_file}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def interactive_mode(self):\n",
        "        \"\"\"Interactive testing mode\"\"\"\n",
        "        print(\"\\n🎮 Entering interactive mode (type 'quit' to exit)\")\n",
        "\n",
        "        generation_configs = {\n",
        "            \"creative\": {\n",
        "                \"max_new_tokens\": 300,\n",
        "                \"do_sample\": True,\n",
        "                \"temperature\": 0.8,\n",
        "                \"top_p\": 0.9,\n",
        "                \"top_k\": 50\n",
        "            },\n",
        "            \"precise\": {\n",
        "                \"max_new_tokens\": 200,\n",
        "                \"do_sample\": False,\n",
        "                \"temperature\": 1.0,\n",
        "                \"top_p\": 1.0\n",
        "            },\n",
        "            \"balanced\": {\n",
        "                \"max_new_tokens\": 256,\n",
        "                \"do_sample\": True,\n",
        "                \"temperature\": 0.7,\n",
        "                \"top_p\": 0.9\n",
        "            }\n",
        "        }\n",
        "\n",
        "        current_mode = \"balanced\"\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                user_input = input(f\"\\n💬 Enter your question [{current_mode} mode]: \").strip()\n",
        "\n",
        "                if user_input.lower() in ['quit', 'exit']:\n",
        "                    break\n",
        "                elif user_input.lower() == 'mode':\n",
        "                    print(\"Available modes: creative, precise, balanced\")\n",
        "                    new_mode = input(\"Select mode: \").strip()\n",
        "                    if new_mode in generation_configs:\n",
        "                        current_mode = new_mode\n",
        "                        print(f\"✅ Switched to {current_mode} mode\")\n",
        "                    continue\n",
        "                elif not user_input:\n",
        "                    continue\n",
        "\n",
        "                # 🔒 Safety and domain check\n",
        "                blocked, safety_msg = self._safety_and_domain_check(user_input)\n",
        "                if blocked:\n",
        "                    print(f\"📝 {safety_msg}\")\n",
        "                    continue\n",
        "\n",
        "                prompt = f\"Question:\\n{user_input}\\nAnswer:\\n\"\n",
        "                full_text, generated_text = self.generate_response(\n",
        "                    prompt,\n",
        "                    generation_configs[current_mode]\n",
        "                )\n",
        "\n",
        "                print(f\"\\n🤖 Model Response ({current_mode} mode):\")\n",
        "                print(f\"📝 {generated_text}\")\n",
        "\n",
        "            except KeyboardInterrupt:\n",
        "                print(\"\\n👋 Exiting interactive mode\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Generation failed: {e}\")\n",
        "\n",
        "\n",
        "# ==========================\n",
        "# Example main() – adjust paths as needed\n",
        "# ==========================\n",
        "def main():\n",
        "    tester = ModelTester(CONFIGS_DIR, DATA_DIR, BASE_DIR, RESULTS_DIR)\n",
        "\n",
        "    try:\n",
        "        tester.load_model()\n",
        "        tester.test_validation_set(num_samples=5, save_results=True)\n",
        "        #tester.interactive_mode()\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1iOzu9K0hS1",
        "outputId": "a766bd03-68db-43c8-f9ee-c776fbb0b1a6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Checking model directory: models/tinyllama_ai_finetuned\n",
            "✅ Detected LoRA model, base model: TinyLlama/TinyLlama_v1.1\n",
            "✅ LoRA adapter loaded successfully\n",
            "📊 Model parameters: 1,102,301,184\n",
            "💻 Model device: cuda:0\n",
            "\n",
            "🧪 Starting validation test (5 samples)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing:   0%|          | 0/5 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Testing:  20%|██        | 1/5 [00:12<00:51, 12.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "📝 Sample 1:\n",
            "❓ Question: I'm always listening to my husband, but it feels like he never listens to me. \r\n",
            "\r\n",
            "How do I get my hu...\n",
            "🤖 Generated: For starters you've hit upon what's been bothering couples for at least a thousand years...\n",
            "He doesn't want to listen to what women have to say! That said, being an individual is only possible if you care about another individual person, and there are a lot of people out here who care (mostly males).\n",
            "This means there has got to be some serious, ongoing reason why your significant other won't pay attention when you talk directly with them. It could be that his listening muscles aren't as strong as yours so he will let you slide by when talking directly to him. Maybe there is such a deep-seated fear of what he might think or say that it makes him not pay full attention. Or perhaps he's not sure how much information to allow into his mind, and so the tension could grow. For now though, concentrate on you're talking to yourself. You're saying and thinking all kinds of wonderful things! I like your optimism.\n",
            "Another option, which isn't my favorite one (because in the end he'll probably end up saying stuff back to you), is to stop trying to convince your husband what he should/shouldn'\n",
            "✅ Expected: It's hard when you feel as if you're the only one that's taking the time to listen to your spouse. But, I would look at this as an opportunity to see if you can become aware of what exactly is happening between you, when you try and talk with your husband. Sometimes, it can be in the way dialogue is approached. I would suggest paying attention to the way you begin dialogue with your husband. See if blame and criticism are present. When blame and criticism are included, bids for connection, can quickly go off track. This can sometimes start off with something like: \"why don't you...\" \"you aren't...\" \"you don't...\" Partners can quickly go into defensive mode if they feel they are being attacked and sometimes starting off like this can feel like an attack.  Also, become aware of the time of day or evening when you approach your husband. Sometimes, this can make a big difference for couples as far as when they can truly be present for one another.  If you find this pattern continues, you might consider seeking professional help through couples therapy. A trained couples therapist can help you both understand more about what's happening between you.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTesting:  40%|████      | 2/5 [00:25<00:38, 12.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "📝 Sample 2:\n",
            "❓ Question: I've been with a man for four years. For the last year, he has said he is done, but he still talks, ...\n",
            "🤖 Generated: Hi, Shelley! 14 months together...that's an amazing relationship considering everyone says relationships are hard but you guys have managed to make it so far.\n",
            "Your partner seems like an incredible guy but when asked why doesn't he move on you haven't heard any answers that help you feel better about your partner who still refuses to do what he could be doing. It gets harder everyday because of this and I get even more frustrated. It is possible that sometimes guys will just shut down and not give in and not want to say the word \"quit\". But if that doesn't really do anything please see if there are other questions we can provide to aid in finding out how to approach him. Maybe the best thing he would tell someone, is \"If you will ever say \"stay\", there will be no turning back.\" This helps the person to put away all thoughts of leaving and stay rather than quitting. Maybe one or two people to talk with about a partner that's holding them down could be a start to getting this problem addressed. And just know that even though it becomes quite painful hearing from time to time, that one day the pain subsides and the person gets excited again about\n",
            "✅ Expected: Have you brought up the topic as to the way you're feeling?The best way for someone to understand us or to understand someone, is to directly talk about  the specific problem.To start the discussion w your partner, understand your own reasons for continuing the relationship.Given his stated disinterest in the relationship, your mood is probably affected by this.Once you are clear on how the range of your feelings, especially any fears on being alone, suggesting you may be staying w this guy simply to avoid such fears, then you'll be ready w your self-knowledge, to start a conversation w your partner about your relationship.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTesting:  60%|██████    | 3/5 [00:38<00:25, 12.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "📝 Sample 3:\n",
            "❓ Question: After first meeting the client, what is the process that a counselor facilitates?...\n",
            "🤖 Generated: After meeting the client for the first time during the intake interview, or after a face to face or phone or group therapy appointment. My counseling style will always be collaborative and goal oriented so you come to the counselor sessions with a preliminary sense of what you would like to do. The individualized work that begins each week usually has some type of goal or outcome in mind.\n",
            "If the counselor is an active member of your therapy it will usually take place within a group. This type of work is often less common then in other types of therapies or sessions. In our offices we will offer a variety of opportunities in one of our offices to meet once per week for at least half an hour at 11 AM.\n",
            "The counselor is always available to make suggestions on how to implement any part or section of the process if the client is already making some progress on his/her own. But, I love the idea of starting up new things or trying out a new concept with someone with whom you are not having as successful a relationship as you'd like!\n",
            "What to expect when starting therapy?\n",
            "Answer:Therapy is usually ongoing and is designed by both you and\n",
            "✅ Expected: A good therapist will discuss what brought you to therapy in the first place and devise a therapy plan with you on some of the things that you may want to work on.  The plan is not set in stone as things may arise during your therapy sessions. You also agree on how often and when you would like to meet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTesting:  80%|████████  | 4/5 [00:51<00:12, 12.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "📝 Sample 4:\n",
            "❓ Question: I feel like every time I do something someone asks me to, I never fully meet what they want. I feel ...\n",
            "🤖 Generated: Well, maybe you are doing more than meets the eye there, you may be understimulated? Not having met exactly the needs of others for some reason I'm guessing you're not quite satisfied. I wonder if a great challenge has been introduced by this interaction on theirs part(s). As the saying goes... we may come across all sorts of obstacles!\n",
            "And on another note! Not wanting and meeting your own needs is indeed a bit of an unusual approach. How about if you asked everyone if they needed you to go help them with something. Maybe ask for feedback or a bit of self-examination. Is this how you would feel in this scenario if your partner did it... or anyone else? What do you feel? Then be the hero - the one who steps forward... and does the job!\n",
            "I am a writer/performer teaching writing courses and workshops on the East coast. I have studied theatre writing and education from The University of the Arts London, London College of Communication, University of Roehampton, The Acting Centre. I have also been active as a theatre performer in the UK, in New York and have performed at Edinburgh Fringe, North American Fringe and the London S\n",
            "✅ Expected: It sounds like you have the perception that people are frequently disappointed in you, wish you were different or someone else, and ultimately reject you. One question I would have for you is what is your evidence that people feel this way? Is there anything in people's words or behaviors that gives you this impression? If your not sure, it may be useful for you to try to notice what people say and do in response to you, even though you perceive these attitudes within them. Additionally, working with a competent therapist may be a great way to get an answer to your question as well as developing ways to move forward with that answer and gain a sense of self-esteem and security in your relationships.One possibility that comes to mind, of which there may be more, is that as we grow up, we often develop relational templates, or sets of expectations about how people are and will relate to us, which influence our experiences and behavior in relationships. Sometimes the templates that we develop to stay connected growing up are not particularly adaptive for adult life and can hamper our self-esteem and capacity for comfortable intimacy as an adult. You ask a great question here, and one that can be very hard to see through, given the difficulty of feeling that people think of you in this way, and I hope that you will stay curious about this and consider working with a therapist who is trained to help you discover the answer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 5/5 [01:04<00:00, 12.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "📝 Sample 5:\n",
            "❓ Question: It's been almost a year since my ex-boyfriend broke up with me after he cheated on me many times. I ...\n",
            "🤖 Generated: In your example, you have two choices you can make. You can either look at things as healing or haunting yourself in a negative way and in the opposite direction. Which one do you think is the best for yourself? The fact he helped you through your feelings by giving financial support makes you feel gratitude towards him. On the other hand, he betrayed his promise to love and protect you. There are no good or bad examples; it just depends on the meaning.\n",
            "However, in order of gratitude to forgiveness, I highly recommend that you look into Forgiveness Therapy. From my own personal experience, it's something I needed to do in my life and in some cases I never got around to it. Most people don't. After my workshops, I have a greater understanding of the situation that led to my betrayal. My feelings started healing. As your experience evolves more and more. I believe that will lead towards greater understanding of why you continue to be haunted from this situation! Let these questions guide you. 1)If you've talked to another counselor or therapist in regards to forgiveness, then yes they can help you more than someone who is just taking\n",
            "✅ Expected: The dilemmas you present are giving you a great chance to understand your true reasons for being in a relationship.Continue developing some points you've written here.That you grew up sensing and/or witnessing your mom's emotional pain from your dad cheating on her, very likely set a standard in your inner self, to expect similar circumstances in your relationship life.This is a natural dynamic which happens for all of us.  What we observe in our growing up households is what we understand as \"normal\", no matter how bad it actually is.After all, children don't have the ability to separate that what their own parents do, is wrong compared with the rest of our culture.It is natural to long for a relationship.What you have the chance to do now, is distinguish the reasons for your longing.Is it to attach to someone who has hurt you, hasn't shown you any understanding of having hurt you, and whose validation, even if he says validating words, has little meaning because people who validate are not the ones who harm us?If you're able to teach yourself that those who love us do not harm us, and to develop new expectations for yourself of feeling good from how your partner treats you, then you will be showing yourself a road that will benefit you for your entire lifetime.\n",
            "\n",
            "💾 Results saved to: /content/drive/MyDrive/AIAA3102/Final_Project/Results/test_results.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tester = ModelTester(CONFIGS_DIR, DATA_DIR, BASE_DIR, RESULTS_DIR)\n",
        "tester.load_model()\n",
        "tester.interactive_mode()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2uOHEUl4ntc",
        "outputId": "42628c81-fce7-4204-d648-85959593fa9e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Checking model directory: models/tinyllama_ai_finetuned\n",
            "✅ Detected LoRA model, base model: TinyLlama/TinyLlama_v1.1\n",
            "✅ LoRA adapter loaded successfully\n",
            "📊 Model parameters: 1,102,301,184\n",
            "💻 Model device: cuda:0\n",
            "\n",
            "🎮 Entering interactive mode (type 'quit' to exit)\n",
            "\n",
            "💬 Enter your question [balanced mode]: I want to suicide\n",
            "📝 I'm really concerned about what you're going through. Please reach out to a mental health professional or contact a crisis hotline immediately. In China, you can call or text 119. Your life matters, and help is available.\n",
            "\n",
            "💬 Enter your question [balanced mode]: I want you to teach me math\n",
            "📝 I'm designed to provide emotional support and counseling-related guidance only. This question is outside my area of expertise.\n",
            "\n",
            "💬 Enter your question [balanced mode]: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxuwlg5IoCR-"
      },
      "source": [
        "# Quick Assessment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FKE-o9SgwL5",
        "outputId": "ea520c5d-fe2c-482b-9fd7-8b97e9c9f154"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "decoded: ### 问：\n",
            "I'm so sad because my best friend left.？\n",
            "### 答：\n",
            " I'm sorry to hear...\n",
            "input_ids (head): [835, 29871, 31658, 30383, 13, 29902, 29915, 29885, 577, 14610, 1363, 590, 1900, 5121, 2175, 29889, 30882, 13, 2277, 29937, 29871, 234, 176, 151, 30383, 13, 306, 29915, 29885, 7423, 304, 8293, 856]\n",
            "labels (head): [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 306, 29915, 29885, 7423, 304, 8293, 856]\n",
            "labels contains -100? True\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama_v1.1\")\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# 示例 prompt/response\n",
        "prompt = \"### 问：\\nI'm so sad because my best friend left.？\\n### 答：\\n\"\n",
        "response = \"I'm sorry to hear...\"\n",
        "\n",
        "# tokenization as our new function does\n",
        "p_ids = tokenizer(prompt, add_special_tokens=False)[\"input_ids\"]\n",
        "r_ids = tokenizer(response, add_special_tokens=False)[\"input_ids\"]\n",
        "max_length = 128\n",
        "full = p_ids + r_ids\n",
        "if len(full) > max_length:\n",
        "    full = full[-max_length:]\n",
        "    if len(r_ids) >= max_length:\n",
        "        resp_start = 0\n",
        "    else:\n",
        "        resp_start = max(0, len(full) - len(r_ids))\n",
        "else:\n",
        "    resp_start = len(p_ids)\n",
        "\n",
        "labels = [-100] * len(full)\n",
        "for i in range(resp_start, len(full)):\n",
        "    labels[i] = full[i]\n",
        "\n",
        "pad_len = max_length - len(full)\n",
        "input_ids = full + [tokenizer.pad_token_id] * pad_len\n",
        "labels = labels + [-100] * pad_len\n",
        "\n",
        "print(\"decoded:\", tokenizer.decode(input_ids[:len(full)]))\n",
        "print(\"input_ids (head):\", input_ids[:len(full)])\n",
        "print(\"labels (head):\", labels[:len(full)])\n",
        "print(\"labels contains -100?\", -100 in labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY9Twbnzan38"
      },
      "source": [
        "### Baseline Tinyllama without LoRA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e928657d",
        "outputId": "48ccdabe-d2dd-4825-9765-578b6a8aea21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading tokenizer for base model: TinyLlama/TinyLlama_v1.1\n",
            "Base tokenizer loaded.\n",
            "Loading base model: TinyLlama/TinyLlama_v1.1\n",
            "Base model loaded.\n",
            "Base model device: cuda:0\n",
            "Base model parameters: 1,100,048,384\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Define the base model name\n",
        "base_model_name = \"TinyLlama/TinyLlama_v1.1\"\n",
        "\n",
        "print(f\"Loading tokenizer for base model: {base_model_name}\")\n",
        "base_tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
        "print(\"Base tokenizer loaded.\")\n",
        "\n",
        "print(f\"Loading base model: {base_model_name}\")\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_name,\n",
        "    device_map=\"auto\",\n",
        "    dtype=torch.float16,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "print(\"Base model loaded.\")\n",
        "print(f\"Base model device: {base_model.device}\")\n",
        "print(f\"Base model parameters: {base_model.num_parameters():,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d432c472",
        "outputId": "67536d8b-d8c5-4c3c-bf36-22129acb444d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🚀 Generating responses with the original TinyLlama model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Base model inference:  20%|██        | 1/5 [00:17<01:11, 17.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "📝 Sample 1 (Base Model):\n",
            "❓ Question: I'm always listening to my husband, but it feels like he never listens to me. \r\n",
            "\r\n",
            "How do I get my hu...\n",
            "🤖 Generated Response: Husbands and wives are not robots. They have feelings, too. If you want your husband to listen to you, you need to give him a reason to. If he thinks that you just don't care about him enough, then that is his problem. If you don't want to argue with him, but want to be heard, then you have to make sure you say what you mean.\n",
            "If you want your husband to listen to you, then he needs to understand your point of view, or at least try.\n",
            "There are three things you can do:\n",
            "1. Start by saying \"I love you\" to your husband every morning (even if it's not true).\n",
            "2. Ask for what you want in your marriage.\n",
            "3. If you know something is bothering him, ask him if he wants to talk about it.\n",
            "You can start by saying \"I love you.\"\n",
            "You can ask for what you want in your marriage.\n",
            "You can ask your husband if he wants to talk about it.\n",
            "You can ask him if he wants to talk about it.\n",
            "You can also ask him for forgiveness.\n",
            "You can also tell him why you don't feel like going out on Saturday\n",
            "✅ Expected Response: It's hard when you feel as if you're the only one that's taking the time to listen to your spouse. But, I would look at this as an opportunity to see if you can become aware of what exactly is happening between you, when you try and talk with your husband. Sometimes, it can be in the way dialogue is approached. I would suggest paying attention to the way you begin dialogue with your husband. See if blame and criticism are present. When blame and criticism are included, bids for connection, can quickly go off track. This can sometimes start off with something like: \"why don't you...\" \"you aren't...\" \"you don't...\" Partners can quickly go into defensive mode if they feel they are being attacked and sometimes starting off like this can feel like an attack.  Also, become aware of the time of day or evening when you approach your husband. Sometimes, this can make a big difference for couples as far as when they can truly be present for one another.  If you find this pattern continues, you might consider seeking professional help through couples therapy. A trained couples therapist can help you both understand more about what's happening between you.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rBase model inference:  40%|████      | 2/5 [00:34<00:51, 17.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "📝 Sample 2 (Base Model):\n",
            "❓ Question: I've been with a man for four years. For the last year, he has said he is done, but he still talks, ...\n",
            "🤖 Generated Response: His words do not match his actions. I love this man, but it's hurting so much.\n",
            "She has been married for two years. He has been with her for six months. She wants to be single. He wants to get married again. They both have children.\n",
            "She has been married for two years. He has been with her for six months. She wants to be single. He wants to get married again. They both have children.\n",
            "He said he was going to get married in September, but never did. The wedding never happened. He said he would wait until next year but never did. He also said that he would never get married again because of how much time they had spent apart since their first meeting.\n",
            "He said he was going to get married in September, but never did. The wedding never happened. He said he would wait until next year but never did. He also said that he would never get married again because of how much time they had spent apart since their first meeting.\n",
            "The man in question is a serial cheater. He's been cheating on me for at least five years now. It started out as an occasional flirtation here or there. Then he got serious about\n",
            "✅ Expected Response: Have you brought up the topic as to the way you're feeling?The best way for someone to understand us or to understand someone, is to directly talk about  the specific problem.To start the discussion w your partner, understand your own reasons for continuing the relationship.Given his stated disinterest in the relationship, your mood is probably affected by this.Once you are clear on how the range of your feelings, especially any fears on being alone, suggesting you may be staying w this guy simply to avoid such fears, then you'll be ready w your self-knowledge, to start a conversation w your partner about your relationship.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rBase model inference:  60%|██████    | 3/5 [00:42<00:26, 13.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "📝 Sample 3 (Base Model):\n",
            "❓ Question: After first meeting the client, what is the process that a counselor facilitates?...\n",
            "🤖 Generated Response: The counseling process begins with a thorough assessment of the client. The counselor uses this information to develop an individualized treatment plan. The plan may include counseling, referrals for appropriate services and follow-up sessions as necessary.\n",
            "When a client comes to see you, how do you assess their level of distress? What are some signs that a person has been affected by a traumatic event or may be at risk of developing PTSD?\n",
            "答 e\n",
            "Assessment includes:\n",
            "What are the client's goals?\n",
            "What are the client's symptoms?\n",
            "Is there a history of substance abuse? If so, how many days/weeks in the last month have you used alcohol or drugs?\n",
            "Does the client appear anxious, depressed or agitated? Are they irritable? Do they seem to be unable to concentrate?\n",
            "Are there any recent events or circumstances that could be related to their current problems? Have they had recent changes in employment, housing, friends or family?\n",
            "Have they experienced recent changes in school or work?\n",
            "Do they have trouble sleeping, concentrating or managing stressors?\n",
            "Does the client have problems with\n",
            "✅ Expected Response: A good therapist will discuss what brought you to therapy in the first place and devise a therapy plan with you on some of the things that you may want to work on.  The plan is not set in stone as things may arise during your therapy sessions. You also agree on how often and when you would like to meet.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rBase model inference:  80%|████████  | 4/5 [00:51<00:11, 11.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "📝 Sample 4 (Base Model):\n",
            "❓ Question: I feel like every time I do something someone asks me to, I never fully meet what they want. I feel ...\n",
            "🤖 Generated Response: I feel like I have to do everything for everyone.\n",
            "I feel like people always ask me to help them but I don't really know how to help anyone because I'm not sure if they are worth helping. So I feel like I'm just giving up on myself.\n",
            "I feel like sometimes, I'm just so busy doing my own thing that I forget about the things other people need. Like, when I'm having a bad day, I'll just go back to what I was doing before and that will make me happy. But then I feel guilty when I'm having a good day.\n",
            "答\n",
            "I feel like sometimes I have no control over myself. I can be really hard on myself sometimes. I feel like there is a lot of negativity in my head that I have to try to get rid of. And I think that's why I feel like I can't let people into my life too easily. I feel like I can only take so much. I also feel like I don't know who I am anymore. When I was younger, I used to think that I could figure out what I wanted to do later. Now I don't think anything will ever happen. And I\n",
            "✅ Expected Response: It sounds like you have the perception that people are frequently disappointed in you, wish you were different or someone else, and ultimately reject you. One question I would have for you is what is your evidence that people feel this way? Is there anything in people's words or behaviors that gives you this impression? If your not sure, it may be useful for you to try to notice what people say and do in response to you, even though you perceive these attitudes within them. Additionally, working with a competent therapist may be a great way to get an answer to your question as well as developing ways to move forward with that answer and gain a sense of self-esteem and security in your relationships.One possibility that comes to mind, of which there may be more, is that as we grow up, we often develop relational templates, or sets of expectations about how people are and will relate to us, which influence our experiences and behavior in relationships. Sometimes the templates that we develop to stay connected growing up are not particularly adaptive for adult life and can hamper our self-esteem and capacity for comfortable intimacy as an adult. You ask a great question here, and one that can be very hard to see through, given the difficulty of feeling that people think of you in this way, and I hope that you will stay curious about this and consider working with a therapist who is trained to help you discover the answer.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Base model inference: 100%|██████████| 5/5 [00:59<00:00, 11.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "📝 Sample 5 (Base Model):\n",
            "❓ Question: It's been almost a year since my ex-boyfriend broke up with me after he cheated on me many times. I ...\n",
            "🤖 Generated Response: I'm so sorry that you've gone through such a traumatic experience in your life. It's understandable why you feel so upset. But also I think you'll be glad to know that you are not alone. I can tell you that it feels so much better to let go of the guilt, and forgive yourself, and move on from the betrayal. This is especially important as you continue to heal.\n",
            "You've mentioned how you feel guilty because you're still mad at him. This is a common reaction to betrayal, and is a normal feeling. You should probably remind yourself that your feelings don't mean anything to him. Your ex is not going to change his ways or think differently about you. He probably just doesn't care what happens to you.\n",
            "The first step in moving forward is forgiving yourself for the hurt you've felt. It may take some time, but it will help you to let go of these feelings and move on. I would suggest that you try to be kinder towards yourself. Try to remember that you are strong enough to survive this. Also, take breaks when you need them, and give yourself permission to just sit back and relax\n",
            "✅ Expected Response: The dilemmas you present are giving you a great chance to understand your true reasons for being in a relationship.Continue developing some points you've written here.That you grew up sensing and/or witnessing your mom's emotional pain from your dad cheating on her, very likely set a standard in your inner self, to expect similar circumstances in your relationship life.This is a natural dynamic which happens for all of us.  What we observe in our growing up households is what we understand as \"normal\", no matter how bad it actually is.After all, children don't have the ability to separate that what their own parents do, is wrong compared with the rest of our culture.It is natural to long for a relationship.What you have the chance to do now, is distinguish the reasons for your longing.Is it to attach to someone who has hurt you, hasn't shown you any understanding of having hurt you, and whose validation, even if he says validating words, has little meaning because people who validate are not the ones who harm us?If you're able to teach yourself that those who love us do not harm us, and to develop new expectations for yourself of feeling good from how your partner treats you, then you will be showing yourself a road that will benefit you for your entire lifetime.\n",
            "\n",
            "✅ Base model inference complete.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def generate_response_base(model, tokenizer, prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_p=0.9, repetition_penalty=1.1):\n",
        "    \"\"\"Generates a response using the base model.\"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    generation_config = {\n",
        "        \"max_new_tokens\": max_new_tokens,\n",
        "        \"do_sample\": do_sample,\n",
        "        \"temperature\": temperature,\n",
        "        \"top_p\": top_p,\n",
        "        \"repetition_penalty\": repetition_penalty,\n",
        "        \"pad_token_id\": tokenizer.eos_token_id\n",
        "    }\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            **generation_config\n",
        "        )\n",
        "\n",
        "    full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    generated_text = full_text[len(prompt):]\n",
        "    return generated_text\n",
        "\n",
        "# 1. Load the con_valid.jsonl dataset and select the first 5 samples\n",
        "validation_data_path = f\"{DATA_DIR}/con_valid.jsonl\"\n",
        "base_model_results = []\n",
        "\n",
        "with open(validation_data_path, 'r', encoding='utf-8') as f:\n",
        "    validation_samples = [json.loads(line) for line in f][:5]\n",
        "\n",
        "# 2. Iterate through the selected validation samples, format the prompt, and generate responses\n",
        "print(\"\\n🚀 Generating responses with the original TinyLlama model...\")\n",
        "for i, sample in enumerate(tqdm(validation_samples, desc=\"Base model inference\")):\n",
        "    prompt_text = f\"问：\\n{sample['prompt']}\\n答：\\n\"\n",
        "    generated_response = generate_response_base(base_model, base_tokenizer, prompt_text)\n",
        "\n",
        "    base_model_results.append({\n",
        "        \"id\": i,\n",
        "        \"prompt\": sample['prompt'],\n",
        "        \"expected\": sample.get('response', ''),\n",
        "        \"generated\": generated_response.strip()\n",
        "    })\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"📝 Sample {i+1} (Base Model):\")\n",
        "    print(f\"❓ Question: {sample['prompt'][:100]}...\")\n",
        "    print(f\"🤖 Generated Response: {generated_response.strip()}\")\n",
        "    print(f\"✅ Expected Response: {sample.get('response', '')}\")\n",
        "\n",
        "print(\"\\n✅ Base model inference complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXGyMMwja79x"
      },
      "source": [
        "### LoRA Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TB4BuMvSzMk",
        "outputId": "7b94904f-8e78-4019-d909-86c815546200"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 检查模型目录: models/tinyllama_ai_finetuned\n",
            "✅ 检测到LoRA模型，基础模型: TinyLlama/TinyLlama_v1.1\n",
            "✅ LoRA适配器加载完成\n",
            "📊 模型参数数量: 1,102,301,184\n",
            "💻 模型设备: cuda:0\n",
            "\n",
            "🧪 开始验证集测试 (5个样本)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "测试进度:  20%|██        | 1/5 [00:17<01:09, 17.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "📝 样本 1:\n",
            "❓ 问题: I'm always listening to my husband, but it feels like he never listens to me. \r\n",
            "\r\n",
            "How do I get my hu...\n",
            "🤖 生成回答: It is a good idea to ask your husband what he wants you to do and how you can help him achieve his goals. If you are not sure about what he wants or needs from you, then you should ask him directly. You may also want to consider asking your husband if there is anything that he would like you to do for him. This will give you an idea of whether or not you two are on the same page when it comes to communication. Finally, try to be patient with your husband as he may take some time to understand what you are saying. Remember that he is trying to understand you as well. Keep in mind that communication is a two-way street and both parties need to be willing to listen to each other. If you can work together to find common ground, then you will have a better chance of resolving any issues that arise. Best of luck!\n",
            "What is the best way to communicate with someone who is deaf?\n",
            "There are many ways to communicate with someone who is deaf. Some people use sign language, others lip reading, and still others use spoken words. It is important to remember that each person has their own unique way of communicating. If you are having\n",
            "✅ 期望回答: It's hard when you feel as if you're the only one that's taking the time to listen to your spouse. But, I would look at this as an opportunity to see if you can become aware of what exactly is happening between you, when you try and talk with your husband. Sometimes, it can be in the way dialogue is approached. I would suggest paying attention to the way you begin dialogue with your husband. See if blame and criticism are present. When blame and criticism are included, bids for connection, can quickly go off track. This can sometimes start off with something like: \"why don't you...\" \"you aren't...\" \"you don't...\" Partners can quickly go into defensive mode if they feel they are being attacked and sometimes starting off like this can feel like an attack.  Also, become aware of the time of day or evening when you approach your husband. Sometimes, this can make a big difference for couples as far as when they can truly be present for one another.  If you find this pattern continues, you might consider seeking professional help through couples therapy. A trained couples therapist can help you both understand more about what's happening between you.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r测试进度:  40%|████      | 2/5 [00:32<00:47, 15.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "📝 样本 2:\n",
            "❓ 问题: I've been with a man for four years. For the last year, he has said he is done, but he still talks, ...\n",
            "🤖 生成回答: It sounds like you are in a very difficult situation. It may be that your partner is simply not ready to move on from you. If he is not ready to move on, then you should respect his wishes. However, if he is ready to move on, then you should respect his wishes as well. It would be best to talk to him about what you want and see if he is willing to work together to find a solution. Good luck!\n",
            "What is the difference between a relationship and a marriage?\n",
            "How can I get over my ex-boyfriend?\n",
            "Is it normal to feel sad when someone you care about dies?\n",
            "How do I stop feeling guilty for being single?\n",
            "How do I know if I am in love or just infatuated?\n",
            "How do I stop feeling like I have to prove myself?\n",
            "How do I stop feeling like I need to prove myself? I'm a college student who feels like I need to prove myself all the time. I'm always trying to do better than everyone else, even though I don't think I'm doing anything wrong. I'm starting to feel like I'm not good enough. How do I stop feeling like I need to prove myself all the time? I\n",
            "✅ 期望回答: Have you brought up the topic as to the way you're feeling?The best way for someone to understand us or to understand someone, is to directly talk about  the specific problem.To start the discussion w your partner, understand your own reasons for continuing the relationship.Given his stated disinterest in the relationship, your mood is probably affected by this.Once you are clear on how the range of your feelings, especially any fears on being alone, suggesting you may be staying w this guy simply to avoid such fears, then you'll be ready w your self-knowledge, to start a conversation w your partner about your relationship.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r测试进度:  60%|██████    | 3/5 [00:46<00:30, 15.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "📝 样本 3:\n",
            "❓ 问题: After first meeting the client, what is the process that a counselor facilitates?...\n",
            "🤖 生成回答: The process of counseling is a collaborative effort between the counselor and the client.  The counselor will ask questions to help understand the client's needs and goals for therapy.  The counselor will also ask questions about the client's history in order to determine if there are any factors that may be contributing to the presenting problem.  Once the counselor has gathered information from both the client and the client's family members, they will begin to develop a treatment plan together.  This plan will include specific goals for the client and how those goals can be achieved through the use of therapeutic techniques.  The counselor will also work with the client to develop a treatment schedule that is tailored to meet their individual needs.  Finally, the counselor will provide ongoing support and guidance throughout the course of treatment.  Counselors are trained to work with clients who have a variety of different issues and needs.  They can help clients identify barriers to change and develop strategies to overcome them.  Counselors can also assist clients in identifying resources that may be helpful in overcoming challenges.  Counselors are often able to refer clients to other services such\n",
            "✅ 期望回答: A good therapist will discuss what brought you to therapy in the first place and devise a therapy plan with you on some of the things that you may want to work on.  The plan is not set in stone as things may arise during your therapy sessions. You also agree on how often and when you would like to meet.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r测试进度:  80%|████████  | 4/5 [01:01<00:15, 15.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "📝 样本 4:\n",
            "❓ 问题: I feel like every time I do something someone asks me to, I never fully meet what they want. I feel ...\n",
            "🤖 生成回答: It's not uncommon for people to ask us to do things and then not follow through on the request. It can be frustrating because we want to help others but we don't know how to do so. The best way to handle this is to be honest about your feelings. If you are feeling frustrated or disappointed in yourself, then you will probably be more open to accepting help from others. You may also find that other people are willing to help you out if you let them know what you need. Finally, try to remember that there are many ways to accomplish a task and sometimes it's just easier to delegate tasks to others. Good luck!\n",
            "What does it mean when someone says \"I love you\" but doesn't mean it?\n",
            "It means that they don't really care about you. They only say those words to make themselves feel better.\n",
            "How do I stop myself from saying yes to everything?\n",
            "Say no to everything. Saying yes to everything is a sign of weakness.\n",
            "How do I stop myself from saying yes to everything?\n",
            "Stop saying yes to everything. Saying yes to everything is a sign of weakness.\n",
            "How do I stop myself from saying yes to everything?\n",
            "✅ 期望回答: It sounds like you have the perception that people are frequently disappointed in you, wish you were different or someone else, and ultimately reject you. One question I would have for you is what is your evidence that people feel this way? Is there anything in people's words or behaviors that gives you this impression? If your not sure, it may be useful for you to try to notice what people say and do in response to you, even though you perceive these attitudes within them. Additionally, working with a competent therapist may be a great way to get an answer to your question as well as developing ways to move forward with that answer and gain a sense of self-esteem and security in your relationships.One possibility that comes to mind, of which there may be more, is that as we grow up, we often develop relational templates, or sets of expectations about how people are and will relate to us, which influence our experiences and behavior in relationships. Sometimes the templates that we develop to stay connected growing up are not particularly adaptive for adult life and can hamper our self-esteem and capacity for comfortable intimacy as an adult. You ask a great question here, and one that can be very hard to see through, given the difficulty of feeling that people think of you in this way, and I hope that you will stay curious about this and consider working with a therapist who is trained to help you discover the answer.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "测试进度: 100%|██████████| 5/5 [01:14<00:00, 14.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "📝 样本 5:\n",
            "❓ 问题: It's been almost a year since my ex-boyfriend broke up with me after he cheated on me many times. I ...\n",
            "🤖 生成回答: I'm sorry you are going through such a difficult time. It sounds like you are trying to move forward in your life while also dealing with the pain of your ex-boyfriend's betrayal. I would recommend that you seek counseling from someone who specializes in working with trauma. You may be able to work through some of these issues with the help of a therapist. If you decide to go ahead with therapy, I would suggest that you bring up the topic of your ex-boyfriend's betrayal during your first session with your therapist. It could be helpful to share your thoughts and feelings with someone who will listen without judgement. I hope that you find peace and closure in your journey. Best of luck!\n",
            "Kimberly L. Hicks, LCSW, BC-DMT, CADC, MBA, NCC, AAMFT\n",
            "Kimberly L. Hicks, LCSW, BC-DMT, CADC, MBA, NCC, AAMFT, is a Licensed Clinical Social Worker, Board Certified Addictionologist/Consultant, Diplomat of Addictions Medicine (D\n",
            "✅ 期望回答: The dilemmas you present are giving you a great chance to understand your true reasons for being in a relationship.Continue developing some points you've written here.That you grew up sensing and/or witnessing your mom's emotional pain from your dad cheating on her, very likely set a standard in your inner self, to expect similar circumstances in your relationship life.This is a natural dynamic which happens for all of us.  What we observe in our growing up households is what we understand as \"normal\", no matter how bad it actually is.After all, children don't have the ability to separate that what their own parents do, is wrong compared with the rest of our culture.It is natural to long for a relationship.What you have the chance to do now, is distinguish the reasons for your longing.Is it to attach to someone who has hurt you, hasn't shown you any understanding of having hurt you, and whose validation, even if he says validating words, has little meaning because people who validate are not the ones who harm us?If you're able to teach yourself that those who love us do not harm us, and to develop new expectations for yourself of feeling good from how your partner treats you, then you will be showing yourself a road that will benefit you for your entire lifetime.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "💾 测试结果已保存至: /content/drive/MyDrive/AIAA3102/Final_Project/Results/test_results.json\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel, PeftConfig\n",
        "import os, json\n",
        "import torch\n",
        "import yaml\n",
        "from tqdm import tqdm\n",
        "\n",
        "class ModelTester:\n",
        "    def __init__(self, configs_dir, data_dir, base_dir, results_dir):\n",
        "        self.configs_dir = configs_dir\n",
        "        self.data_dir = data_dir\n",
        "        self.base_dir = base_dir\n",
        "        self.results_dir = results_dir\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"加载模型和tokenizer\"\"\"\n",
        "        # 读取配置\n",
        "        cfg = yaml.safe_load(open(f\"{self.configs_dir}/training_args.yaml\"))\n",
        "        outdir = cfg.get(\"output_dir\", f\"{self.base_dir}/models/finetuned_model\")\n",
        "\n",
        "        print(f\"🔍 检查模型目录: {outdir}\")\n",
        "        if not os.path.exists(outdir):\n",
        "            raise FileNotFoundError(f\"模型目录不存在: {outdir}\")\n",
        "\n",
        "        # 检查是否是LoRA模型\n",
        "        try:\n",
        "            peft_config = PeftConfig.from_pretrained(outdir)\n",
        "            is_lora = True\n",
        "            base_model_name = peft_config.base_model_name_or_path\n",
        "            print(f\"✅ 检测到LoRA模型，基础模型: {base_model_name}\")\n",
        "        except:\n",
        "            is_lora = False\n",
        "            base_model_name = cfg.get(\"model_name_or_path\", \"TinyLlama/TinyLlama_v1.1\")\n",
        "            print(f\"✅ 加载完整模型: {base_model_name}\")\n",
        "\n",
        "        # 加载tokenizer\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
        "\n",
        "        # 加载模型\n",
        "        if is_lora:\n",
        "            # LoRA模型加载方式\n",
        "            base_model = AutoModelForCausalLM.from_pretrained(\n",
        "                base_model_name,\n",
        "                device_map=\"auto\",\n",
        "                torch_dtype=torch.float16,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "            self.model = PeftModel.from_pretrained(base_model, outdir)\n",
        "            print(\"✅ LoRA适配器加载完成\")\n",
        "        else:\n",
        "            # 完整模型加载方式\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                outdir,\n",
        "                device_map=\"auto\",\n",
        "                torch_dtype=torch.float16,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "            print(\"✅ 完整模型加载完成\")\n",
        "\n",
        "        print(f\"📊 模型参数数量: {self.model.num_parameters():,}\")\n",
        "        print(f\"💻 模型设备: {self.model.device}\")\n",
        "\n",
        "    def generate_response(self, prompt, generation_config=None):\n",
        "        \"\"\"生成回复\"\"\"\n",
        "        if generation_config is None:\n",
        "            generation_config = {\n",
        "                \"max_new_tokens\": 256,\n",
        "                \"do_sample\": True,\n",
        "                \"temperature\": 0.1,\n",
        "                \"top_p\": 0.5,\n",
        "                \"repetition_penalty\": 1.1,\n",
        "                \"pad_token_id\": self.tokenizer.eos_token_id\n",
        "            }\n",
        "\n",
        "        # 编码输入\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
        "\n",
        "        # 生成\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                **generation_config\n",
        "            )\n",
        "\n",
        "        # 解码输出\n",
        "        full_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        generated_text = full_text[len(prompt):]\n",
        "\n",
        "        return full_text, generated_text\n",
        "\n",
        "    def test_validation_set(self, num_samples=10, save_results=False):\n",
        "        \"\"\"测试验证集\"\"\"\n",
        "        print(f\"\\n🧪 开始验证集测试 ({num_samples}个样本)\")\n",
        "\n",
        "        # 加载验证数据\n",
        "        with open(f\"{self.data_dir}/con_valid.jsonl\", 'r', encoding='utf-8') as f:\n",
        "            lines = [json.loads(l) for l in f][:num_samples]\n",
        "\n",
        "        results = []\n",
        "\n",
        "        for i, ex in enumerate(tqdm(lines, desc=\"测试进度\")):\n",
        "            prompt = f\"问：\\n{ex['prompt']}\\n答：\\n\"\n",
        "            expected_response = ex.get('response', '')\n",
        "\n",
        "            try:\n",
        "                full_text, generated_text = self.generate_response(prompt)\n",
        "\n",
        "                result = {\n",
        "                    \"id\": i,\n",
        "                    \"prompt\": ex['prompt'],\n",
        "                    \"expected\": expected_response,\n",
        "                    \"generated\": generated_text,\n",
        "                    \"full_output\": full_text\n",
        "                }\n",
        "                results.append(result)\n",
        "\n",
        "                # 打印结果\n",
        "                print(f\"\\n{'='*60}\")\n",
        "                print(f\"📝 样本 {i+1}:\")\n",
        "                print(f\"❓ 问题: {ex['prompt'][:100]}...\")\n",
        "                print(f\"🤖 生成回答: {generated_text.strip()}\")\n",
        "                print(f\"✅ 期望回答: {expected_response}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ 样本 {i+1} 生成失败: {e}\")\n",
        "                continue\n",
        "\n",
        "        # 保存结果\n",
        "        if save_results:\n",
        "            output_file = f\"{self.results_dir}/test_results.json\"\n",
        "            with open(output_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"\\n💾 测试结果已保存至: {output_file}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def interactive_mode(self):\n",
        "        \"\"\"交互式测试模式\"\"\"\n",
        "        print(\"\\n🎮 进入交互模式 (输入 'quit' 退出)\")\n",
        "\n",
        "        generation_configs = {\n",
        "            \"creative\": {\n",
        "                \"max_new_tokens\": 300,\n",
        "                \"do_sample\": True,\n",
        "                \"temperature\": 0.8,\n",
        "                \"top_p\": 0.9,\n",
        "                \"top_k\": 50\n",
        "            },\n",
        "            \"precise\": {\n",
        "                \"max_new_tokens\": 200,\n",
        "                \"do_sample\": False,  # 贪婪解码\n",
        "                \"temperature\": 1.0,\n",
        "                \"top_p\": 1.0\n",
        "            },\n",
        "            \"balanced\": {\n",
        "                \"max_new_tokens\": 256,\n",
        "                \"do_sample\": True,\n",
        "                \"temperature\": 0.7,\n",
        "                \"top_p\": 0.9\n",
        "            }\n",
        "        }\n",
        "\n",
        "        current_mode = \"balanced\"\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                user_input = input(f\"\\n💬 请输入问题 [{current_mode}模式]: \").strip()\n",
        "\n",
        "                if user_input.lower() in ['quit', 'exit', '退出']:\n",
        "                    break\n",
        "                elif user_input.lower() == 'mode':\n",
        "                    # 切换生成模式\n",
        "                    print(\"可用模式: creative, precise, balanced\")\n",
        "                    new_mode = input(\"选择模式: \").strip()\n",
        "                    if new_mode in generation_configs:\n",
        "                        current_mode = new_mode\n",
        "                        print(f\"✅ 切换到 {current_mode} 模式\")\n",
        "                    continue\n",
        "                elif not user_input:\n",
        "                    continue\n",
        "\n",
        "                prompt = f\"问：\\n{user_input}\\n答：\\n\"\n",
        "                full_text, generated_text = self.generate_response(\n",
        "                    prompt,\n",
        "                    generation_configs[current_mode]\n",
        "                )\n",
        "\n",
        "                print(f\"\\n🤖 模型回答 ({current_mode}模式):\")\n",
        "                print(f\"📝 {generated_text.strip()}\")\n",
        "\n",
        "            except KeyboardInterrupt:\n",
        "                print(\"\\n👋 退出交互模式\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"❌ 生成失败: {e}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"主函数\"\"\"\n",
        "    tester = ModelTester(CONFIGS_DIR, DATA_DIR, BASE_DIR, RESULTS_DIR)\n",
        "\n",
        "    try:\n",
        "        # 1. 加载模型\n",
        "        tester.load_model()\n",
        "\n",
        "        # 2. 验证集测试\n",
        "        tester.test_validation_set(num_samples=5, save_results=True)\n",
        "\n",
        "        # 3. 交互模式\n",
        "        #tester.interactive_mode()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 错误: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX5BFNfp5OJ0"
      },
      "source": [
        "### ROUGE-L scores & LLM-as-Judge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCCYjiDx5Nps",
        "outputId": "4f3488ec-61cd-427c-8101-17135754c5fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LLM-as-Judge评分: 100%|██████████| 5/5 [00:07<00:00,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   relevance  politeness  clarity  usefulness  professionalism  id\n",
            "0          2           4        3           2                3   0\n",
            "1          3           4        3           3                3   1\n",
            "2          4           5        4           4                5   2\n",
            "3          2           3        3           2                2   3\n",
            "4          5           5        5           4                5   4\n",
            "\n",
            "各维度平均分:\n",
            "relevance          3.2\n",
            "politeness         4.2\n",
            "clarity            3.6\n",
            "usefulness         3.0\n",
            "professionalism    3.6\n",
            "dtype: float64\n",
            "\n",
            "💾 评分结果已保存至: /content/drive/MyDrive/AIAA3102/Final_Project/Results/test_results_scores.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from openai import OpenAI\n",
        "import re\n",
        "# 配置客户端\n",
        "key = \"sk-GslHHRxrgakQY0XKiCNP2ZoFDU53bKtEuexTLjG3mmGflMlW\"  # 替换成你的实际 API key\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api2.aigcbest.top/v1\",\n",
        "    api_key=key\n",
        ")\n",
        "\n",
        "# 读取测试结果\n",
        "json_file = \"/content/drive/MyDrive/AIAA3102/Final_Project/Results/test_results.json\"\n",
        "with open(json_file, 'r', encoding='utf-8') as f:\n",
        "    results = json.load(f)\n",
        "\n",
        "def extract_json(text):\n",
        "    try:\n",
        "        # 匹配第一个大括号包裹的 JSON 对象\n",
        "        match = re.search(r'\\{.*\\}', text, re.DOTALL)\n",
        "        if match:\n",
        "            return json.loads(match.group())\n",
        "        else:\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(\"解析 JSON 失败:\", e)\n",
        "        return None\n",
        "\n",
        "# 创建评分 prompt\n",
        "def create_judge_prompt(prompt_text, generated_text):\n",
        "    return f\"\"\"\n",
        "你是心理咨询的评分专家，请根据以下维度对给定回答评分，每个维度 1-5 分（1 最差，5 最好），并严格输出 JSON 格式：\n",
        "\n",
        "维度：\n",
        "1. relevance: 回答是否直接回应了问题。\n",
        "2. politeness: 回答是否礼貌、有同理心。\n",
        "3. clarity: 回答是否易读、语言流畅。\n",
        "4. usefulness: 提供的建议是否具体、可操作。\n",
        "5. professionalism: 回答是否专业、安全、不会误导。\n",
        "\n",
        "问题: {prompt_text}\n",
        "模型回答: {generated_text}\n",
        "\n",
        "请输出如下 JSON:\n",
        "{{\"relevance\": , \"politeness\": , \"clarity\": , \"usefulness\": , \"professionalism\": }}\n",
        "\"\"\"\n",
        "\n",
        "# 批量评分\n",
        "scores = []\n",
        "\n",
        "for ex in tqdm(results, desc=\"LLM-as-Judge评分\"):\n",
        "    prompt_judge = create_judge_prompt(ex['prompt'], ex['generated'])\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt_judge}],\n",
        "            temperature=0\n",
        "        )\n",
        "        content = response.choices[0].message.content\n",
        "        score = extract_json(content)\n",
        "        if score is None:\n",
        "            print(f\"❌ 样本 {ex['id']} JSON 解析失败，跳过\")\n",
        "            continue\n",
        "        score['id'] = ex['id']\n",
        "        scores.append(score)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 样本 {ex['id']} 评分失败: {e}\")\n",
        "        continue\n",
        "\n",
        "# 转成 DataFrame\n",
        "df_scores = pd.DataFrame(scores)\n",
        "print(df_scores.head())\n",
        "\n",
        "# 计算平均分\n",
        "mean_scores = df_scores[['relevance','politeness','clarity','usefulness','professionalism']].mean()\n",
        "print(\"\\n各维度平均分:\")\n",
        "print(mean_scores)\n",
        "\n",
        "# 保存结果\n",
        "output_file = \"/content/drive/MyDrive/AIAA3102/Final_Project/Results/test_results_scores.json\"\n",
        "df_scores.to_json(output_file, orient='records', force_ascii=False, indent=2)\n",
        "print(f\"\\n💾 评分结果已保存至: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7BXE8jl5rWw",
        "outputId": "24bb4bfb-e0d9-4160-ee83-441e8a72643c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=78e0c6303ef1fe1216d354b89d46eca3911255af42dc5030c308e8a88502661b\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n",
            "   id  rougeL_f\n",
            "0   0  0.153846\n",
            "1   1  0.115502\n",
            "2   2  0.140078\n",
            "3   3  0.136170\n",
            "4   4  0.135678\n",
            "\n",
            "平均 ROUGE-L F1 分数: 0.1363\n",
            "💾 ROUGE-L 分数已保存至: /content/drive/MyDrive/AIAA3102/Final_Project/Results/test_results_rouge.json\n"
          ]
        }
      ],
      "source": [
        "!pip install  rouge_score\n",
        "import json\n",
        "from rouge_score import rouge_scorer\n",
        "import pandas as pd\n",
        "\n",
        "# 读取测试结果\n",
        "json_file = \"/content/drive/MyDrive/AIAA3102/Final_Project/Results/test_results.json\"\n",
        "with open(json_file, 'r', encoding='utf-8') as f:\n",
        "    results = json.load(f)\n",
        "\n",
        "# 创建 ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "\n",
        "# 存放分数\n",
        "rouge_scores = []\n",
        "\n",
        "for ex in results:\n",
        "    expected = ex.get('expected', '')\n",
        "    generated = ex.get('generated', '')\n",
        "    if expected.strip() == '' or generated.strip() == '':\n",
        "        continue\n",
        "\n",
        "    score = scorer.score(expected, generated)\n",
        "    rougeL_f = score['rougeL'].fmeasure  # F1 分数\n",
        "    rouge_scores.append({\n",
        "        'id': ex['id'],\n",
        "        'rougeL_f': rougeL_f\n",
        "    })\n",
        "\n",
        "# 转 DataFrame 查看\n",
        "df_rouge = pd.DataFrame(rouge_scores)\n",
        "print(df_rouge.head())\n",
        "\n",
        "# 计算平均 ROUGE-L F1\n",
        "mean_rougeL = df_rouge['rougeL_f'].mean()\n",
        "print(f\"\\n平均 ROUGE-L F1 分数: {mean_rougeL:.4f}\")\n",
        "\n",
        "# 可选择保存结果\n",
        "output_file = \"/content/drive/MyDrive/AIAA3102/Final_Project/Results/test_results_rouge.json\"\n",
        "df_rouge.to_json(output_file, orient='records', force_ascii=False, indent=2)\n",
        "print(f\"💾 ROUGE-L 分数已保存至: {output_file}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "038d4ef87fa74c53b9416ed79dd0c4ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2350a57bb4514b9b9d5e0f7899c275ff",
              "IPY_MODEL_ee5a096e552d417286b6c8a1f1fe7556",
              "IPY_MODEL_a6a6a8e9f59e4578977ca441a621106e"
            ],
            "layout": "IPY_MODEL_70dba67ec3224f8fb8b839914d716d47"
          }
        },
        "2350a57bb4514b9b9d5e0f7899c275ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TabModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TabModel",
            "_titles": {
              "0": "Training Parameters",
              "1": "LoRA Parameters",
              "2": "Data Parameters"
            },
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TabView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e915826245a243609d91de4dfecc4d39",
              "IPY_MODEL_ec60bfb2332a494bae0b4fd1d9fcf170",
              "IPY_MODEL_d0528b1f7b3b46c6909b1d0047f88bfe"
            ],
            "layout": "IPY_MODEL_73d449953c45453aa100920eac9b5469",
            "selected_index": 0
          }
        },
        "ee5a096e552d417286b6c8a1f1fe7556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49bfb3bb49454f499ae9492247e7a0c0",
              "IPY_MODEL_0b2df86222f2418c8fa24c809588e078",
              "IPY_MODEL_41bb550430984750a3714be37bea1fa6"
            ],
            "layout": "IPY_MODEL_f3a3777eab014b6a8388d4a2addfbad5"
          }
        },
        "a6a6a8e9f59e4578977ca441a621106e": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_f05146921d504673b745e9a0a619613e",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "🚀 Start Training...\n",
                  "Press 'Stop Training' to interrupt\n",
                  "\n",
                  "Command: python -u /content/drive/MyDrive/AIAA3102/Final_Project/Scripts/train_base.py --config_dir /content/drive/MyDrive/AIAA3102/Final_Project/Configs --train_file /content/drive/MyDrive/AIAA3102/Final_Project/Data/con_train.jsonl --valid_file /content/drive/MyDrive/AIAA3102/Final_Project/Data/con_valid.jsonl --overwrite_output_dir --num_train_epochs 2 --learning_rate 5e-05 --per_device_train_batch_size 16 --gradient_accumulation_steps 2 --max_train_samples 1500 --max_eval_samples 50 --use_lora True --use_qlora False --lora_rank 8 --lora_alpha 16\n",
                  "============================================================\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "2025-11-26 15:35:30.451131: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "E0000 00:00:1764171330.488127    1932 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "E0000 00:00:1764171330.503119    1932 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "W0000 00:00:1764171330.540959    1932 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "W0000 00:00:1764171330.540983    1932 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "W0000 00:00:1764171330.540985    1932 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "W0000 00:00:1764171330.540988    1932 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "/content/drive/MyDrive/AIAA3102/Final_Project/Scripts/train_base.py:535: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "trainer = Trainer(\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:   0%|          | 0/94 [00:00<?, ?step/s]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "⚠️ 0%|          | 0/94 [00:00<?, ?it/s]\u001b[A`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:   1%|          | 1/94 [00:10<16:15, 10.49s/step]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:   2%|▏         | 2/94 [00:19<14:55,  9.74s/step, loss=N/A, epoch=0.0213]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:   3%|▎         | 3/94 [00:29<14:31,  9.58s/step, loss=N/A, epoch=0.0426]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:   4%|▍         | 4/94 [00:38<14:12,  9.47s/step, loss=N/A, epoch=0.0638]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:   5%|▌         | 5/94 [00:47<13:57,  9.41s/step, loss=N/A, epoch=0.0851]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:   6%|▋         | 6/94 [00:57<13:46,  9.40s/step, loss=N/A, epoch=0.106]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:   7%|▋         | 7/94 [01:06<13:39,  9.42s/step, loss=N/A, epoch=0.128]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:   9%|▊         | 8/94 [01:16<13:36,  9.49s/step, loss=N/A, epoch=0.149]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  10%|▉         | 9/94 [01:25<13:31,  9.55s/step, loss=N/A, epoch=0.17]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  11%|█         | 10/94 [01:35<13:28,  9.63s/step, loss=N/A, epoch=0.191]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  12%|█▏        | 11/94 [01:45<13:27,  9.73s/step, loss=N/A, epoch=0.213]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  13%|█▎        | 12/94 [01:55<13:24,  9.81s/step, loss=N/A, epoch=0.234]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  14%|█▍        | 13/94 [02:05<13:17,  9.85s/step, loss=N/A, epoch=0.255]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  15%|█▍        | 14/94 [02:15<13:07,  9.84s/step, loss=N/A, epoch=0.277]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  16%|█▌        | 15/94 [02:25<12:54,  9.81s/step, loss=N/A, epoch=0.298]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  17%|█▋        | 16/94 [02:34<12:45,  9.82s/step, loss=N/A, epoch=0.319]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  18%|█▊        | 17/94 [02:45<12:41,  9.89s/step, loss=N/A, epoch=0.34]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  19%|█▉        | 18/94 [02:54<12:32,  9.91s/step, loss=N/A, epoch=0.362]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  20%|██        | 19/94 [03:04<12:24,  9.93s/step, loss=N/A, epoch=0.383]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  21%|██▏       | 20/94 [03:14<12:15,  9.93s/step, loss=N/A, epoch=0.404]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  22%|██▏       | 21/94 [03:24<12:06,  9.95s/step, loss=N/A, epoch=0.426]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  23%|██▎       | 22/94 [03:34<11:54,  9.92s/step, loss=N/A, epoch=0.447]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  24%|██▍       | 23/94 [03:44<11:41,  9.87s/step, loss=N/A, epoch=0.468]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  26%|██▌       | 24/94 [03:54<11:29,  9.85s/step, loss=N/A, epoch=0.489]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  27%|██▋       | 25/94 [04:04<11:18,  9.84s/step, loss=N/A, epoch=0.511]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  28%|██▊       | 26/94 [04:13<11:08,  9.83s/step, loss=N/A, epoch=0.532]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  29%|██▊       | 27/94 [04:23<10:59,  9.84s/step, loss=N/A, epoch=0.553]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  30%|██▉       | 28/94 [04:33<10:50,  9.86s/step, loss=N/A, epoch=0.574]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  31%|███       | 29/94 [04:43<10:42,  9.88s/step, loss=N/A, epoch=0.596]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  32%|███▏      | 30/94 [04:53<10:32,  9.89s/step, loss=N/A, epoch=0.617]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  33%|███▎      | 31/94 [05:03<10:21,  9.86s/step, loss=N/A, epoch=0.638]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  34%|███▍      | 32/94 [05:13<10:10,  9.85s/step, loss=N/A, epoch=0.66]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  35%|███▌      | 33/94 [05:22<10:00,  9.84s/step, loss=N/A, epoch=0.681]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  36%|███▌      | 34/94 [05:32<09:50,  9.85s/step, loss=N/A, epoch=0.702]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  37%|███▋      | 35/94 [05:42<09:41,  9.85s/step, loss=N/A, epoch=0.723]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  38%|███▊      | 36/94 [05:52<09:31,  9.85s/step, loss=N/A, epoch=0.745]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  39%|███▉      | 37/94 [06:02<09:21,  9.85s/step, loss=N/A, epoch=0.766]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  40%|████      | 38/94 [06:12<09:11,  9.84s/step, loss=N/A, epoch=0.787]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  41%|████▏     | 39/94 [06:22<09:01,  9.85s/step, loss=N/A, epoch=0.809]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  43%|████▎     | 40/94 [06:31<08:51,  9.85s/step, loss=N/A, epoch=0.83]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  44%|████▎     | 41/94 [06:41<08:41,  9.84s/step, loss=N/A, epoch=0.851]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  45%|████▍     | 42/94 [06:51<08:31,  9.83s/step, loss=N/A, epoch=0.872]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  46%|████▌     | 43/94 [07:01<08:21,  9.83s/step, loss=N/A, epoch=0.894]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  47%|████▋     | 44/94 [07:11<08:11,  9.83s/step, loss=N/A, epoch=0.915]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  48%|████▊     | 45/94 [07:21<08:01,  9.83s/step, loss=N/A, epoch=0.936]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  49%|████▉     | 46/94 [07:30<07:51,  9.83s/step, loss=N/A, epoch=0.957]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  50%|█████     | 47/94 [07:39<07:24,  9.46s/step, loss=N/A, epoch=0.979]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  51%|█████     | 48/94 [07:49<07:20,  9.58s/step, loss=N/A, epoch=1]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  52%|█████▏    | 49/94 [07:59<07:13,  9.64s/step, loss=N/A, epoch=1.02]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  53%|█████▎    | 50/94 [08:08<07:07,  9.71s/step, loss=N/A, epoch=1.04]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\u001b[A{'loss': 2.5262, 'grad_norm': 0.45251429080963135, 'learning_rate': 2.45e-05, 'epoch': 1.06}\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  54%|█████▍    | 51/94 [08:18<06:59,  9.75s/step, loss=N/A, epoch=1.06]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  55%|█████▌    | 52/94 [08:28<06:50,  9.76s/step, loss=2.5262, epoch=1.09]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  56%|█████▋    | 53/94 [08:38<06:41,  9.78s/step, loss=2.5262, epoch=1.11]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  57%|█████▋    | 54/94 [08:48<06:32,  9.80s/step, loss=2.5262, epoch=1.13]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  59%|█████▊    | 55/94 [08:58<06:23,  9.83s/step, loss=2.5262, epoch=1.15]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  60%|█████▉    | 56/94 [09:08<06:14,  9.84s/step, loss=2.5262, epoch=1.17]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  61%|██████    | 57/94 [09:17<06:03,  9.83s/step, loss=2.5262, epoch=1.19]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  62%|██████▏   | 58/94 [09:27<05:54,  9.84s/step, loss=2.5262, epoch=1.21]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  63%|██████▎   | 59/94 [09:37<05:44,  9.84s/step, loss=2.5262, epoch=1.23]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  64%|██████▍   | 60/94 [09:47<05:34,  9.85s/step, loss=2.5262, epoch=1.26]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  65%|██████▍   | 61/94 [09:57<05:25,  9.87s/step, loss=2.5262, epoch=1.28]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  66%|██████▌   | 62/94 [10:07<05:15,  9.86s/step, loss=2.5262, epoch=1.3]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  67%|██████▋   | 63/94 [10:17<05:05,  9.87s/step, loss=2.5262, epoch=1.32]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  68%|██████▊   | 64/94 [10:26<04:56,  9.87s/step, loss=2.5262, epoch=1.34]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  69%|██████▉   | 65/94 [10:36<04:46,  9.87s/step, loss=2.5262, epoch=1.36]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  70%|███████   | 66/94 [10:46<04:35,  9.85s/step, loss=2.5262, epoch=1.38]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  71%|███████▏  | 67/94 [10:56<04:26,  9.86s/step, loss=2.5262, epoch=1.4]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  72%|███████▏  | 68/94 [11:06<04:15,  9.84s/step, loss=2.5262, epoch=1.43]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  73%|███████▎  | 69/94 [11:16<04:06,  9.85s/step, loss=2.5262, epoch=1.45]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  74%|███████▍  | 70/94 [11:25<03:56,  9.84s/step, loss=2.5262, epoch=1.47]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  76%|███████▌  | 71/94 [11:35<03:46,  9.85s/step, loss=2.5262, epoch=1.49]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  77%|███████▋  | 72/94 [11:45<03:36,  9.86s/step, loss=2.5262, epoch=1.51]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  78%|███████▊  | 73/94 [11:55<03:26,  9.85s/step, loss=2.5262, epoch=1.53]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  79%|███████▊  | 74/94 [12:05<03:16,  9.85s/step, loss=2.5262, epoch=1.55]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  80%|███████▉  | 75/94 [12:15<03:07,  9.85s/step, loss=2.5262, epoch=1.57]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  81%|████████  | 76/94 [12:25<02:57,  9.86s/step, loss=2.5262, epoch=1.6]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  82%|████████▏ | 77/94 [12:34<02:47,  9.85s/step, loss=2.5262, epoch=1.62]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  83%|████████▎ | 78/94 [12:44<02:37,  9.85s/step, loss=2.5262, epoch=1.64]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  84%|████████▍ | 79/94 [12:54<02:27,  9.85s/step, loss=2.5262, epoch=1.66]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  85%|████████▌ | 80/94 [13:04<02:17,  9.85s/step, loss=2.5262, epoch=1.68]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  86%|████████▌ | 81/94 [13:14<02:08,  9.85s/step, loss=2.5262, epoch=1.7]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  87%|████████▋ | 82/94 [13:24<01:58,  9.87s/step, loss=2.5262, epoch=1.72]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  88%|████████▊ | 83/94 [13:34<01:48,  9.85s/step, loss=2.5262, epoch=1.74]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  89%|████████▉ | 84/94 [13:43<01:38,  9.85s/step, loss=2.5262, epoch=1.77]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  90%|█████████ | 85/94 [13:53<01:28,  9.84s/step, loss=2.5262, epoch=1.79]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  91%|█████████▏| 86/94 [14:03<01:18,  9.85s/step, loss=2.5262, epoch=1.81]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  93%|█████████▎| 87/94 [14:13<01:08,  9.85s/step, loss=2.5262, epoch=1.83]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  94%|█████████▎| 88/94 [14:23<00:58,  9.83s/step, loss=2.5262, epoch=1.85]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  95%|█████████▍| 89/94 [14:33<00:49,  9.83s/step, loss=2.5262, epoch=1.87]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  96%|█████████▌| 90/94 [14:42<00:39,  9.82s/step, loss=2.5262, epoch=1.89]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  97%|█████████▋| 91/94 [14:52<00:29,  9.83s/step, loss=2.5262, epoch=1.91]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  98%|█████████▊| 92/94 [15:02<00:19,  9.83s/step, loss=2.5262, epoch=1.94]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training:  99%|█████████▉| 93/94 [15:12<00:09,  9.81s/step, loss=2.5262, epoch=1.96]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Training: 100%|██████████| 94/94 [15:20<00:00,  9.45s/step, loss=2.5262, epoch=1.98]\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\u001b[A{'train_runtime': 921.5302, 'train_samples_per_second': 3.255, 'train_steps_per_second': 0.102, 'train_loss': 2.498774102393617, 'epoch': 2.0}\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "============================================================\n",
                  "✅ Training completed successfully!\n"
                ]
              }
            ]
          }
        },
        "70dba67ec3224f8fb8b839914d716d47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e915826245a243609d91de4dfecc4d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bca27627895c4eefbfc0e42f673ed1f8",
              "IPY_MODEL_02bda5ae65ff49eca7ca9d85dc9f9fde",
              "IPY_MODEL_d3c9668541634b68a038513ab04552bd",
              "IPY_MODEL_b07218a34540494aa195ebfd5b117bba"
            ],
            "layout": "IPY_MODEL_df2d7d6a1709475bb016d350f0dfb9cd"
          }
        },
        "ec60bfb2332a494bae0b4fd1d9fcf170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7cc58c0e36240498cc59f30f3613235",
              "IPY_MODEL_d8f95ea53f43460386e534c7a7e388d2",
              "IPY_MODEL_e1f2226b7c234302b49f703b7166ba24",
              "IPY_MODEL_4ac69b286b71499e84ba2c9bf53842dc"
            ],
            "layout": "IPY_MODEL_ba22222804bf439da3da75e78db8f348"
          }
        },
        "d0528b1f7b3b46c6909b1d0047f88bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee9f854d85b4403e814345e8d74140ce",
              "IPY_MODEL_74a1353dea3141289ecd823b3671dcf4"
            ],
            "layout": "IPY_MODEL_d44339678a37423791602eb36c905b56"
          }
        },
        "73d449953c45453aa100920eac9b5469": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49bfb3bb49454f499ae9492247e7a0c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Start Training",
            "disabled": false,
            "icon": "rocket",
            "layout": "IPY_MODEL_29b9be4a3a1e42d2ab6eeb2bd5e0a6b1",
            "style": "IPY_MODEL_0a9704453b534214b7a07e289d61df91",
            "tooltip": ""
          }
        },
        "0b2df86222f2418c8fa24c809588e078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "danger",
            "description": "Stop Training",
            "disabled": true,
            "icon": "stop",
            "layout": "IPY_MODEL_f5b2ce7a3f1344478c7352e1f1503da1",
            "style": "IPY_MODEL_572bf87b5da742eba8952e23ef05032a",
            "tooltip": ""
          }
        },
        "41bb550430984750a3714be37bea1fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "info",
            "description": "Save Settings",
            "disabled": false,
            "icon": "save",
            "layout": "IPY_MODEL_17a4f2b608ce467f8ad739ac1d59de7f",
            "style": "IPY_MODEL_87be1bb561b24cb9a061057fdae60943",
            "tooltip": ""
          }
        },
        "f3a3777eab014b6a8388d4a2addfbad5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bca27627895c4eefbfc0e42f673ed1f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": true,
            "description": "epoch:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_72e983d4a9474273b88638913e061559",
            "max": 20,
            "min": 1,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 1,
            "style": "IPY_MODEL_23c37f2b497041d8a0471787969287f0",
            "value": 2
          }
        },
        "02bda5ae65ff49eca7ca9d85dc9f9fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatLogSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatLogSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatLogSliderView",
            "base": 10,
            "continuous_update": true,
            "description": "learning rate:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_5b0ccc7ee64f4e8d84a6c6768c2b3d3b",
            "max": -3,
            "min": -6,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": ".3g",
            "step": 0.1,
            "style": "IPY_MODEL_f0d9ff174aec4f708024cfe21b8cd2cd",
            "value": 0.00005
          }
        },
        "d3c9668541634b68a038513ab04552bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": true,
            "description": "batch size:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_3e42affd65cc4861a79e56fefe7b174d",
            "max": 16,
            "min": 1,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 1,
            "style": "IPY_MODEL_88bece3f7fcb4ca7b24d5a5a871bab94",
            "value": 16
          }
        },
        "b07218a34540494aa195ebfd5b117bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": true,
            "description": "gradient accumulation steps:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_7a64d68638a74f35bb8897de18fbb620",
            "max": 16,
            "min": 1,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 1,
            "style": "IPY_MODEL_8bd0aaf4a7c142d2aa49c35b2ef3e91c",
            "value": 2
          }
        },
        "df2d7d6a1709475bb016d350f0dfb9cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7cc58c0e36240498cc59f30f3613235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Use LoRA",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_ee43947fabab441a9fab251869d6e850",
            "style": "IPY_MODEL_d8c25d93cc89478b9688b2f6d68b2f39",
            "value": true
          }
        },
        "d8f95ea53f43460386e534c7a7e388d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": true,
            "description": "LoRA rank:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_af98cedb370540b890087f101039e06d",
            "max": 64,
            "min": 4,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 4,
            "style": "IPY_MODEL_bb97041f5ae34eaa8a90c9d1f2ad97a0",
            "value": 8
          }
        },
        "e1f2226b7c234302b49f703b7166ba24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": true,
            "description": "LoRA Alpha:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b59cbf828c114d7bb8ba29d8a8c7cf7b",
            "max": 128,
            "min": 8,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 8,
            "style": "IPY_MODEL_94e1f99aa8a443ca9e2036d2f3ec9d1f",
            "value": 16
          }
        },
        "4ac69b286b71499e84ba2c9bf53842dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Use QLoRA (4-bit)",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_f7e46686608e4a4abb84952aadf42fc3",
            "style": "IPY_MODEL_c21200208c1147f1b3e555aa562278c3",
            "value": false
          }
        },
        "ba22222804bf439da3da75e78db8f348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee9f854d85b4403e814345e8d74140ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntTextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntTextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntTextView",
            "continuous_update": false,
            "description": "Max Train Samples:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_d6e9cb3ff487403586f30a9c329e478a",
            "step": 1,
            "style": "IPY_MODEL_240c090bdf8048369f792170d6d7e41d",
            "value": 1500
          }
        },
        "74a1353dea3141289ecd823b3671dcf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntTextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntTextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntTextView",
            "continuous_update": false,
            "description": "Max Eval Samples:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_63c426670e094dcbbb1e0653596addb4",
            "step": 1,
            "style": "IPY_MODEL_251197c8bf6d475d8eb824198507000c",
            "value": 50
          }
        },
        "d44339678a37423791602eb36c905b56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29b9be4a3a1e42d2ab6eeb2bd5e0a6b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a9704453b534214b7a07e289d61df91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f5b2ce7a3f1344478c7352e1f1503da1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "572bf87b5da742eba8952e23ef05032a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "17a4f2b608ce467f8ad739ac1d59de7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87be1bb561b24cb9a061057fdae60943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "72e983d4a9474273b88638913e061559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23c37f2b497041d8a0471787969287f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial",
            "handle_color": null
          }
        },
        "5b0ccc7ee64f4e8d84a6c6768c2b3d3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0d9ff174aec4f708024cfe21b8cd2cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial",
            "handle_color": null
          }
        },
        "3e42affd65cc4861a79e56fefe7b174d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88bece3f7fcb4ca7b24d5a5a871bab94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial",
            "handle_color": null
          }
        },
        "7a64d68638a74f35bb8897de18fbb620": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bd0aaf4a7c142d2aa49c35b2ef3e91c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial",
            "handle_color": null
          }
        },
        "ee43947fabab441a9fab251869d6e850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8c25d93cc89478b9688b2f6d68b2f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "af98cedb370540b890087f101039e06d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb97041f5ae34eaa8a90c9d1f2ad97a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial",
            "handle_color": null
          }
        },
        "b59cbf828c114d7bb8ba29d8a8c7cf7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94e1f99aa8a443ca9e2036d2f3ec9d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial",
            "handle_color": null
          }
        },
        "f7e46686608e4a4abb84952aadf42fc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c21200208c1147f1b3e555aa562278c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "d6e9cb3ff487403586f30a9c329e478a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "240c090bdf8048369f792170d6d7e41d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "63c426670e094dcbbb1e0653596addb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "251197c8bf6d475d8eb824198507000c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "f05146921d504673b745e9a0a619613e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}