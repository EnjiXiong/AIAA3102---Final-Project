{"cells":[{"cell_type":"markdown","metadata":{"id":"PawYFNTou8lw"},"source":["# Run train_base.py (LoRA / QLoRA) from Drive\n","æœ¬ Notebook åŒ…å«ä»¥ä¸‹æ­¥éª¤ï¼š\n","1. æŒ‚è½½ Google Driveï¼ˆè¯»å–ä½ å·²ä¿å­˜çš„ train_base.py / Configs / Dataï¼‰\n","2. å®‰è£…ä¾èµ–ï¼ˆtransformers, datasets, peft, bitsandbytes, accelerate, huggingface_hubï¼‰\n","3. è®¾ç½® HF_TOKENï¼ˆä» Colab Secrets / äº¤äº’è¾“å…¥ï¼‰\n","4. åšä¸€ä¸ªå°è§„æ¨¡ debug å­é›†å¹¶è¿è¡Œ train_base.py è¿›è¡Œå¿«é€Ÿ smoke-test\n","5.ï¼ˆå¯é€‰ï¼‰è¿è¡Œå®Œæ•´è®­ç»ƒ"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0QvgOtP5E-nl","executionInfo":{"status":"ok","timestamp":1763957841014,"user_tz":-480,"elapsed":41175,"user":{"displayName":"Andy","userId":"06581432161554596484"}},"outputId":"412567f2-14c2-4f74-868a-1b1454fe44a1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q-zMdRtmvJPf","outputId":"3127f93f-4f92-4765-e0f2-94d32bd2cb20","executionInfo":{"status":"ok","timestamp":1763380105906,"user_tz":-480,"elapsed":3011,"user":{"displayName":"Andy","userId":"06581432161554596484"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","BASE_DIR = /content/drive/MyDrive/AIAA3102/Final_Project\n","total 296\n","-rw------- 1 root root  67456 Nov 12 06:36 AIAA3102-FinalProject_Awareness_Ignorance.ipynb\n","-rw------- 1 root root 112736 Nov 14 16:38 AIAA3102_FinalProject_wyy_01.ipynb\n","-rw------- 1 root root  68111 Nov 17 11:47 AIAA3102_FinalProject_wyy_02.ipynb\n","drwx------ 2 root root   4096 Nov  9 10:48 Configs\n","drwx------ 2 root root   4096 Nov  9 10:48 Data\n","drwx------ 2 root root   4096 Nov  9 10:50 Deliverables\n","-rw------- 1 root root  24623 Nov 12 06:00 File_creator.ipynb\n","drwx------ 2 root root   4096 Nov  9 11:19 .ipynb_checkpoints\n","drwx------ 2 root root   4096 Nov  9 11:29 Models\n","drwx------ 2 root root   4096 Nov  9 10:48 Results\n","drwx------ 2 root root   4096 Nov  9 11:19 Scripts\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# ä¿®æ”¹ä¸ºä½ è‡ªå·±çš„é¡¹ç›®æ ¹ç›®å½•ï¼ˆä¸ train_base.py å†™å…¥ä½ç½®ä¸€è‡´ï¼‰\n","BASE_DIR = \"/content/drive/MyDrive/AIAA3102/Final_Project\"   # <- å¦‚æœå„ä½çš„è·¯å¾„ä¸åŒï¼Œè¯·ä¿®æ”¹\n","SCRIPTS_DIR = f\"{BASE_DIR}/Scripts\"\n","CONFIGS_DIR = f\"{BASE_DIR}/Configs\"\n","DATA_DIR = f\"{BASE_DIR}/Data\"\n","MODELS_DIR = f\"{BASE_DIR}/Models\"\n","\n","print(\"BASE_DIR =\", BASE_DIR)\n","!ls -la \"{BASE_DIR}\"\n"]},{"cell_type":"markdown","metadata":{"id":"ss8UocMimzA5"},"source":["# Install dependencies and import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rqURByA6msI4","outputId":"4330377f-fb3e-40d9-e563-76e0015894f6","executionInfo":{"status":"ok","timestamp":1763380342985,"user_tz":-480,"elapsed":7074,"user":{"displayName":"Andy","userId":"06581432161554596484"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n","Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.8.0+cu126)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.4.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n","Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.48.2\n"]}],"source":["!pip install transformers datasets peft bitsandbytes accelerate huggingface_hub\n","# éœ€è¦ä¸€ä¹ƒä¹ƒæ—¶é—´"]},{"cell_type":"markdown","metadata":{"id":"rHnE5d2fvX2T"},"source":["# Check Cuda"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7PutlfsRnEHM","outputId":"67810ea8-ff7b-4e35-ad72-9c628a9bbf37","executionInfo":{"status":"ok","timestamp":1763380399723,"user_tz":-480,"elapsed":54044,"user":{"displayName":"Andy","userId":"06581432161554596484"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n","from peft import LoraConfig, get_peft_model\n","import bitsandbytes as bnb\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n"]},{"cell_type":"markdown","metadata":{"id":"xZ9W8JJpnIB6"},"source":["# Ensure the configs/script/py files"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a-L2JXlAnUW0","outputId":"c19f9afd-20e7-4210-ce0c-90f5ff02faf3","executionInfo":{"status":"ok","timestamp":1763380419456,"user_tz":-480,"elapsed":739,"user":{"displayName":"Andy","userId":"06581432161554596484"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["script exists: True /content/drive/MyDrive/AIAA3102/Final_Project/Scripts/train_base.py\n","configs exists: True /content/drive/MyDrive/AIAA3102/Final_Project/Configs\n","train exists: True /content/drive/MyDrive/AIAA3102/Final_Project/Data/train.jsonl\n","valid exists: True /content/drive/MyDrive/AIAA3102/Final_Project/Data/valid.jsonl\n","unknown exists: True /content/drive/MyDrive/AIAA3102/Final_Project/Data/unknown_test.jsonl\n","\n","--- train.jsonl (first 3 lines) ---\n","{\"prompt\": \"Help debug this code snippet by adding comments with the appropriate error messages.\\ndef greetings(name):\\nnum = 5\\nmessage = \\\"Hello, \\\" + name + \\\"!\\\"\\nreturn message\", \"response\": \"def greetings(name):\\n    # assert name is a string\\n    assert isinstance(name, str), \\\"name must be a string\\\"\\n    num = 5\\n    # \\\"message\\\" variable should be defined before using it \\n    message = \\\"Hello, \\\" + name + \\\"!\\\"\\n    return message\"}\n","{\"prompt\": \"Create a JavaScript function which takes a string and returns the longest word in it.\\n\\\"This is an example string\\\"\", \"response\": \"function longestWord(str) { \\n    let words = str.split(' '); \\n    let longestWord = words.reduce((longest, current) => { \\n       if (current.length > longest.length) \\n          return current; \\n       else\\n          return longest; \\n    }, ''); \\n    return longestWord; \\n} \\n\\nconsole.log(longestWord(\\\"This is an example string\\\"));\"}\n","{\"prompt\": \"Write a function that takes in two arrays of integers and returns the sum of the elements in both arrays.\\narray1 = [1, 2, 3] \\narray2 = [4, 5, 6]\", \"response\": \"def sum_arrays(arr1, arr2):\\n    sums = []\\n    for i in range(len(arr1)):\\n        sums.append(arr1[i] + arr2[i])\\n    return sums\"}\n","\n","--- configs (list) ---\n","total 11\n","-rw------- 1 root root 1411 Nov  9 11:16 eval_config.yaml\n","drwx------ 2 root root 4096 Nov 17 11:33 .ipynb_checkpoints\n","-rw------- 1 root root  814 Nov  9 11:58 model_config.yaml\n","-rw------- 1 root root 1560 Nov 17 11:33 training_args0.yaml\n","-rw------- 1 root root 1580 Nov 14 16:38 training_args.yaml\n"]}],"source":["import os\n","paths = {\n","    \"script\": f\"{SCRIPTS_DIR}/train_base.py\",\n","    \"configs\": CONFIGS_DIR,\n","    \"train\": f\"{DATA_DIR}/train.jsonl\",\n","    \"valid\": f\"{DATA_DIR}/valid.jsonl\",\n","    \"unknown\": f\"{DATA_DIR}/unknown_test.jsonl\",\n","}\n","for k, p in paths.items():\n","    print(k, \"exists:\", os.path.exists(p), p)\n","\n","# æ‰“å°å‰å‡ è¡Œæ£€æŸ¥\n","print(\"\\n--- train.jsonl (first 3 lines) ---\")\n","!head -n 3 \"{paths['train']}\"\n","print(\"\\n--- configs (list) ---\")\n","!ls -la \"{CONFIGS_DIR}\"\n"]},{"cell_type":"markdown","metadata":{"id":"gAcnlA-CnW7b"},"source":["# Debug Dataset Generation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HsXvVXkHneIV","outputId":"fe9c3a62-4b38-4fc1-eab1-78812597041e","executionInfo":{"status":"ok","timestamp":1763380436471,"user_tz":-480,"elapsed":601,"user":{"displayName":"Andy","userId":"06581432161554596484"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Debug subsets created: /content/drive/MyDrive/AIAA3102/Final_Project/Data/train_debug.jsonl /content/drive/MyDrive/AIAA3102/Final_Project/Data/valid_debug.jsonl\n","  20 /content/drive/MyDrive/AIAA3102/Final_Project/Data/train_debug.jsonl\n","  10 /content/drive/MyDrive/AIAA3102/Final_Project/Data/valid_debug.jsonl\n","  30 total\n"]}],"source":["# Create tiny debug subsets to run a quick smoke-test (avoid long runs)\n","import shutil\n","from pathlib import Path\n","p_data = Path(DATA_DIR)\n","debug_train = p_data / \"train_debug.jsonl\"\n","debug_valid = p_data / \"valid_debug.jsonl\"\n","\n","def subset(src, dst, n=20):\n","    with open(src, 'r', encoding='utf-8') as rf, open(dst, 'w', encoding='utf-8') as wf:\n","        for i, line in enumerate(rf):\n","            if i >= n:\n","                break\n","            wf.write(line)\n","\n","subset(paths[\"train\"], debug_train, n=20)\n","subset(paths[\"valid\"], debug_valid, n=10)\n","print(\"Debug subsets created:\", debug_train, debug_valid)\n","!wc -l \"{debug_train}\" \"{debug_valid}\"\n"]},{"cell_type":"markdown","metadata":{"id":"G_AzrivIu7aC"},"source":[]},{"cell_type":"markdown","metadata":{"id":"TA6O5hegn2Eh"},"source":["**Training**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MIJUcC_0n4Ku","outputId":"dd84fbce-deaf-4cc6-fc68-22a55c7c8282"},"outputs":[{"output_type":"stream","name":"stdout","text":["2025-11-17 11:54:15.514191: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1763380455.546638    5503 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1763380455.556783    5503 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1763380455.580552    5503 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1763380455.580581    5503 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1763380455.580588    5503 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1763380455.580598    5503 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","tokenizer_config.json: 100% 776/776 [00:00<00:00, 7.09MB/s]\n","tokenizer.model: 100% 500k/500k [00:00<00:00, 872kB/s]\n","tokenizer.json: 1.84MB [00:00, 70.8MB/s]\n","special_tokens_map.json: 100% 414/414 [00:00<00:00, 4.05MB/s]\n","config.json: 100% 560/560 [00:00<00:00, 5.21MB/s]\n","pytorch_model.bin: 100% 4.40G/4.40G [00:53<00:00, 82.6MB/s]\n","generation_config.json: 100% 129/129 [00:00<00:00, 1.26MB/s]\n","Map: 100% 16013/16013 [00:06<00:00, 2581.26 examples/s]\n","Map: 100% 1000/1000 [00:00<00:00, 2737.16 examples/s]\n","/content/drive/MyDrive/AIAA3102/Final_Project/Scripts/train_base.py:253: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n","The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n","  0% 0/501 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n","{'loss': 4.8517, 'grad_norm': 0.0, 'learning_rate': 0.009021956087824351, 'epoch': 0.1}\n","{'loss': 10.4802, 'grad_norm': 0.0, 'learning_rate': 0.008023952095808383, 'epoch': 0.2}\n","{'loss': 10.48, 'grad_norm': 0.0, 'learning_rate': 0.007025948103792415, 'epoch': 0.3}\n","{'loss': 10.6125, 'grad_norm': 0.0, 'learning_rate': 0.006027944111776448, 'epoch': 0.4}\n"," 40% 200/501 [31:49<47:54,  9.55s/it]\n","  0% 0/100 [00:00<?, ?it/s]\u001b[A\n","  2% 2/100 [00:00<00:08, 11.99it/s]\u001b[A\n","  4% 4/100 [00:00<00:12,  7.52it/s]\u001b[A\n","  5% 5/100 [00:00<00:13,  6.93it/s]\u001b[A\n","  6% 6/100 [00:00<00:14,  6.56it/s]\u001b[A\n","  7% 7/100 [00:01<00:14,  6.33it/s]\u001b[A\n","  8% 8/100 [00:01<00:14,  6.20it/s]\u001b[A\n","  9% 9/100 [00:01<00:14,  6.10it/s]\u001b[A\n"," 10% 10/100 [00:01<00:14,  6.02it/s]\u001b[A\n"," 11% 11/100 [00:01<00:15,  5.91it/s]\u001b[A\n"," 12% 12/100 [00:01<00:14,  5.88it/s]\u001b[A\n"," 13% 13/100 [00:02<00:14,  5.83it/s]\u001b[A\n"," 14% 14/100 [00:02<00:14,  5.80it/s]\u001b[A\n"," 15% 15/100 [00:02<00:14,  5.79it/s]\u001b[A\n"," 16% 16/100 [00:02<00:14,  5.74it/s]\u001b[A\n"," 17% 17/100 [00:02<00:14,  5.71it/s]\u001b[A\n"," 18% 18/100 [00:02<00:14,  5.67it/s]\u001b[A\n"," 19% 19/100 [00:03<00:14,  5.65it/s]\u001b[A\n"," 20% 20/100 [00:03<00:14,  5.67it/s]\u001b[A\n"," 21% 21/100 [00:03<00:14,  5.63it/s]\u001b[A\n"," 22% 22/100 [00:03<00:13,  5.61it/s]\u001b[A\n"," 23% 23/100 [00:03<00:13,  5.60it/s]\u001b[A\n"," 24% 24/100 [00:04<00:13,  5.56it/s]\u001b[A\n"," 25% 25/100 [00:04<00:13,  5.54it/s]\u001b[A\n"," 26% 26/100 [00:04<00:13,  5.52it/s]\u001b[A\n"," 27% 27/100 [00:04<00:13,  5.50it/s]\u001b[A\n"," 28% 28/100 [00:04<00:13,  5.48it/s]\u001b[A\n"," 29% 29/100 [00:04<00:13,  5.46it/s]\u001b[A\n"," 30% 30/100 [00:05<00:12,  5.44it/s]\u001b[A\n"," 31% 31/100 [00:05<00:12,  5.44it/s]\u001b[A\n"," 32% 32/100 [00:05<00:12,  5.42it/s]\u001b[A\n"," 33% 33/100 [00:05<00:14,  4.66it/s]\u001b[A\n"," 34% 34/100 [00:05<00:14,  4.61it/s]\u001b[A\n"," 35% 35/100 [00:06<00:13,  4.82it/s]\u001b[A\n"," 36% 36/100 [00:06<00:12,  4.94it/s]\u001b[A\n"," 37% 37/100 [00:06<00:12,  5.03it/s]\u001b[A\n"," 38% 38/100 [00:06<00:16,  3.76it/s]\u001b[A\n"," 39% 39/100 [00:07<00:15,  4.06it/s]\u001b[A\n"," 40% 40/100 [00:07<00:13,  4.33it/s]\u001b[A\n"," 41% 41/100 [00:07<00:12,  4.54it/s]\u001b[A\n"," 42% 42/100 [00:07<00:15,  3.72it/s]\u001b[A\n"," 43% 43/100 [00:08<00:14,  4.02it/s]\u001b[A\n"," 44% 44/100 [00:08<00:12,  4.32it/s]\u001b[A\n"," 45% 45/100 [00:08<00:15,  3.55it/s]\u001b[A\n"," 46% 46/100 [00:08<00:13,  3.89it/s]\u001b[A\n"," 47% 47/100 [00:09<00:12,  4.18it/s]\u001b[A\n"," 48% 48/100 [00:09<00:15,  3.45it/s]\u001b[A\n"," 49% 49/100 [00:09<00:13,  3.80it/s]\u001b[A\n"," 50% 50/100 [00:09<00:12,  4.04it/s]\u001b[A\n"," 51% 51/100 [00:10<00:14,  3.29it/s]\u001b[A\n"," 52% 52/100 [00:10<00:13,  3.65it/s]\u001b[A\n"," 53% 53/100 [00:10<00:11,  3.94it/s]\u001b[A\n"," 54% 54/100 [00:11<00:14,  3.20it/s]\u001b[A\n"," 55% 55/100 [00:11<00:12,  3.56it/s]\u001b[A\n"," 56% 56/100 [00:11<00:13,  3.23it/s]\u001b[A\n"," 57% 57/100 [00:12<00:11,  3.61it/s]\u001b[A\n"," 58% 58/100 [00:12<00:12,  3.23it/s]\u001b[A\n"," 59% 59/100 [00:12<00:11,  3.59it/s]\u001b[A\n"," 60% 60/100 [00:13<00:12,  3.21it/s]\u001b[A\n"," 61% 61/100 [00:13<00:10,  3.57it/s]\u001b[A\n"," 62% 62/100 [00:13<00:12,  3.16it/s]\u001b[A\n"," 63% 63/100 [00:13<00:10,  3.53it/s]\u001b[A\n"," 64% 64/100 [00:14<00:11,  3.13it/s]\u001b[A\n"," 65% 65/100 [00:14<00:10,  3.50it/s]\u001b[A\n"," 66% 66/100 [00:14<00:11,  3.09it/s]\u001b[A\n"," 67% 67/100 [00:15<00:09,  3.45it/s]\u001b[A\n"," 68% 68/100 [00:15<00:10,  3.04it/s]\u001b[A\n"," 69% 69/100 [00:15<00:09,  3.41it/s]\u001b[A\n"," 70% 70/100 [00:16<00:10,  2.99it/s]\u001b[A\n"," 71% 71/100 [00:16<00:08,  3.36it/s]\u001b[A\n"," 72% 72/100 [00:16<00:09,  2.95it/s]\u001b[A\n"," 73% 73/100 [00:17<00:09,  2.97it/s]\u001b[A\n"," 74% 74/100 [00:17<00:08,  2.96it/s]\u001b[A\n"," 75% 75/100 [00:17<00:08,  2.95it/s]\u001b[A\n"," 76% 76/100 [00:18<00:08,  2.93it/s]\u001b[A\n"," 77% 77/100 [00:18<00:07,  2.92it/s]\u001b[A\n"," 78% 78/100 [00:18<00:07,  2.91it/s]\u001b[A\n"," 79% 79/100 [00:19<00:07,  2.90it/s]\u001b[A\n"," 80% 80/100 [00:19<00:06,  2.88it/s]\u001b[A\n"," 81% 81/100 [00:19<00:06,  2.86it/s]\u001b[A\n"," 82% 82/100 [00:20<00:06,  2.83it/s]\u001b[A\n"," 83% 83/100 [00:20<00:06,  2.82it/s]\u001b[A\n"," 84% 84/100 [00:20<00:05,  2.80it/s]\u001b[A\n"," 85% 85/100 [00:21<00:05,  2.78it/s]\u001b[A\n"," 86% 86/100 [00:21<00:05,  2.73it/s]\u001b[A\n"," 87% 87/100 [00:22<00:04,  2.72it/s]\u001b[A\n"," 88% 88/100 [00:22<00:04,  2.68it/s]\u001b[A\n"," 89% 89/100 [00:22<00:04,  2.66it/s]\u001b[A\n"," 90% 90/100 [00:23<00:03,  2.65it/s]\u001b[A\n"," 91% 91/100 [00:23<00:03,  2.62it/s]\u001b[A\n"," 92% 92/100 [00:24<00:03,  2.62it/s]\u001b[A\n"," 93% 93/100 [00:24<00:02,  2.61it/s]\u001b[A\n"," 94% 94/100 [00:24<00:02,  2.61it/s]\u001b[A\n"," 95% 95/100 [00:25<00:01,  2.60it/s]\u001b[A\n"," 96% 96/100 [00:25<00:01,  2.59it/s]\u001b[A\n"," 97% 97/100 [00:25<00:01,  2.58it/s]\u001b[A\n"," 98% 98/100 [00:26<00:00,  2.57it/s]\u001b[A\n"," 99% 99/100 [00:26<00:00,  2.56it/s]\u001b[A\n","                                     \n","\u001b[A{'eval_loss': 10.03968334197998, 'eval_runtime': 32.0768, 'eval_samples_per_second': 3.118, 'eval_steps_per_second': 3.118, 'epoch': 0.4}\n"," 40% 200/501 [32:21<47:54,  9.55s/it]\n","100% 100/100 [00:31<00:00,  2.55it/s]\u001b[A\n","{'loss': 10.5243, 'grad_norm': 0.0, 'learning_rate': 0.0050299401197604785, 'epoch': 0.5}\n"," 55% 276/501 [44:28<35:47,  9.54s/it]"]}],"source":["# è¿™ä¸ªæ˜¯debugçš„å‘½ä»¤\n","# æ³¨æ„ï¼š--config_dir æŒ‡å‘ä½  Drive ä¸‹çš„ Configs æ–‡ä»¶å¤¹\n","'''\n","!python \"{SCRIPTS_DIR}/train_base.py\" \\\n","  --config_dir \"{CONFIGS_DIR}\" \\\n","  --train_file \"{DATA_DIR}/train_debug.jsonl\" \\\n","  --valid_file \"{DATA_DIR}/valid_debug.jsonl\" \\\n","  --overwrite_output_dir \\\n","  --num_train_epochs 5 \\\n","  --learning_rate 3e-4 \\\n","  --per_device_train_batch_size 4 \\\n","  --gradient_accumulation_steps 2\n","  '''\n","\n","# è¿™ä¸ªæ˜¯æ­£å¼è¿è¡Œçš„å‘½ä»¤\n","# æ­£å¼è®­ç»ƒï¼ˆæŒ‰ configs æŒ‡å®šçš„è¶…å‚\n","!python \"{SCRIPTS_DIR}/train_base.py\" \\\n","  --config_dir \"{CONFIGS_DIR}\" \\\n","  --train_file \"{DATA_DIR}/train.jsonl\" \\\n","  --valid_file \"{DATA_DIR}/valid.jsonl\" \\\n","  --overwrite_output_dir \\\n","  --num_train_epochs 1 \\\n","  --learning_rate 1e-2 \\\n","  --per_device_train_batch_size 32 \\\n","  --metric_for_best_model \"eval_loss\""]},{"cell_type":"code","source":["!cp -r /content/models/tinyllama_ai_finetuned_02 /content/drive/MyDrive/AIAA3102/Final_Project/Models"],"metadata":{"id":"daSoVEjeyCpB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rsync -av --delete --progress /content/drive/MyDrive/AIAA3102/Final_Project/Models/tinyllama_ai_finetuned/ /content/models/tinyllama_ai_finetuned/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"92nsz3uBaTe-","outputId":"3e818f5a-e6ba-4977-ba2e-a02203d80e3b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sending incremental file list\n","deleting tinyllama_ai_finetuned_02/checkpoint-501/training_args.bin\n","deleting tinyllama_ai_finetuned_02/checkpoint-501/trainer_state.json\n","deleting tinyllama_ai_finetuned_02/checkpoint-501/tokenizer_config.json\n","deleting tinyllama_ai_finetuned_02/checkpoint-501/tokenizer.model\n","deleting tinyllama_ai_finetuned_02/checkpoint-501/tokenizer.json\n","deleting tinyllama_ai_finetuned_02/checkpoint-501/special_tokens_map.json\n","deleting tinyllama_ai_finetuned_02/checkpoint-501/scheduler.pt\n","deleting tinyllama_ai_finetuned_02/checkpoint-501/scaler.pt\n","deleting tinyllama_ai_finetuned_02/checkpoint-501/rng_state.pth\n","deleting tinyllama_ai_finetuned_02/checkpoint-501/optimizer.pt\n","deleting tinyllama_ai_finetuned_02/checkpoint-501/adapter_model.safetensors\n","deleting tinyllama_ai_finetuned_02/checkpoint-501/adapter_config.json\n","deleting tinyllama_ai_finetuned_02/checkpoint-501/README.md\n","deleting tinyllama_ai_finetuned_02/checkpoint-501/\n","deleting tinyllama_ai_finetuned_02/checkpoint-400/training_args.bin\n","deleting tinyllama_ai_finetuned_02/checkpoint-400/trainer_state.json\n","deleting tinyllama_ai_finetuned_02/checkpoint-400/tokenizer_config.json\n","deleting tinyllama_ai_finetuned_02/checkpoint-400/tokenizer.model\n","deleting tinyllama_ai_finetuned_02/checkpoint-400/tokenizer.json\n","deleting tinyllama_ai_finetuned_02/checkpoint-400/special_tokens_map.json\n","deleting tinyllama_ai_finetuned_02/checkpoint-400/scheduler.pt\n","deleting tinyllama_ai_finetuned_02/checkpoint-400/scaler.pt\n","deleting tinyllama_ai_finetuned_02/checkpoint-400/rng_state.pth\n","deleting tinyllama_ai_finetuned_02/checkpoint-400/optimizer.pt\n","deleting tinyllama_ai_finetuned_02/checkpoint-400/adapter_model.safetensors\n","deleting tinyllama_ai_finetuned_02/checkpoint-400/adapter_config.json\n","deleting tinyllama_ai_finetuned_02/checkpoint-400/README.md\n","deleting tinyllama_ai_finetuned_02/checkpoint-400/\n","deleting tinyllama_ai_finetuned_02/checkpoint-200/training_args.bin\n","deleting tinyllama_ai_finetuned_02/checkpoint-200/trainer_state.json\n","deleting tinyllama_ai_finetuned_02/checkpoint-200/tokenizer_config.json\n","deleting tinyllama_ai_finetuned_02/checkpoint-200/tokenizer.model\n","deleting tinyllama_ai_finetuned_02/checkpoint-200/tokenizer.json\n","deleting tinyllama_ai_finetuned_02/checkpoint-200/special_tokens_map.json\n","deleting tinyllama_ai_finetuned_02/checkpoint-200/scheduler.pt\n","deleting tinyllama_ai_finetuned_02/checkpoint-200/scaler.pt\n","deleting tinyllama_ai_finetuned_02/checkpoint-200/rng_state.pth\n","deleting tinyllama_ai_finetuned_02/checkpoint-200/optimizer.pt\n","deleting tinyllama_ai_finetuned_02/checkpoint-200/adapter_model.safetensors\n","deleting tinyllama_ai_finetuned_02/checkpoint-200/adapter_config.json\n","deleting tinyllama_ai_finetuned_02/checkpoint-200/README.md\n","deleting tinyllama_ai_finetuned_02/checkpoint-200/\n","deleting tinyllama_ai_finetuned_02/tokenizer_config.json\n","deleting tinyllama_ai_finetuned_02/tokenizer.model\n","deleting tinyllama_ai_finetuned_02/tokenizer.json\n","deleting tinyllama_ai_finetuned_02/special_tokens_map.json\n","deleting tinyllama_ai_finetuned_02/adapter_model.safetensors\n","deleting tinyllama_ai_finetuned_02/adapter_config.json\n","deleting tinyllama_ai_finetuned_02/README.md\n","deleting tinyllama_ai_finetuned_02/\n","deleting tinyllama_ai_finetuned/checkpoint-2002/training_args.bin\n","deleting tinyllama_ai_finetuned/checkpoint-2002/trainer_state.json\n","deleting tinyllama_ai_finetuned/checkpoint-2002/tokenizer_config.json\n","deleting tinyllama_ai_finetuned/checkpoint-2002/tokenizer.model\n","deleting tinyllama_ai_finetuned/checkpoint-2002/tokenizer.json\n","deleting tinyllama_ai_finetuned/checkpoint-2002/special_tokens_map.json\n","deleting tinyllama_ai_finetuned/checkpoint-2002/scheduler.pt\n","deleting tinyllama_ai_finetuned/checkpoint-2002/scaler.pt\n","deleting tinyllama_ai_finetuned/checkpoint-2002/rng_state.pth\n","deleting tinyllama_ai_finetuned/checkpoint-2002/optimizer.pt\n","deleting tinyllama_ai_finetuned/checkpoint-2002/adapter_model.safetensors\n","deleting tinyllama_ai_finetuned/checkpoint-2002/adapter_config.json\n","deleting tinyllama_ai_finetuned/checkpoint-2002/README.md\n","deleting tinyllama_ai_finetuned/checkpoint-2002/\n","deleting tinyllama_ai_finetuned/checkpoint-2000/training_args.bin\n","deleting tinyllama_ai_finetuned/checkpoint-2000/trainer_state.json\n","deleting tinyllama_ai_finetuned/checkpoint-2000/tokenizer_config.json\n","deleting tinyllama_ai_finetuned/checkpoint-2000/tokenizer.model\n","deleting tinyllama_ai_finetuned/checkpoint-2000/tokenizer.json\n","deleting tinyllama_ai_finetuned/checkpoint-2000/special_tokens_map.json\n","deleting tinyllama_ai_finetuned/checkpoint-2000/scheduler.pt\n","deleting tinyllama_ai_finetuned/checkpoint-2000/scaler.pt\n","deleting tinyllama_ai_finetuned/checkpoint-2000/rng_state.pth\n","deleting tinyllama_ai_finetuned/checkpoint-2000/optimizer.pt\n","deleting tinyllama_ai_finetuned/checkpoint-2000/adapter_model.safetensors\n","deleting tinyllama_ai_finetuned/checkpoint-2000/adapter_config.json\n","deleting tinyllama_ai_finetuned/checkpoint-2000/README.md\n","deleting tinyllama_ai_finetuned/checkpoint-2000/\n","deleting tinyllama_ai_finetuned/checkpoint-1600/training_args.bin\n","deleting tinyllama_ai_finetuned/checkpoint-1600/trainer_state.json\n","deleting tinyllama_ai_finetuned/checkpoint-1600/tokenizer_config.json\n","deleting tinyllama_ai_finetuned/checkpoint-1600/tokenizer.model\n","deleting tinyllama_ai_finetuned/checkpoint-1600/tokenizer.json\n","deleting tinyllama_ai_finetuned/checkpoint-1600/special_tokens_map.json\n","deleting tinyllama_ai_finetuned/checkpoint-1600/scheduler.pt\n","deleting tinyllama_ai_finetuned/checkpoint-1600/scaler.pt\n","deleting tinyllama_ai_finetuned/checkpoint-1600/rng_state.pth\n","deleting tinyllama_ai_finetuned/checkpoint-1600/optimizer.pt\n","deleting tinyllama_ai_finetuned/checkpoint-1600/adapter_model.safetensors\n","deleting tinyllama_ai_finetuned/checkpoint-1600/adapter_config.json\n","deleting tinyllama_ai_finetuned/checkpoint-1600/README.md\n","deleting tinyllama_ai_finetuned/checkpoint-1600/\n","deleting tinyllama_ai_finetuned/tokenizer_config.json\n","deleting tinyllama_ai_finetuned/tokenizer.model\n","deleting tinyllama_ai_finetuned/tokenizer.json\n","deleting tinyllama_ai_finetuned/special_tokens_map.json\n","deleting tinyllama_ai_finetuned/adapter_model.safetensors\n","deleting tinyllama_ai_finetuned/adapter_config.json\n","deleting tinyllama_ai_finetuned/README.md\n","deleting tinyllama_ai_finetuned/\n","deleting checkpoint-501/training_args.bin\n","deleting checkpoint-501/trainer_state.json\n","deleting checkpoint-501/tokenizer_config.json\n","deleting checkpoint-501/tokenizer.model\n","deleting checkpoint-501/tokenizer.json\n","deleting checkpoint-501/special_tokens_map.json\n","deleting checkpoint-501/scheduler.pt\n","deleting checkpoint-501/scaler.pt\n","deleting checkpoint-501/rng_state.pth\n","deleting checkpoint-501/optimizer.pt\n","deleting checkpoint-501/adapter_model.safetensors\n","deleting checkpoint-501/adapter_config.json\n","deleting checkpoint-501/README.md\n","deleting checkpoint-501/\n","deleting checkpoint-400/training_args.bin\n","deleting checkpoint-400/trainer_state.json\n","deleting checkpoint-400/tokenizer_config.json\n","deleting checkpoint-400/tokenizer.model\n","deleting checkpoint-400/tokenizer.json\n","deleting checkpoint-400/special_tokens_map.json\n","deleting checkpoint-400/scheduler.pt\n","deleting checkpoint-400/scaler.pt\n","deleting checkpoint-400/rng_state.pth\n","deleting checkpoint-400/optimizer.pt\n","deleting checkpoint-400/adapter_model.safetensors\n","deleting checkpoint-400/adapter_config.json\n","deleting checkpoint-400/README.md\n","deleting checkpoint-400/\n","deleting checkpoint-200/training_args.bin\n","deleting checkpoint-200/trainer_state.json\n","deleting checkpoint-200/tokenizer_config.json\n","deleting checkpoint-200/tokenizer.model\n","deleting checkpoint-200/tokenizer.json\n","deleting checkpoint-200/special_tokens_map.json\n","deleting checkpoint-200/scheduler.pt\n","deleting checkpoint-200/scaler.pt\n","deleting checkpoint-200/rng_state.pth\n","deleting checkpoint-200/optimizer.pt\n","deleting checkpoint-200/adapter_model.safetensors\n","deleting checkpoint-200/adapter_config.json\n","deleting checkpoint-200/README.md\n","deleting checkpoint-200/\n","./\n","README.md\n","\r          5,202 100%    0.00kB/s    0:00:00  \r          5,202 100%    0.00kB/s    0:00:00 (xfr#1, to-chk=48/50)\n","adapter_config.json\n","\r            885 100%  432.13kB/s    0:00:00  \r            885 100%  432.13kB/s    0:00:00 (xfr#2, to-chk=47/50)\n","adapter_model.safetensors\n","\r         32,768   0%    2.40MB/s    0:00:03  \r      9,034,304 100%  239.33MB/s    0:00:00 (xfr#3, to-chk=46/50)\n","special_tokens_map.json\n","\r            437 100%   11.53kB/s    0:00:00  \r            437 100%   11.53kB/s    0:00:00 (xfr#4, to-chk=45/50)\n","tokenizer.json\n","\r         32,768   0%  800.00kB/s    0:00:04  \r      3,619,280 100%   59.51MB/s    0:00:00 (xfr#5, to-chk=44/50)\n","tokenizer.model\n","\r         32,768   6%  533.33kB/s    0:00:00  \r        499,723 100%    7.45MB/s    0:00:00 (xfr#6, to-chk=43/50)\n","tokenizer_config.json\n","\r            978 100%   14.69kB/s    0:00:00  \r            978 100%   14.69kB/s    0:00:00 (xfr#7, to-chk=42/50)\n","checkpoint-1600/\n","checkpoint-1600/README.md\n","\r          5,202 100%   76.97kB/s    0:00:00  \r          5,202 100%   76.97kB/s    0:00:00 (xfr#8, to-chk=38/50)\n","checkpoint-1600/adapter_config.json\n","\r            885 100%   12.71kB/s    0:00:00  \r            885 100%   12.71kB/s    0:00:00 (xfr#9, to-chk=37/50)\n","checkpoint-1600/adapter_model.safetensors\n","\r         32,768   0%  450.70kB/s    0:00:19  \r      9,034,304 100%   91.66MB/s    0:00:00 (xfr#10, to-chk=36/50)\n","checkpoint-1600/optimizer.pt\n","     18,173,131 100%  116.32MB/s    0:00:00 (xfr#11, to-chk=35/50)\n","checkpoint-1600/rng_state.pth\n","         14,645 100%   94.71kB/s    0:00:00 (xfr#12, to-chk=34/50)\n","checkpoint-1600/scaler.pt\n","          1,383 100%    8.71kB/s    0:00:00 (xfr#13, to-chk=33/50)\n","checkpoint-1600/scheduler.pt\n","          1,465 100%    9.05kB/s    0:00:00 (xfr#14, to-chk=32/50)\n","checkpoint-1600/special_tokens_map.json\n","            437 100%    2.67kB/s    0:00:00 (xfr#15, to-chk=31/50)\n","checkpoint-1600/tokenizer.json\n","      3,619,280 100%   19.50MB/s    0:00:00 (xfr#16, to-chk=30/50)\n","checkpoint-1600/tokenizer.model\n","        499,723 100%    2.62MB/s    0:00:00 (xfr#17, to-chk=29/50)\n","checkpoint-1600/tokenizer_config.json\n","            978 100%    5.22kB/s    0:00:00 (xfr#18, to-chk=28/50)\n","checkpoint-1600/trainer_state.json\n","          7,643 100%   40.35kB/s    0:00:00 (xfr#19, to-chk=27/50)\n","checkpoint-1600/training_args.bin\n","          5,841 100%   30.50kB/s    0:00:00 (xfr#20, to-chk=26/50)\n","checkpoint-2000/\n","checkpoint-2000/README.md\n","          5,202 100%   26.88kB/s    0:00:00 (xfr#21, to-chk=25/50)\n","checkpoint-2000/adapter_config.json\n","            885 100%    4.55kB/s    0:00:00 (xfr#22, to-chk=24/50)\n","checkpoint-2000/adapter_model.safetensors\n","      9,034,304 100%   36.82MB/s    0:00:00 (xfr#23, to-chk=23/50)\n","checkpoint-2000/optimizer.pt\n","     18,173,131 100%   51.89MB/s    0:00:00 (xfr#24, to-chk=22/50)\n","checkpoint-2000/rng_state.pth\n","         14,645 100%   42.44kB/s    0:00:00 (xfr#25, to-chk=21/50)\n","checkpoint-2000/scaler.pt\n","          1,383 100%    3.85kB/s    0:00:00 (xfr#26, to-chk=20/50)\n","checkpoint-2000/scheduler.pt\n","          1,465 100%    3.99kB/s    0:00:00 (xfr#27, to-chk=19/50)\n","checkpoint-2000/special_tokens_map.json\n","            437 100%    1.17kB/s    0:00:00 (xfr#28, to-chk=18/50)\n","checkpoint-2000/tokenizer.json\n","      3,619,280 100%    8.87MB/s    0:00:00 (xfr#29, to-chk=17/50)\n","checkpoint-2000/tokenizer.model\n","        499,723 100%    1.21MB/s    0:00:00 (xfr#30, to-chk=16/50)\n","checkpoint-2000/tokenizer_config.json\n","            978 100%    2.41kB/s    0:00:00 (xfr#31, to-chk=15/50)\n","checkpoint-2000/trainer_state.json\n","          9,345 100%   22.93kB/s    0:00:00 (xfr#32, to-chk=14/50)\n","checkpoint-2000/training_args.bin\n","          5,841 100%   14.26kB/s    0:00:00 (xfr#33, to-chk=13/50)\n","checkpoint-2002/\n","checkpoint-2002/README.md\n","          5,202 100%   12.67kB/s    0:00:00 (xfr#34, to-chk=12/50)\n","checkpoint-2002/adapter_config.json\n","            885 100%    2.14kB/s    0:00:00 (xfr#35, to-chk=11/50)\n","checkpoint-2002/adapter_model.safetensors\n","      9,034,304 100%   19.99MB/s    0:00:00 (xfr#36, to-chk=10/50)\n","checkpoint-2002/optimizer.pt\n","     18,173,131 100%   34.12MB/s    0:00:00 (xfr#37, to-chk=9/50)\n","checkpoint-2002/rng_state.pth\n","         14,645 100%   27.77kB/s    0:00:00 (xfr#38, to-chk=8/50)\n","checkpoint-2002/scaler.pt\n","          1,383 100%    2.60kB/s    0:00:00 (xfr#39, to-chk=7/50)\n","checkpoint-2002/scheduler.pt\n","          1,465 100%    2.75kB/s    0:00:00 (xfr#40, to-chk=6/50)\n","checkpoint-2002/special_tokens_map.json\n","            437 100%    0.82kB/s    0:00:00 (xfr#41, to-chk=5/50)\n","checkpoint-2002/tokenizer.json\n","      3,619,280 100%    6.37MB/s    0:00:00 (xfr#42, to-chk=4/50)\n","checkpoint-2002/tokenizer.model\n","        499,723 100%  892.16kB/s    0:00:00 (xfr#43, to-chk=3/50)\n","checkpoint-2002/tokenizer_config.json\n","            978 100%    1.74kB/s    0:00:00 (xfr#44, to-chk=2/50)\n","checkpoint-2002/trainer_state.json\n","          9,332 100%   16.57kB/s    0:00:00 (xfr#45, to-chk=1/50)\n","checkpoint-2002/training_args.bin\n","          5,841 100%   10.33kB/s    0:00:00 (xfr#46, to-chk=0/50)\n","\n","sent 107,288,162 bytes  received 7,982 bytes  214,592,288.00 bytes/sec\n","total size is 107,258,951  speedup is 1.00\n"]}]},{"cell_type":"markdown","metadata":{"id":"kxuwlg5IoCR-"},"source":["# Quick Assessment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fx0NlWcPoHHG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dbc10c9e-76fd-4a7f-ced3-516030be21d2","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Expecting model at: models/tinyllama_ai_finetuned\n"]},{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["========================================\n","PROMPT: ### é—®ï¼š\n","Create a function in C to check whether a given string contains any punctuations or not.\n","### ç­”ï¼š\n","\n","OUTPUT: ### é—®ï¼š\n","Create a function in C to check whether a given string contains any punctuations or not.\n","### ç­”ï¼š\n","\n","### ç­”swers\n","\n","### ç­”swers\n","\n","### ç­”swers\n","\n","### ç­”swers\n","\n","### ç­”swers\n","\n","### ç­”swers\n","\n","### ç­”swers\n","\n","### ç­”swers\n","\n","### ç­”swers\n","\n","### ç­”swers\n","\n","### ç­”swers\n","\n","### ç­”swers\n","\n","### ç­”swers\n","\n","### ç­”swers\n","\n","##\n","========================================\n","PROMPT: ### é—®ï¼š\n","Design a function in PHP that takes two strings as input and return true if the strings are an anagram of each other.\n","string1 = â€œlistenâ€\n","string2 = â€œsilentâ€\n","### ç­”ï¼š\n","\n","OUTPUT: ### é—®ï¼š\n","Design a function in PHP that takes two strings as input and return true if the strings are an anagram of each other.\n","string1 = â€œlistenâ€\n","string2 = â€œsilentâ€\n","### ç­”ï¼š\n","string1 = string2\n","string2 = string1\n","### ç­”è€Œé\n","string1 = string2\n","string2 = string1\n","### ç­”è€Œé\n","string1 = string2\n","string2 = string1\n","### ç­”è€Œé\n","string1 = string2\n","string2 = string1\n","### ç­”è€Œé\n","string1 = string2\n","string2 = string1\n","### ç­”è€Œé\n","string1 = string2\n","string2 = string1\n","### ç­”è€Œé\n","string1\n","========================================\n","PROMPT: ### é—®ï¼š\n","Create a custom exception class for a restaurant that has no menu items.\n","### ç­”ï¼š\n","\n","OUTPUT: ### é—®ï¼š\n","Create a custom exception class for a restaurant that has no menu items.\n","### ç­”ï¼š\n","\n","Create a custom exception class for a restaurant that has no menu items.\n","\n","### ç­”åº”çš„é—®é¢˜\n","\n","What is the difference between the two methods?\n","\n","### ç­”åº”çš„é—®é¢˜\n","\n","What is the difference between the two methods?\n","\n","### ç­”åº”çš„é—®é¢˜\n","\n","What is the difference between the two methods?\n","\n","### ç­”åº”çš„é—®é¢˜\n","\n","What is the difference between the two methods?\n","\n","### ç­”åº”çš„é—®é¢˜\n","\n","What is the difference between the two\n","========================================\n","PROMPT: ### é—®ï¼š\n","Using JavaScript, write a function that takes a string as an argument and prints out whether the string is a Palindrome.\n","str = \"racecar\"\n","### ç­”ï¼š\n","\n","OUTPUT: ### é—®ï¼š\n","Using JavaScript, write a function that takes a string as an argument and prints out whether the string is a Palindrome.\n","str = \"racecar\"\n","### ç­”ï¼š\n","str = \"racecar\"\n","### ç­”\n","str = \"racecar\"\n","### ç­”\n","str = \"racecar\"\n","### ç­”\n","str = \"racecar\"\n","### ç­”\n","str = \"racecar\"\n","### ç­”\n","str = \"racecar\"\n","### ç­”\n","str = \"racecar\"\n","### ç­”\n","str = \"racecar\"\n","### ç­”\n","str = \"racecar\"\n","### ç­”\n","str =\n","========================================\n","PROMPT: ### é—®ï¼š\n","Create an array of 10 random numbers between 1 and 100 in JavaScript and print each number in the console.\n","### ç­”ï¼š\n","\n","OUTPUT: ### é—®ï¼š\n","Create an array of 10 random numbers between 1 and 100 in JavaScript and print each number in the console.\n","### ç­”ï¼š\n","\n","### ç­”åº”\n","\n","### ç­”åº”ç­”åº”\n","\n","### ç­”åº”ç­”åº”ç­”åº”\n","\n","### ç­”åº”ç­”åº”ç­”åº”ç­”åº”\n","\n","### ç­”åº”ç­”åº”ç­”åº”ç­”åº”\n","\n","### ç­”åº”ç­”åº”ç­”åº”ç­”åº”\n","\n","### ç­”åº”ç­”åº”ç­”åº”ç­”åº”\n","\n","### ï¿½\n"]}],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n","import os, json\n","\n","# æ ¹æ® training_args.yaml çš„ output_dir ç¡®å®šä¿å­˜è·¯å¾„ï¼Œæˆ–æ”¹æˆä½ æƒ³è¦çš„ models è·¯å¾„\n","import yaml\n","cfg = yaml.safe_load(open(f\"{CONFIGS_DIR}/training_args.yaml\"))\n","outdir = cfg.get(\"output_dir\", f\"{BASE_DIR}/models/finetuned_model\")\n","print(\"Expecting model at:\", outdir)\n","\n","tokenizer = AutoTokenizer.from_pretrained(outdir)\n","model = AutoModelForCausalLM.from_pretrained(outdir, device_map=\"auto\")\n","gen = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n","\n","# æµ‹è¯•å‡ æ¡ valid\n","with open(f\"{DATA_DIR}/valid.jsonl\",'r',encoding='utf-8') as f:\n","    lines = [json.loads(l) for l in f][:5]\n","\n","for ex in lines:\n","    prompt = f\"### é—®ï¼š\\n{ex['prompt']}\\n### ç­”ï¼š\\n\"\n","    out = gen(prompt, max_new_tokens=128, do_sample=False)[0][\"generated_text\"]\n","    print(\"=\"*40)\n","    print(\"PROMPT:\", prompt)\n","    print(\"OUTPUT:\", out)\n"]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","from peft import PeftModel, PeftConfig\n","import os, json\n","import torch\n","import yaml\n","from tqdm import tqdm\n","\n","class ModelTester:\n","    def __init__(self, configs_dir, data_dir, base_dir):\n","        self.configs_dir = configs_dir\n","        self.data_dir = data_dir\n","        self.base_dir = base_dir\n","        self.model = None\n","        self.tokenizer = None\n","\n","    def load_model(self):\n","        \"\"\"åŠ è½½æ¨¡å‹å’Œtokenizer\"\"\"\n","        # è¯»å–é…ç½®\n","        cfg = yaml.safe_load(open(f\"{self.configs_dir}/training_args.yaml\"))\n","        outdir = cfg.get(\"output_dir\", f\"{self.base_dir}/models/finetuned_model\")\n","\n","        print(f\"ğŸ” æ£€æŸ¥æ¨¡å‹ç›®å½•: {outdir}\")\n","        if not os.path.exists(outdir):\n","            raise FileNotFoundError(f\"æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {outdir}\")\n","\n","        # æ£€æŸ¥æ˜¯å¦æ˜¯LoRAæ¨¡å‹\n","        try:\n","            peft_config = PeftConfig.from_pretrained(outdir)\n","            is_lora = True\n","            base_model_name = peft_config.base_model_name_or_path\n","            print(f\"âœ… æ£€æµ‹åˆ°LoRAæ¨¡å‹ï¼ŒåŸºç¡€æ¨¡å‹: {base_model_name}\")\n","        except:\n","            is_lora = False\n","            base_model_name = cfg.get(\"model_name_or_path\", \"TinyLlama/TinyLlama_v1.1\")\n","            print(f\"âœ… åŠ è½½å®Œæ•´æ¨¡å‹: {base_model_name}\")\n","\n","        # åŠ è½½tokenizer\n","        self.tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n","\n","        # åŠ è½½æ¨¡å‹\n","        if is_lora:\n","            # LoRAæ¨¡å‹åŠ è½½æ–¹å¼\n","            base_model = AutoModelForCausalLM.from_pretrained(\n","                base_model_name,\n","                device_map=\"auto\",\n","                torch_dtype=torch.float16,\n","                trust_remote_code=True\n","            )\n","            self.model = PeftModel.from_pretrained(base_model, outdir)\n","            print(\"âœ… LoRAé€‚é…å™¨åŠ è½½å®Œæˆ\")\n","        else:\n","            # å®Œæ•´æ¨¡å‹åŠ è½½æ–¹å¼\n","            self.model = AutoModelForCausalLM.from_pretrained(\n","                outdir,\n","                device_map=\"auto\",\n","                torch_dtype=torch.float16,\n","                trust_remote_code=True\n","            )\n","            print(\"âœ… å®Œæ•´æ¨¡å‹åŠ è½½å®Œæˆ\")\n","\n","        print(f\"ğŸ“Š æ¨¡å‹å‚æ•°æ•°é‡: {self.model.num_parameters():,}\")\n","        print(f\"ğŸ’» æ¨¡å‹è®¾å¤‡: {self.model.device}\")\n","\n","    def generate_response(self, prompt, generation_config=None):\n","        \"\"\"ç”Ÿæˆå›å¤\"\"\"\n","        if generation_config is None:\n","            generation_config = {\n","                \"max_new_tokens\": 256,\n","                \"do_sample\": True,\n","                \"temperature\": 0.1,\n","                \"top_p\": 0.5,\n","                \"repetition_penalty\": 1.1,\n","                \"pad_token_id\": self.tokenizer.eos_token_id\n","            }\n","\n","        # ç¼–ç è¾“å…¥\n","        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n","\n","        # ç”Ÿæˆ\n","        with torch.no_grad():\n","            outputs = self.model.generate(\n","                **inputs,\n","                **generation_config\n","            )\n","\n","        # è§£ç è¾“å‡º\n","        full_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        generated_text = full_text[len(prompt):]\n","\n","        return full_text, generated_text\n","\n","    def test_validation_set(self, num_samples=10, save_results=False):\n","        \"\"\"æµ‹è¯•éªŒè¯é›†\"\"\"\n","        print(f\"\\nğŸ§ª å¼€å§‹éªŒè¯é›†æµ‹è¯• ({num_samples}ä¸ªæ ·æœ¬)\")\n","\n","        # åŠ è½½éªŒè¯æ•°æ®\n","        with open(f\"{self.data_dir}/valid.jsonl\", 'r', encoding='utf-8') as f:\n","            lines = [json.loads(l) for l in f][:num_samples]\n","\n","        results = []\n","\n","        for i, ex in enumerate(tqdm(lines, desc=\"æµ‹è¯•è¿›åº¦\")):\n","            prompt = f\"é—®ï¼š\\n{ex['prompt']}\\nç­”ï¼š\\n\"\n","            expected_response = ex.get('response', '')\n","\n","            try:\n","                full_text, generated_text = self.generate_response(prompt)\n","\n","                result = {\n","                    \"id\": i,\n","                    \"prompt\": ex['prompt'],\n","                    \"expected\": expected_response,\n","                    \"generated\": generated_text,\n","                    \"full_output\": full_text\n","                }\n","                results.append(result)\n","\n","                # æ‰“å°ç»“æœ\n","                print(f\"\\n{'='*60}\")\n","                print(f\"ğŸ“ æ ·æœ¬ {i+1}:\")\n","                print(f\"â“ é—®é¢˜: {ex['prompt'][:100]}...\")\n","                print(f\"ğŸ¤– ç”Ÿæˆå›ç­”: {generated_text.strip()}\")\n","                print(f\"âœ… æœŸæœ›å›ç­”: {expected_response}\")\n","\n","            except Exception as e:\n","                print(f\"âŒ æ ·æœ¬ {i+1} ç”Ÿæˆå¤±è´¥: {e}\")\n","                continue\n","\n","        # ä¿å­˜ç»“æœ\n","        if save_results:\n","            output_file = f\"{self.base_dir}/test_results.json\"\n","            with open(output_file, 'w', encoding='utf-8') as f:\n","                json.dump(results, f, ensure_ascii=False, indent=2)\n","            print(f\"\\nğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜è‡³: {output_file}\")\n","\n","        return results\n","\n","    def interactive_mode(self):\n","        \"\"\"äº¤äº’å¼æµ‹è¯•æ¨¡å¼\"\"\"\n","        print(\"\\nğŸ® è¿›å…¥äº¤äº’æ¨¡å¼ (è¾“å…¥ 'quit' é€€å‡º)\")\n","\n","        generation_configs = {\n","            \"creative\": {\n","                \"max_new_tokens\": 300,\n","                \"do_sample\": True,\n","                \"temperature\": 0.8,\n","                \"top_p\": 0.9,\n","                \"top_k\": 50\n","            },\n","            \"precise\": {\n","                \"max_new_tokens\": 200,\n","                \"do_sample\": False,  # è´ªå©ªè§£ç \n","                \"temperature\": 1.0,\n","                \"top_p\": 1.0\n","            },\n","            \"balanced\": {\n","                \"max_new_tokens\": 256,\n","                \"do_sample\": True,\n","                \"temperature\": 0.7,\n","                \"top_p\": 0.9\n","            }\n","        }\n","\n","        current_mode = \"balanced\"\n","\n","        while True:\n","            try:\n","                user_input = input(f\"\\nğŸ’¬ è¯·è¾“å…¥é—®é¢˜ [{current_mode}æ¨¡å¼]: \").strip()\n","\n","                if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:\n","                    break\n","                elif user_input.lower() == 'mode':\n","                    # åˆ‡æ¢ç”Ÿæˆæ¨¡å¼\n","                    print(\"å¯ç”¨æ¨¡å¼: creative, precise, balanced\")\n","                    new_mode = input(\"é€‰æ‹©æ¨¡å¼: \").strip()\n","                    if new_mode in generation_configs:\n","                        current_mode = new_mode\n","                        print(f\"âœ… åˆ‡æ¢åˆ° {current_mode} æ¨¡å¼\")\n","                    continue\n","                elif not user_input:\n","                    continue\n","\n","                prompt = f\"é—®ï¼š\\n{user_input}\\nç­”ï¼š\\n\"\n","                full_text, generated_text = self.generate_response(\n","                    prompt,\n","                    generation_configs[current_mode]\n","                )\n","\n","                print(f\"\\nğŸ¤– æ¨¡å‹å›ç­” ({current_mode}æ¨¡å¼):\")\n","                print(f\"ğŸ“ {generated_text.strip()}\")\n","\n","            except KeyboardInterrupt:\n","                print(\"\\nğŸ‘‹ é€€å‡ºäº¤äº’æ¨¡å¼\")\n","                break\n","            except Exception as e:\n","                print(f\"âŒ ç”Ÿæˆå¤±è´¥: {e}\")\n","\n","def main():\n","    \"\"\"ä¸»å‡½æ•°\"\"\"\n","    tester = ModelTester(CONFIGS_DIR, DATA_DIR, BASE_DIR)\n","\n","    try:\n","        # 1. åŠ è½½æ¨¡å‹\n","        tester.load_model()\n","\n","        # 2. éªŒè¯é›†æµ‹è¯•\n","        tester.test_validation_set(num_samples=5, save_results=True)\n","\n","        # 3. äº¤äº’æ¨¡å¼\n","        #tester.interactive_mode()\n","\n","    except Exception as e:\n","        print(f\"âŒ é”™è¯¯: {e}\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8TB4BuMvSzMk","outputId":"0354428f-799b-4a9d-8162-298a8a9e3acd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ” æ£€æŸ¥æ¨¡å‹ç›®å½•: models/tinyllama_ai_finetuned\n","âœ… æ£€æµ‹åˆ°LoRAæ¨¡å‹ï¼ŒåŸºç¡€æ¨¡å‹: TinyLlama/TinyLlama_v1.1\n","âœ… LoRAé€‚é…å™¨åŠ è½½å®Œæˆ\n","ğŸ“Š æ¨¡å‹å‚æ•°æ•°é‡: 1,102,301,184\n","ğŸ’» æ¨¡å‹è®¾å¤‡: cuda:0\n","\n","ğŸ§ª å¼€å§‹éªŒè¯é›†æµ‹è¯• (5ä¸ªæ ·æœ¬)\n"]},{"output_type":"stream","name":"stderr","text":["æµ‹è¯•è¿›åº¦:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:20,  5.23s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","ğŸ“ æ ·æœ¬ 1:\n","â“ é—®é¢˜: Create a function in C to check whether a given string contains any punctuations or not....\n","ğŸ¤– ç”Ÿæˆå›ç­”: A: You can use the following code:\n","#include <stdio.h>\n","int main() {\n","    char str[100];\n","    printf(\"Enter a string: \");\n","    scanf(\"%s\", str);\n","    if (strchr(str, '!') || strchr(str, '#')) {\n","        printf(\"The string contains punctuation marks.\\n\");\n","    } else {\n","        printf(\"The string does not contain punctuation marks.\\n\");\n","    }\n","}\n","âœ… æœŸæœ›å›ç­”: bool containsPunctuation(string s) {\n","  for (char c : s) {\n","    if (ispunct(c)) \n","      return true;\n","  }\n","  return false;\n","}\n"]},{"output_type":"stream","name":"stderr","text":["\ræµ‹è¯•è¿›åº¦:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:17<00:28,  9.54s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","ğŸ“ æ ·æœ¬ 2:\n","â“ é—®é¢˜: Design a function in PHP that takes two strings as input and return true if the strings are an anagr...\n","ğŸ¤– ç”Ÿæˆå›ç­”: string1 = string2\n","string2 = string1\n","string1 = string2\n","string2 = string1\n","string1 = string2\n","string2 = string1\n","string1 = string2\n","string2 = string1\n","string1 = string2\n","string2 = string1\n","string1 = string2\n","string2 = string1\n","string1 = string2\n","string2 = string1\n","string1 = string2\n","string2 = string1\n","string1 = string2\n","string2 = string1\n","string1 = string2\n","string2 = string1\n","string1 = string2\n","string2 = string1\n","string1 = string2\n","string2 = string1\n","string1 = string2\n","string2 = string1\n","string1 = string2\n","string2 = string1\n","string1 = string2\n","string2 = string1\n","string1 = string2\n","string2 = string1\n","string1 = string2\n","string2 = string1\n","string1 = string2\n","string2 = string1\n","string1 = string2\n","string2 = string1\n","string1 = string2\n","string2 = string1\n","string1 = string2\n","string2 = string1\n","string1 = string\n","âœ… æœŸæœ›å›ç­”: function checkAnagram(string1, string2) {\n","  if(string1.length !== string2.length) {\n","    return false;\n","  }\n","  var charCounter1 = {}, charCounter2 = {};\n","\n","  for(var  i = 0; i < string1.length; i++) {\n","    var char1 = string1[i];\n","    var char2 = string2[i];\n","\n","    if(charCounter1[char1]) {\n","      charCounter1[char1]++;\n","    } else {\n","      charCounter1[char1] = 1;\n","    }\n","\n","    if(charCounter2[char2]) {\n","      charCounter2[char2]++;\n","    } else {\n","      charCounter2[char2] = 1;\n","    }\n","  }\n","\n","  for(var char in charCounter1) {\n","    if(charCounter1[char] !== charCounter2[char]) {\n","      return false;\n","    }\n","  }\n","\n","  return true;\n","}\n"]},{"output_type":"stream","name":"stderr","text":["\ræµ‹è¯•è¿›åº¦:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:30<00:21, 10.91s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","ğŸ“ æ ·æœ¬ 3:\n","â“ é—®é¢˜: Create a custom exception class for a restaurant that has no menu items....\n","ğŸ¤– ç”Ÿæˆå›ç­”: The following code will create an exception class for a restaurant that has no menu items:\n","class NoMenuException : public Exception {\n","public:\n","NoMenuException(const std::string & message) : Exception(message) {}\n","};\n","The following code will create an exception class for a restaurant that has one menu item:\n","class OneMenuItemException : public Exception {\n","public:\n","OneMenuItemException(const std::string & message) : Exception(message) {}\n","};\n","The following code will create an exception class for a restaurant that has two menu items:\n","class TwoMenuItemsException : public Exception {\n","public:\n","TwoMenuItemsException(const std::string & message) : Exception(message) {}\n","};\n","The following code will create an exception class for a restaurant that has three menu items:\n","class ThreeMenuItemsException : public Exception {\n","public:\n","ThreeMenuItemsException(const std::string & message) : Exception(message) {}\n","};\n","The following code will create an exception class for a restaurant that has four menu items:\n","class FourMenuItemsException : public Exception {\n","public:\n","FourMenuItemsException(const std::string & message) : Exception(message) {}\n","âœ… æœŸæœ›å›ç­”: class NoMenuItemsError(Exception): \n","    def __init__(self, message): \n","        super().__init__(message)\n","        self.message = message \n","\n","def raise_error():\n","    raise NoMenuItemsError(\"No menu items are available\")\n"]},{"output_type":"stream","name":"stderr","text":["\ræµ‹è¯•è¿›åº¦:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:42<00:11, 11.56s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","ğŸ“ æ ·æœ¬ 4:\n","â“ é—®é¢˜: Using JavaScript, write a function that takes a string as an argument and prints out whether the str...\n","ğŸ¤– ç”Ÿæˆå›ç­”: The function returns true if the string is a palindrome, otherwise it returns false.\n","function isPalindrome(str) {\n","var i;\n","for (i = str.length - 1; i >= 0; i--) {\n","if (str[i] != str[i + 1]) return false;\n","return true;\n","This function is called recursively to check each character in the string.\n","If the character is not equal to its previous value, then the function returns false. Otherwise, it returns true.\n","The function is recursive because it calls itself recursively until the string is empty or the length of the string is less than 2.\n","The function is also written in a way that it can be used for any string.\n","The function is also written in a way that it can be used for any string. The function is also written in a way that it can be used for any string.\n","The function is also written in a way that it can be used for any string. The function is also written in a way that it can be used for any string. The function is also written in a way that it can be used for any string.\n","The function is also written in a way\n","âœ… æœŸæœ›å›ç­”: function isPalindrome(str) {\n","    var i;\n","    var len = str.length;\n","\n","    for (i = 0; i < len/2; i++) {\n","        if (str[i] !== str[len - 1 - i]) {\n","            return false;\n","        }\n","    }\n","    return true;\n","}\n"]},{"output_type":"stream","name":"stderr","text":["æµ‹è¯•è¿›åº¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:55<00:00, 11.07s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","ğŸ“ æ ·æœ¬ 5:\n","â“ é—®é¢˜: Create an array of 10 random numbers between 1 and 100 in JavaScript and print each number in the co...\n","ğŸ¤– ç”Ÿæˆå›ç­”: The number of times you have to press the space bar is equal to the number of times you have to press the space bar in JavaScript.\n","The number of times you have to press the space bar is equal to the number of times you have to press the space bar in JavaScript.\n","The number of times you have to press the space bar is equal to the number of times you have to press the space bar in JavaScript.\n","The number of times you have to press the space bar is equal to the number of times you have to press the space bar in JavaScript.\n","The number of times you have to press the space bar is equal to the number of times you have to press the space bar in JavaScript.\n","The number of times you have to press the space bar is equal to the number of times you have to press the space bar in JavaScript.\n","The number of times you have to press the space bar is equal to the number of times you have to press the space bar in JavaScript.\n","The number of times you have to press the space bar is equal to the number of times you have to press the space bar in JavaScript.\n","The number of times you have to press the space bar is equal to the number of times you have to press the space\n","âœ… æœŸæœ›å›ç­”: var arr = [];\n","\n","for (i = 0; i < 10; i++) {\n","  arr.push(Math.floor(Math.random() * 100) + 1);\n","  console.log(arr[i]);\n","}\n","\n","ğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜è‡³: /content/drive/MyDrive/Final_Project/test_results.json\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}